{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyMJHscqr1lqGLFYGFQl6e66"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hZdclMxQd6kq","executionInfo":{"status":"ok","timestamp":1764556617059,"user_tz":-540,"elapsed":21528,"user":{"displayName":"TE nok","userId":"01928761000188356119"}},"outputId":"d346b11c-ed92-4c80-953d-31d0ea5f0666"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# RDKit ã‚’ Colab ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«\n","!pip install rdkit"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ex-vveI6eWiM","executionInfo":{"status":"ok","timestamp":1764556625871,"user_tz":-540,"elapsed":6729,"user":{"displayName":"TE nok","userId":"01928761000188356119"}},"outputId":"6f3862f0-9ba3-42c6-dc62-07d5eb55205c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rdkit\n","  Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rdkit) (2.0.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from rdkit) (11.3.0)\n","Downloading rdkit-2025.9.1-cp312-cp312-manylinux_2_28_x86_64.whl (36.2 MB)\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m36.2/36.2 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rdkit\n","Successfully installed rdkit-2025.9.1\n"]}]},{"cell_type":"code","source":["%%bash\n","set -euo pipefail\n","echo \"â³  Installing PyTorch-Geometric + RDKit (Py3.12 friendly)â€¦\"\n","\n","# æœ€æ–° pip\n","python -m pip install -q --upgrade pip\n","\n","# â˜… ã“ã“ã‚’ã€Œãƒã‚¤ãƒŠãƒªæ‹¡å¼µãªã—ã€ã«ç°¡ç•¥åŒ–ã™ã‚‹\n","#   - torch_geometric ã¯ PyTorch ã•ãˆå…¥ã£ã¦ã„ã‚Œã°å˜ä½“ã§å‹•ä½œå¯èƒ½\n","python -m pip install -q torch_geometric rdkit captum matplotlib pandas\n","\n","# å‹•ä½œç¢ºèª\n","python - <<'PY'\n","import torch, torch_geometric, captum\n","from rdkit import Chem, RDLogger; RDLogger.DisableLog('rdApp.*')\n","\n","print(\"âœ… torch         :\", torch.__version__)\n","print(\"âœ… torch_geometric:\", torch_geometric.__version__)\n","print(\"âœ… captum        :\", captum.__version__)\n","print(\"âœ… rdkit import OK | MolFromSmiles:\",\n","      Chem.MolFromSmiles(\"CCO\") is not None)\n","PY\n","\n","echo \"ğŸ‰  All deps installed\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Boe-ipeeihk","executionInfo":{"status":"ok","timestamp":1764557026972,"user_tz":-540,"elapsed":21975,"user":{"displayName":"TE nok","userId":"01928761000188356119"}},"outputId":"be4785ea-1ca5-47c4-b6de-e8d5dacc9c74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["â³  Installing PyTorch-Geometric + RDKit (Py3.12 friendly)â€¦\n","âœ… torch         : 2.9.0+cu126\n","âœ… torch_geometric: 2.7.0\n","âœ… captum        : 0.8.0\n","âœ… rdkit import OK | MolFromSmiles: True\n","ğŸ‰  All deps installed\n"]},{"output_type":"stream","name":"stderr","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n","jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n","shap 0.50.0 requires numpy>=2, but you have numpy 1.26.4 which is incompatible.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","# å…¥åŠ›\n","p6 = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/AID_1346986_datatable_all.csv\"  # KB-3-1\n","p7 = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/AID_1346987_datatable_all.csv\"  # KB-8-5-11\n","df6 = pd.read_csv(p6)\n","df7 = pd.read_csv(p7)\n","\n","def out2lab(x):\n","    if pd.isna(x): return np.nan\n","    x = str(x).strip().lower()\n","    return 1 if x=='active' else (0 if x=='inactive' else np.nan)\n","\n","# å¿…è¦åˆ—æŠ½å‡ºï¼†å‘½å\n","a6 = df6[['PUBCHEM_CID','PUBCHEM_EXT_DATASOURCE_SMILES',\n","          'PUBCHEM_ACTIVITY_OUTCOME','Fit_LogAC50','Max_Response']].copy()\n","a6['Active6'] = a6['PUBCHEM_ACTIVITY_OUTCOME'].apply(out2lab)\n","a6 = a6.rename(columns={'Fit_LogAC50':'logAC50_6','Max_Response':'MaxResp_6'})\n","\n","a7 = df7[['PUBCHEM_CID','PUBCHEM_EXT_DATASOURCE_SMILES',\n","          'PUBCHEM_ACTIVITY_OUTCOME','Fit_LogAC50','Max_Response']].copy()\n","a7['Active7'] = a7['PUBCHEM_ACTIVITY_OUTCOME'].apply(out2lab)\n","a7 = a7.rename(columns={'Fit_LogAC50':'logAC50_7','Max_Response':'MaxResp_7'})\n","\n","# --- ã“ã“ãŒé‡è¦ï¼šæ•°å€¤åŒ–ï¼ˆéæ•°ã¯ NaN ã«ï¼‰\n","for col in ['logAC50_6','MaxResp_6']:\n","    a6[col] = pd.to_numeric(a6[col], errors='coerce')\n","for col in ['logAC50_7','MaxResp_7']:\n","    a7[col] = pd.to_numeric(a7[col], errors='coerce')\n","\n","print(\"dtypes after cast:\")\n","print(a6[['logAC50_6','MaxResp_6']].dtypes)\n","print(a7[['logAC50_7','MaxResp_7']].dtypes)\n","\n","# å¤‰æ›ã§NaNã«ãªã£ãŸä»¶æ•°ã‚’æŠŠæ¡\n","print(\"coerceâ†’NaN counts:\",\n","      (a6['logAC50_6'].isna()).sum(), (a7['logAC50_7'].isna()).sum())\n","\n","# ãƒãƒ¼ã‚¸\n","m = pd.merge(a6.drop(columns=['PUBCHEM_ACTIVITY_OUTCOME']),\n","             a7.drop(columns=['PUBCHEM_ACTIVITY_OUTCOME']),\n","             on=['PUBCHEM_CID','PUBCHEM_EXT_DATASOURCE_SMILES'],\n","             how='outer')\n","\n","# å·®åˆ†\n","m['dlogAC50'] = m['logAC50_7'] - m['logAC50_6']\n","\n","# 4å€é–¾å€¤\n","LOG_FR_THR = np.log10(4.0)  # 0.60206...\n","\n","def label_row(r):\n","    s6, s7, d = r['Active6'], r['Active7'], r['dlogAC50']\n","    # substrate\n","    if s6 == 1 and (s7 == 0 or (pd.notna(d) and d >= LOG_FR_THR)):\n","        return 1\n","    # non-substrate\n","    if (s7 == 1 and (s6 != 1 or (pd.notna(d) and d < LOG_FR_THR))) or (s6 == 0 and s7 == 0):\n","        return 0\n","    # ãã®ä»–ã¯é™¤å¤–ï¼ˆInconclusiveå«ã‚€ï¼‰\n","    return np.nan\n","\n","m['Substrate'] = m.apply(label_row, axis=1)\n","\n","out = m.rename(columns={'PUBCHEM_CID':'CID',\n","                        'PUBCHEM_EXT_DATASOURCE_SMILES':'SMILES'})[['CID','SMILES','Substrate','dlogAC50']]\n","out = out.dropna(subset=['Substrate']).drop_duplicates()\n","\n","print(out['Substrate'].value_counts(dropna=False))\n","\n","# --- ã“ã“ã‹ã‚‰è¿½åŠ å…¥ã‚Š --- #\n","# CIDãŒç©ºç™½ï¼ˆæ¬ æï¼‰ã‚’å‰Šé™¤ã—ã€SampleWeightåˆ—(å…¨ã¦0.7)ã‚’è¿½åŠ \n","out['CID'] = pd.to_numeric(out['CID'], errors='coerce')  # æ•°å€¤åŒ–ã—ã¦æ¬ æåˆ¤å®šã‚’å®‰å®šåŒ–\n","out = out.dropna(subset=['CID'])                         # CIDæ¬ æè¡Œã‚’å‰Šé™¤\n","out['SampleWeight'] = 0.7                                # è¿½åŠ : å…¨è¡Œ 0.7\n","# --- è¿½åŠ å…¥ã‚Šã“ã“ã¾ã§ --- #\n","\n","# --- å‹ã®æ•´å‚™ï¼ˆä»»æ„ã ãŒã‚ªã‚¹ã‚¹ãƒ¡ï¼‰ ---\n","out['CID'] = out['CID'].astype('Int64')   # æ¬ æå¯¾å¿œã®æ•´æ•°\n","out['Substrate'] = out['Substrate'].astype('Int64')\n","out['dlogAC50'] = pd.to_numeric(out['dlogAC50'], errors='coerce')\n","\n","# ä¸¦ã¹æ›¿ãˆï¼ˆä»»æ„ï¼šé™½æ€§ã‚’ä¸Šã«ã€dlogAC50å¤§ãã„é †ï¼‰\n","out = out.sort_values(['Substrate','dlogAC50'], ascending=[False, False])\n","\n","# --- ä¿å­˜ ---\n","save_dir = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","out_path = f\"{save_dir}/AID_1346986_1346987_labels_fold4.csv\"\n","out.to_csv(out_path, index=False)\n","\n","print(\"âœ… ä¿å­˜:\", out_path)\n","print(\"shape:\", out.shape)\n","print(\"label counts:\\n\", out['Substrate'].value_counts(dropna=False))\n","\n","audit_cols = [\n","    'PUBCHEM_CID','PUBCHEM_EXT_DATASOURCE_SMILES',\n","    'Active6','Active7','logAC50_6','logAC50_7','dlogAC50','Substrate'\n","]\n","audit = m[audit_cols].rename(columns={\n","    'PUBCHEM_CID':'CID','PUBCHEM_EXT_DATASOURCE_SMILES':'SMILES'\n","})\n","audit['CID'] = pd.to_numeric(audit['CID'], errors='coerce').astype('Int64')\n","audit_path = f\"{save_dir}/AID_1346986_1346987_labels_fold4_audit.csv\"\n","audit.to_csv(audit_path, index=False)\n","\n","print(\"ğŸ“ ç›£æŸ»ç”¨ã‚‚ä¿å­˜:\", audit_path)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLdfbBWef19Y","executionInfo":{"status":"ok","timestamp":1760672367109,"user_tz":-540,"elapsed":5728,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"429ae450-6d91-4915-f528-f6d0df840744"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["dtypes after cast:\n","logAC50_6    float64\n","MaxResp_6    float64\n","dtype: object\n","logAC50_7    float64\n","MaxResp_7    float64\n","dtype: object\n","coerceâ†’NaN counts: 6512 5900\n","Substrate\n","0.0    8397\n","1.0     399\n","Name: count, dtype: int64\n","âœ… ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/AID_1346986_1346987_labels_fold4.csv\n","shape: (8708, 5)\n","label counts:\n"," Substrate\n","0    8325\n","1     383\n","Name: count, dtype: Int64\n","ğŸ“ ç›£æŸ»ç”¨ã‚‚ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/AID_1346986_1346987_labels_fold4_audit.csv\n"]}]},{"cell_type":"code","source":["# =========================================\n","# Drugåï¼ˆè‹±èªï¼‰â†’ PubChem CID â†’ SMILESï¼ˆå¤šæ®µãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰\n","# 1) CanonicalSMILES > 2) IsomericSMILES > 3) PUG View > 4) SDFâ†’RDKit\n","# å–å¾—å…ƒã¯ SMILES_Source ã«è¨˜éŒ² / ç„¡å¡©æœ¬ä½“ã®æ­£è¦åŒ–ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚ã‚Š\n","# â˜… å…ƒExcelã®ã€ŒABCB1 Substrateã€ç›¸å½“åˆ—ã‚’æœ€çµ‚CSVã¸ä¿å­˜ï¼ˆåˆ—åã¯å…ƒã®ã¾ã¾ä¿æŒï¼‰\n","#    é‡è¤‡æ™‚ã®å„ªå…ˆãƒ«ãƒ¼ãƒ«ã¯ SUBSTRATE_RESOLVE_POLICY ã§é¸æŠå¯ï¼ˆ\"first\" / \"positive\"ï¼‰\n","# =========================================\n","\n","# 0) å¿…è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆColabæƒ³å®šã€‚ä¸è¦ãªã‚‰ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰\n","try:\n","    import requests, pandas, openpyxl, rdkit\n","except Exception:\n","    import sys, subprocess\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"requests\", \"pandas\", \"openpyxl\", \"rdkit-pypi\"])\n","\n","# 1) è¨­å®š\n","INPUT_XLSX = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/Drug_Transporters_(ABCB1).xlsx\"\n","DRUG_COL   = \"Drug\"\n","OUT_CSV    = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles.csv\"\n","UNRES_CSV  = OUT_CSV.replace(\".csv\", \"_unresolved.csv\")\n","\n","UNSALT       = False              # True: æœ€å¤§ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆã§â€œç„¡å¡©æœ¬ä½“â€ã«æ­£è¦åŒ–\n","KEEP_METALS  = True               # é‡‘å±ã‚’å«ã‚€ã¨ãã¯ãƒ•ãƒ©ã‚°ãƒ¡ãƒ³ãƒˆåŒ–ã—ãªã„\n","PER_ITEM_SLEEP_SEC = 0.25\n","\n","# â–¼ Substrateã®é‡è¤‡æ™‚å„ªå…ˆãƒ«ãƒ¼ãƒ«: \"first\"ï¼ˆå…ˆå‹ã¡ï¼‰ or \"positive\"ï¼ˆé™½æ€§å„ªå…ˆï¼‰\n","SUBSTRATE_RESOLVE_POLICY = \"first\"\n","\n","# 2) å®Ÿè£…\n","import time, random, re, csv\n","import pandas as pd\n","import requests\n","from typing import List, Optional, Tuple\n","from requests.adapters import HTTPAdapter\n","from urllib3.util.retry import Retry\n","from rdkit import Chem\n","from rdkit import RDLogger\n","RDLogger.DisableLog('rdApp.*')\n","\n","PUG_BASE   = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug\"\n","PUGVIEW    = \"https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound\"\n","HDRS = {\"User-Agent\":\"drugname2cid-fallback/1.2 (colab)\", \"Accept\":\"application/json\"}\n","METALS = {\"Li\",\"Na\",\"K\",\"Mg\",\"Ca\",\"Fe\",\"Cu\",\"Zn\",\"Pt\",\"Bi\",\"Al\",\"Mn\",\"Ni\",\"Co\",\"Sr\",\"Ba\",\"Ag\",\"Au\"}\n","\n","def build_session():\n","    s = requests.Session()\n","    retry = Retry(total=6, connect=6, read=6, backoff_factor=0.6,\n","                  status_forcelist=[429,500,502,503,504],\n","                  allowed_methods=frozenset([\"GET\"]), raise_on_status=False)\n","    ad = HTTPAdapter(max_retries=retry, pool_connections=32, pool_maxsize=32)\n","    s.mount(\"https://\", ad); s.mount(\"http://\", ad)\n","    s.headers.update(HDRS)\n","    return s\n","\n","S = build_session()\n","\n","def sleep():\n","    time.sleep(PER_ITEM_SLEEP_SEC + random.uniform(0, PER_ITEM_SLEEP_SEC))\n","\n","def get_json(url, timeout=60):\n","    try:\n","        r = S.get(url, timeout=timeout)\n","        if r.status_code == 200:\n","            try: return r.json()\n","            except Exception: return None\n","        if r.status_code in (400,404):\n","            return None\n","    except requests.RequestException:\n","        return None\n","    return None\n","\n","def get_bytes(url, timeout=60):\n","    try:\n","        r = S.get(url, timeout=timeout)\n","        if r.status_code == 200:\n","            return r.content\n","        if r.status_code in (400,404):\n","            return None\n","    except requests.RequestException:\n","        return None\n","    return None\n","\n","def normalize_name(x:str)->str:\n","    return re.sub(r\"\\s+\",\" \", (x or \"\").strip())\n","\n","def find_real_col(df: pd.DataFrame, target: str)->Optional[str]:\n","    t = target.strip().lower()\n","    for c in df.columns:\n","        if str(c).strip().lower() == t:\n","            return c\n","    return None\n","\n","def find_substrate_col(df: pd.DataFrame)->Optional[str]:\n","    # ã€ŒABCB1 Substrateã€ç›¸å½“åˆ—ã‚’â€œç·©ãâ€æ¤œå‡º\n","    norm = {str(c): str(c).strip().lower().replace(\" \", \"\").replace(\"_\",\"\") for c in df.columns}\n","    inv  = {v: k for k, v in norm.items()}\n","    keys = [\n","        \"abcb1substrate\", \"abcb1_substrate\", \"abcb1 substrate\",\n","        \"substrate\", \"p-gpsubstrate\", \"pgpsubstrate\"\n","    ]\n","    for k in keys:\n","        kk = k.replace(\" \", \"\").replace(\"_\",\"\")\n","        if kk in inv:\n","            return inv[kk]\n","    return None\n","\n","# ---- PubChem basic ----\n","def name_to_cids(name:str)->List[int]:\n","    from urllib.parse import quote\n","    js = get_json(f\"{PUG_BASE}/compound/name/{quote(name)}/cids/JSON\")\n","    if not js: return []\n","    return list(map(int, js.get(\"IdentifierList\",{}).get(\"CID\",[])))\n","\n","def cid_title(cid:int)->Optional[str]:\n","    js = get_json(f\"{PUG_BASE}/compound/cid/{cid}/property/Title/JSON\")\n","    if not js: return None\n","    rows = js.get(\"PropertyTable\",{}).get(\"Properties\",[])\n","    return rows[0].get(\"Title\") if rows else None\n","\n","def cid_synonyms(cid:int)->List[str]:\n","    js = get_json(f\"{PUG_BASE}/compound/cid/{cid}/synonyms/JSON\")\n","    if not js: return []\n","    info = js.get(\"InformationList\",{}).get(\"Information\",[])\n","    syns = info[0].get(\"Synonym\",[]) if info else []\n","    return [normalize_name(s).lower() for s in syns if isinstance(s,str)]\n","\n","# ---- SMILES getters with fallback ----\n","def cid_canonical_smiles(cid:int)->Optional[str]:\n","    js = get_json(f\"{PUG_BASE}/compound/cid/{cid}/property/CanonicalSMILES/JSON\")\n","    if not js: return None\n","    rows = js.get(\"PropertyTable\",{}).get(\"Properties\",[])\n","    return rows[0].get(\"CanonicalSMILES\") if rows else None\n","\n","def cid_isomeric_smiles(cid:int)->Optional[str]:\n","    js = get_json(f\"{PUG_BASE}/compound/cid/{cid}/property/IsomericSMILES/JSON\")\n","    if not js: return None\n","    rows = js.get(\"PropertyTable\",{}).get(\"Properties\",[])\n","    return rows[0].get(\"IsomericSMILES\") if rows else None\n","\n","def cid_smiles_from_pugview(cid:int)->Tuple[Optional[str], Optional[str]]:\n","    js = get_json(f\"{PUGVIEW}/{cid}/JSON\")\n","    if not js: return (None, None)\n","    iso, can = None, None\n","    def walk(obj):\n","        nonlocal iso, can\n","        if isinstance(obj, dict):\n","            head = obj.get(\"TOCHeading\") or obj.get(\"Name\")\n","            if head in (\"Isomeric SMILES\",\"Canonical SMILES\"):\n","                for info in obj.get(\"Information\", []):\n","                    for swm in info.get(\"Value\", {}).get(\"StringWithMarkup\", []):\n","                        s = swm.get(\"String\")\n","                        if isinstance(s, str) and s:\n","                            if head == \"Isomeric SMILES\" and not iso: iso = s\n","                            if head == \"Canonical SMILES\" and not can: can = s\n","            for v in obj.values(): walk(v)\n","        elif isinstance(obj, list):\n","            for v in obj: walk(v)\n","    walk(js)\n","    return iso, can\n","\n","def cid_smiles_from_sdf(cid:int)->Optional[str]:\n","    b = get_bytes(f\"{PUG_BASE}/compound/cid/{cid}/SDF?record_type=2d\")\n","    if not b: return None\n","    try:\n","        txt = b.decode(\"utf-8\",\"ignore\")\n","        mol = Chem.MolFromMolBlock(txt, sanitize=True)\n","        if mol is None: return None\n","        return Chem.MolToSmiles(mol, isomericSmiles=True, canonical=True)\n","    except Exception:\n","        return None\n","\n","def best_available_smiles(cid:int)->Tuple[Optional[str], str, Optional[str]]:\n","    \"\"\"\n","    æˆ»ã‚Š: (BestAvailableSMILES, SMILES_Source, CanonicalSMILES_raw)\n","    Source: 'canonical' | 'isomeric' | 'pugview_isomeric' | 'pugview_canonical' | 'sdf_rdkit'\n","    \"\"\"\n","    can = cid_canonical_smiles(cid); sleep()\n","    if can: return can, \"canonical\", can\n","    iso = cid_isomeric_smiles(cid); sleep()\n","    if iso: return iso, \"isomeric\", None\n","    iso2, can2 = cid_smiles_from_pugview(cid); sleep()\n","    if iso2: return iso2, \"pugview_isomeric\", can2\n","    if can2: return can2, \"pugview_canonical\", can2\n","    sdf = cid_smiles_from_sdf(cid)\n","    if sdf: return sdf, \"sdf_rdkit\", None\n","    return None, \"none\", None\n","\n","# ---- ç„¡å¡©æ­£è¦åŒ– ----\n","def elements_in(smiles:str):\n","    m = Chem.MolFromSmiles(smiles)\n","    if not m: return set()\n","    return {a.GetSymbol() for a in m.GetAtoms()}\n","\n","def largest_fragment_smiles(smiles:str)->Optional[str]:\n","    m = Chem.MolFromSmiles(smiles)\n","    if m is None: return None\n","    frags = Chem.GetMolFrags(m, asMols=True, sanitizeFrags=False)\n","    if len(frags)==1:\n","        return Chem.MolToSmiles(frags[0], isomericSmiles=True, canonical=True)\n","    best, heavy = None, -1\n","    for f in frags:\n","        h = f.GetNumHeavyAtoms()\n","        if h>heavy: best, heavy = f, h\n","    return Chem.MolToSmiles(best, isomericSmiles=True, canonical=True) if best else None\n","\n","def maybe_unsalt(smi:str)->str:\n","    if not UNSALT: return smi\n","    if any(e in METALS for e in elements_in(smi)):\n","        return smi if KEEP_METALS else (largest_fragment_smiles(smi) or smi)\n","    return largest_fragment_smiles(smi) or smi\n","\n","# ---- å€™è£œã‹ã‚‰æœ€è‰¯CIDã‚’é¸ã¶ ----\n","def choose_best_cid(name:str, cids:List[int])->Tuple[Optional[int], str]:\n","    \"\"\"å„ªå…ˆåº¦: Title å®Œå…¨ä¸€è‡´ > Synonym å®Œå…¨ä¸€è‡´ > å…ˆé ­å€™è£œ\"\"\"\n","    q = normalize_name(name).lower()\n","    for cid in cids:\n","        t = cid_title(cid)\n","        if t and normalize_name(t).lower() == q:\n","            return cid, \"exact_title\"\n","        sleep()\n","    for cid in cids:\n","        syns = cid_synonyms(cid)\n","        if q in syns:\n","            return cid, \"exact_synonym\"\n","        sleep()\n","    return (cids[0] if cids else None), \"first_hit\"\n","\n","# ---- Substrate å€¤ã®æ•´å½¢ï¼ˆæ–‡å­—ã§ã‚‚æ•°å€¤ã§ã‚‚â€œäººé–“ã®Yes/Noâ€ã«é ‘å¥ï¼‰----\n","def normalize_substrate_value(v) -> str:\n","    if v is None or (isinstance(v, float) and pd.isna(v)): return \"\"\n","    s = str(v).strip()\n","    if not s: return \"\"\n","    low = s.lower()\n","    # å…¸å‹çš„ãªè‚¯å®šèª\n","    if low in {\"1\",\"yes\",\"y\",\"true\",\"substrate\",\"positive\",\"pos\"}:\n","        return \"1\"\n","    # å…¸å‹çš„ãªå¦å®šèª\n","    if low in {\"0\",\"no\",\"n\",\"false\",\"non-substrate\",\"negative\",\"neg\"}:\n","        return \"0\"\n","    # ãã‚Œä»¥å¤–ã¯å…ƒã®æ–‡å­—åˆ—ã‚’æ®‹ã™\n","    return s\n","\n","def resolve_substrate(prev: str, new: str) -> str:\n","    \"\"\"é‡è¤‡æ™‚ã®è§£æ±ºã€‚SUBSTRATE_RESOLVE_POLICYã«å¾“ã†ã€‚\"\"\"\n","    prev = prev or \"\"\n","    new  = new or \"\"\n","    if not prev: return new\n","    if not new:  return prev\n","    if SUBSTRATE_RESOLVE_POLICY == \"positive\":\n","        # ã©ã¡ã‚‰ã‹ãŒ1/Yesç³»ãªã‚‰ \"1\" ã‚’å„ªå…ˆ\n","        if normalize_substrate_value(prev) == \"1\" or normalize_substrate_value(new) == \"1\":\n","            return \"1\"\n","        # ã©ã¡ã‚‰ã‚‚æ˜ç¢ºã§ãªã„å ´åˆã¯å…ˆå‹ã¡\n","        return prev\n","    # default: firstï¼ˆå…ˆå‹ã¡ï¼‰\n","    return prev\n","\n","# ---- ãƒ¡ã‚¤ãƒ³ ----\n","def main():\n","    xf = pd.ExcelFile(INPUT_XLSX)\n","    chosen_sheet, df, drug_col = None, None, None\n","    for sh in xf.sheet_names:\n","        tmp = pd.read_excel(INPUT_XLSX, sheet_name=sh)\n","        real = find_real_col(tmp, DRUG_COL)\n","        if real is not None:\n","            chosen_sheet, df, drug_col = sh, tmp, real\n","            break\n","    if df is None:\n","        raise RuntimeError(f\"Excelå†…ã« '{DRUG_COL}' åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼š{INPUT_XLSX}\")\n","    print(f\"âœ… ä½¿ç”¨ã‚·ãƒ¼ãƒˆ: {chosen_sheet} / Drugåˆ—: {drug_col}\")\n","\n","    # Substrateåˆ—ã‚’ç‰¹å®šï¼ˆç„¡ã„å ´åˆã¯ Noneï¼‰\n","    substrate_col = find_substrate_col(df)\n","    if substrate_col:\n","        print(f\"âœ… è¦‹ã¤ã‹ã£ãŸ Substrate åˆ—: {substrate_col}\")\n","    else:\n","        print(\"â„¹ Substrate åˆ—ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆå‡ºåŠ›ã«ã¯å«ã‚ã¾ã›ã‚“ï¼‰\")\n","\n","    # Drugåâ†’Substrateå€¤ï¼ˆæ­£è¦åŒ–ï¼‰ã®è¾æ›¸ã‚’æ§‹ç¯‰ï¼ˆé‡è¤‡ã¯ãƒãƒªã‚·ãƒ¼ã§è§£æ±ºï¼‰\n","    name_to_sub = {}\n","    if substrate_col:\n","        for _, r in df.iterrows():\n","            name = normalize_name(str(r.get(drug_col, \"\")))\n","            if not name:\n","                continue\n","            val_raw = r.get(substrate_col, \"\")\n","            val_norm = normalize_substrate_value(val_raw)\n","            if name in name_to_sub:\n","                name_to_sub[name] = resolve_substrate(name_to_sub[name], val_norm)\n","            else:\n","                name_to_sub[name] = val_norm\n","\n","    names = [normalize_name(x) for x in df[drug_col].astype(str).tolist()]\n","    names = [n for n in names if n]\n","    seen = set()\n","    rows, unresolved = [], []\n","\n","    for i, name in enumerate(names, 1):\n","        if name in seen:\n","            continue\n","        seen.add(name)\n","\n","        cids = name_to_cids(name); sleep()\n","        if not cids:\n","            rec = {\"Drug_name\": name, \"reason\":\"no_cid_from_name\"}\n","            if substrate_col: rec[substrate_col] = name_to_sub.get(name, \"\")\n","            unresolved.append(rec)\n","            continue\n","\n","        best_cid, match = choose_best_cid(name, cids)\n","        if not best_cid:\n","            rec = {\"Drug_name\": name, \"candidates\":\";\".join(map(str,cids)), \"reason\":\"could_not_choose\"}\n","            if substrate_col: rec[substrate_col] = name_to_sub.get(name, \"\")\n","            unresolved.append(rec)\n","            continue\n","\n","        best_smi, src, can_raw = best_available_smiles(best_cid); sleep()\n","        if not best_smi:\n","            rec = {\"Drug_name\": name, \"Chosen_CID\": best_cid, \"reason\":\"no_smiles_all_sources\"}\n","            if substrate_col: rec[substrate_col] = name_to_sub.get(name, \"\")\n","            unresolved.append(rec)\n","            continue\n","\n","        best_smi_norm = maybe_unsalt(best_smi)\n","\n","        row = {\n","            \"Drug_name\": name,\n","            \"Chosen_CID\": best_cid,\n","            \"BestAvailableSMILES\": best_smi_norm,\n","            \"SMILES_Source\": src,                 # canonical / isomeric / pugview_* / sdf_rdkit\n","            \"CanonicalSMILES_raw\": can_raw or \"\", # å‚è€ƒ\n","            \"MatchType\": match,\n","            \"Candidates\": \";\".join(map(str,cids))\n","        }\n","        # å‡ºåŠ›ã«å…ƒã®åˆ—åã®ã¾ã¾ Substrate ã‚’è¿½åŠ \n","        if substrate_col:\n","            row[substrate_col] = name_to_sub.get(name, \"\")\n","\n","        rows.append(row)\n","\n","        if i % 25 == 0 or i == len(names):\n","            print(f\"[prog] {i}/{len(names)}  resolved={len(rows)}  unresolved={len(unresolved)}\")\n","\n","    # å‡ºåŠ›åˆ—ï¼ˆSubstrateåˆ—ã¯è¦‹ã¤ã‹ã£ãŸå ´åˆã®ã¿è¿½åŠ ï¼‰\n","    base_cols = [\"Drug_name\",\"Chosen_CID\",\"BestAvailableSMILES\",\"SMILES_Source\",\n","                 \"CanonicalSMILES_raw\",\"MatchType\",\"Candidates\"]\n","    out_cols = base_cols + ([substrate_col] if substrate_col else [])\n","\n","    out_df = pd.DataFrame(rows, columns=out_cols)\n","    out_df.to_csv(OUT_CSV, index=False, quoting=csv.QUOTE_MINIMAL, encoding=\"utf-8\")\n","    print(f\"âœ… ä¿å­˜: {OUT_CSV} (rows={len(out_df)})\")\n","\n","    if unresolved:\n","        unresolved_df = pd.DataFrame(unresolved)\n","        # è¡¨ç¤ºã®ãŸã‚ã®åˆ—é †æ•´å½¢\n","        un_cols = [\"Drug_name\", \"reason\", \"Chosen_CID\", \"candidates\"]\n","        if substrate_col and substrate_col not in un_cols:\n","            un_cols.append(substrate_col)\n","        unresolved_df = unresolved_df[[c for c in un_cols if c in unresolved_df.columns]]\n","        unresolved_df.to_csv(UNRES_CSV, index=False, encoding=\"utf-8\")\n","        print(f\"âš  æœªè§£æ±º: {UNRES_CSV} (rows={len(unresolved_df)})\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNTUbLorcg1T","executionInfo":{"status":"ok","timestamp":1760587113336,"user_tz":-540,"elapsed":732178,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"b04eef9e-fb5b-4194-8979-df0179e0658c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ä½¿ç”¨ã‚·ãƒ¼ãƒˆ: Sheet 1 / Drugåˆ—: Drug\n","âœ… è¦‹ã¤ã‹ã£ãŸ Substrate åˆ—: ABCB1 Substrate\n","[prog] 25/235  resolved=24  unresolved=0\n","[prog] 50/235  resolved=49  unresolved=0\n","[prog] 75/235  resolved=74  unresolved=0\n","[prog] 100/235  resolved=99  unresolved=0\n","[prog] 125/235  resolved=123  unresolved=0\n","[prog] 150/235  resolved=146  unresolved=0\n","[prog] 175/235  resolved=170  unresolved=1\n","[prog] 200/235  resolved=195  unresolved=1\n","[prog] 225/235  resolved=220  unresolved=1\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:urllib3.connectionpool:Retrying (Retry(total=5, connect=6, read=5, redirect=None, status=None)) after connection broken by 'RemoteDisconnected('Remote end closed connection without response')': /rest/pug/compound/cid/42611257/property/IsomericSMILES/JSON\n"]},{"output_type":"stream","name":"stdout","text":["[prog] 235/235  resolved=230  unresolved=1\n","âœ… ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles.csv (rows=230)\n","âš  æœªè§£æ±º: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_unresolved.csv (rows=1)\n"]}]},{"cell_type":"code","source":["# === Merge 'kegg_pubchem_smiles.csv' with uploaded FDA file ===\n","# ä»•æ§˜:\n","#  - ä¸»ã‚­ãƒ¼: CIDå„ªå…ˆ (cid â†” Chosen_CID)ã€æ¬ ã‘ã‚‹å ´åˆã¯åå‰ã®æ­£è¦åŒ–ä¸€è‡´ (name â†” Drug_name)\n","#  - SMILESä¸ä¸€è‡´æ™‚: æ—¢å­˜(BestAvailableSMILES)ã‚’å„ªå…ˆï¼ˆFDAå€¤ã¯æœ€çµ‚CSVã«å‡ºã•ãšã€åˆ¥diffã§ç›£æŸ»ï¼‰\n","#  - å‡ºåŠ›: å…ƒã¨åŒã˜ãƒ•ã‚©ãƒ«ãƒ€ã« kegg_pubchem_smiles_merged.csv\n","#  - åˆ—: å…ƒCSVã®åˆ—ã‚’ä¿æŒ + MergeSourceï¼ˆ\"base\" | \"base+fda\" | \"fda_file\"ï¼‰+ SampleWeightï¼ˆâ˜…è¿½åŠ ï¼‰\n","#  - ç›£æŸ»: è¿½åŠ ãƒ»ã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆã¯ _diff_report.csv ã«ã¾ã¨ã‚ã‚‹ï¼ˆFDA_SMILESã¯ã“ã“ã ã‘ã«å‡ºåŠ›ï¼‰\n","#  - è¿½åŠ è¦ä»¶: FDAç”±æ¥ãƒ‡ãƒ¼ã‚¿ã«ã¯ã€ŒABCB1 Substrateã€åˆ—ã« 1 ã‚’å…¥åŠ›ï¼ˆæ—¢å­˜å€¤ãŒç©ºã®ã¨ãã®ã¿è£œå®Œï¼‰\n","#  - è¿½åŠ è¦ä»¶(é‡ã¿): FDAç”±æ¥ï¼ˆbase+fda / fda_fileï¼‰ã¯ SampleWeight=5.0ã€ãã®ä»–=1.0\n","\n","import os, csv\n","import numpy as np\n","import pandas as pd\n","\n","BASE_CSV   = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles.csv\"   # æ—¢å­˜\n","FDA_CSV    = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/fda_ex_mdr_sub.csv\"\n","OUT_MERGED = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged.csv\"\n","OUT_DIFF   = OUT_MERGED.replace(\".csv\", \"_diff_report.csv\")\n","\n","# --- load ---\n","base = pd.read_csv(BASE_CSV)\n","fda  = pd.read_csv(FDA_CSV)\n","\n","# --- substrateåˆ—ã®åŒå®š/æ•´å‚™ï¼ˆæœ€çµ‚åˆ—åã¯ \"ABCB1 Substrate\" ã«çµ±ä¸€ï¼‰ ---\n","def _norm_key(s: str) -> str:\n","    return str(s).strip().lower().replace(\" \", \"\").replace(\"_\", \"\")\n","\n","sub_col_found = None\n","for c in base.columns:\n","    if _norm_key(c) in {\"abcb1substrate\", \"pgpsubstrate\", \"p-gpsubstrate\", \"substrate\"}:\n","        sub_col_found = c\n","        break\n","\n","# ãƒ™ãƒ¼ã‚¹å´ã«å¯¾è±¡åˆ—ãŒç„¡ã‘ã‚Œã°ç©ºåˆ—ã‚’æ–°è¦ä½œæˆ\n","if sub_col_found is None and \"ABCB1 Substrate\" not in base.columns:\n","    base[\"ABCB1 Substrate\"] = \"\"\n","elif sub_col_found is not None and sub_col_found != \"ABCB1 Substrate\":\n","    # åˆ¥åã§å­˜åœ¨ã™ã‚‹å ´åˆã¯ \"ABCB1 Substrate\" ã«ã‚³ãƒ”ãƒ¼ã—ã¦çµ±ä¸€\n","    base[\"ABCB1 Substrate\"] = base[sub_col_found].astype(object)\n","elif \"ABCB1 Substrate\" in base.columns:\n","    pass\n","else:\n","    base[\"ABCB1 Substrate\"] = \"\"\n","\n","# --- ensure base columns exist ---\n","base_cols = [\n","    \"Drug_name\",\"Chosen_CID\",\"BestAvailableSMILES\",\"SMILES_Source\",\n","    \"CanonicalSMILES_raw\",\"MatchType\",\"Candidates\",\"ABCB1 Substrate\"\n","]\n","for c in base_cols:\n","    if c not in base.columns:\n","        base[c] = \"\"\n","\n","# --- normalize helpers ---\n","def _to_int_or_nan(x):\n","    try:\n","        if pd.isna(x): return np.nan\n","        s = str(x).strip()\n","        if s == \"\": return np.nan\n","        return int(s)\n","    except:\n","        return np.nan\n","\n","def _norm_name(x:str)->str:\n","    s = str(x).strip()\n","    s = \" \".join(s.split())\n","    return s.lower()\n","\n","base[\"Chosen_CID_norm\"] = base[\"Chosen_CID\"].apply(_to_int_or_nan)\n","base[\"Drug_name_norm\"]  = base[\"Drug_name\"].astype(str).map(_norm_name)\n","\n","# FDAå´ æœŸå¾…åˆ—: name, cid, smiles\n","for col in [\"name\",\"cid\",\"smiles\"]:\n","    if col not in fda.columns:\n","        raise RuntimeError(f\"æ·»ä»˜CSVã«å¿…è¦åˆ—ãŒã‚ã‚Šã¾ã›ã‚“: {col}\")\n","\n","fda[\"cid_norm\"]  = fda[\"cid\"].apply(_to_int_or_nan)\n","fda[\"name_norm\"] = fda[\"name\"].astype(str).map(_norm_name)\n","\n","# --- step1: CIDã§ãƒãƒ¼ã‚¸ï¼ˆå·¦å¤–çµåˆ: æ—¢å­˜å„ªå…ˆï¼‰ ---\n","m = base.merge(\n","    fda.rename(columns={\"name\":\"FDA_name\",\"cid\":\"FDA_cid\",\"smiles\":\"FDA_SMILES\"}),\n","    left_on=\"Chosen_CID_norm\", right_on=\"cid_norm\", how=\"left\"\n",")\n","\n","# MergeSource ã®åˆæœŸå€¤ï¼ˆãƒ™ãƒ¼ã‚¹ã«FDAãŒä½•ã‹ã—ã‚‰çµã³ã¤ã„ãŸã‚‰ base+fdaã€ç„¡ã‘ã‚Œã° baseï¼‰\n","m[\"MergeSource\"] = np.where(m[\"FDA_name\"].notna(), \"base+fda\", \"base\")\n","\n","# --- step2: CIDã§çµã³ã¤ã‹ãªã‹ã£ãŸFDAè¡Œã‚’ã€Œåå‰ä¸€è‡´ã€ã§è£œå®Œ/è¿½åŠ  ---\n","linked_fda_cids = set(m[\"cid_norm\"].dropna().astype(int).unique().tolist())\n","\n","base_name_to_rows = {}\n","for i, nm in enumerate(m[\"Drug_name_norm\"].tolist()):\n","    base_name_to_rows.setdefault(nm, []).append(i)\n","\n","extra_rows = []\n","for _, fr in fda.iterrows():\n","    nm = fr[\"name_norm\"]\n","    cidn = fr[\"cid_norm\"]\n","    fda_smiles = fr[\"FDA_SMILES\"] if \"FDA_SMILES\" in fr else (fr[\"smiles\"] if isinstance(fr[\"smiles\"], str) else \"\")\n","    if pd.notna(cidn) and int(cidn) in linked_fda_cids:\n","        continue\n","\n","    if nm in base_name_to_rows:\n","        # æ—¢å­˜è¡Œã«FDAæƒ…å ±ã‚’è£œå®Œï¼ˆåå‰ä¸€è‡´ï¼‰\n","        idxs = base_name_to_rows[nm]\n","        m.loc[idxs, \"FDA_name\"]   = fr[\"name\"]\n","        m.loc[idxs, \"FDA_cid\"]    = fr[\"cid\"]\n","        m.loc[idxs, \"FDA_SMILES\"] = fda_smiles\n","        m.loc[idxs, \"MergeSource\"] = \"base+fda\"\n","        # â˜… FDAç”±æ¥ â†’ ã€ŒABCB1 Substrateã€ãŒç©ºãªã‚‰ 1 ã‚’è£œå®Œ\n","        if \"ABCB1 Substrate\" not in m.columns:\n","            m[\"ABCB1 Substrate\"] = \"\"\n","        empty_mask = m.loc[idxs, \"ABCB1 Substrate\"].astype(str).str.strip().isin([\"\", \"nan\", \"None\", \"NA\"])\n","        m.loc[np.array(idxs)[empty_mask.values], \"ABCB1 Substrate\"] = \"1\"\n","    else:\n","        # æ–°è¦è¿½åŠ ï¼ˆfrom FDAï¼‰\n","        new_row = {\n","            \"Drug_name\": fr[\"name\"],\n","            \"Chosen_CID\": int(fr[\"cid\"]) if pd.notna(cidn) else \"\",\n","            \"BestAvailableSMILES\": fda_smiles,\n","            \"SMILES_Source\": \"fda_file\",\n","            \"CanonicalSMILES_raw\": \"\",\n","            \"MatchType\": \"from_fda\",\n","            \"Candidates\": \"\",\n","            \"Chosen_CID_norm\": cidn,\n","            \"Drug_name_norm\": nm,\n","            \"FDA_name\": fr[\"name\"],\n","            \"FDA_cid\": fr[\"cid\"],\n","            \"FDA_SMILES\": fda_smiles,\n","            \"cid_norm\": cidn,\n","            \"MergeSource\": \"fda_file\",\n","            # â˜… è¿½åŠ è¡Œã¯FDAç”±æ¥ãªã®ã§å¸¸ã« 1\n","            \"ABCB1 Substrate\": \"1\",\n","        }\n","        extra_rows.append(new_row)\n","\n","if extra_rows:\n","    m = pd.concat([m, pd.DataFrame(extra_rows)], ignore_index=True)\n","\n","# --- SMILESä¸ä¸€è‡´å‡¦ç†ï¼šæ—¢å­˜ã‚’å„ªå…ˆã€æœ€çµ‚CSVã«ã¯FDA_SMILESã¯è¼‰ã›ãªã„ï¼ˆdiffã«ã®ã¿å‡ºåŠ›ï¼‰ ---\n","m[\"BestAvailableSMILES\"] = m[\"BestAvailableSMILES\"].astype(str)\n","m[\"FDA_SMILES\"]          = m.get(\"FDA_SMILES\", pd.Series(\"\", index=m.index)).astype(str)\n","\n","# æ—¢å­˜ç©ºï¼†FDAã‚ã‚Š â†’ è£œå®Œï¼ˆSMILES_Sourceã‚‚fda_file_fillã¸ï¼‰\n","need_fill = (m[\"BestAvailableSMILES\"].str.len()==0) & (m[\"FDA_SMILES\"].str.len()>0)\n","m.loc[need_fill, \"BestAvailableSMILES\"] = m.loc[need_fill, \"FDA_SMILES\"]\n","m.loc[need_fill, \"SMILES_Source\"] = m.loc[need_fill, \"SMILES_Source\"].mask(\n","    m.loc[need_fill, \"SMILES_Source\"].astype(str).str.len()==0, \"fda_file_fill\"\n",")\n","# SMILESè£œå®ŒãŒç™ºç”Ÿã—ãŸè¡ŒãŒFDAç”±æ¥ãªã‚‰ Substrate ã‚‚ 1ï¼ˆç©ºã®ã¨ãã®ã¿ï¼‰ã«è£œå®Œ\n","if \"ABCB1 Substrate\" not in m.columns:\n","    m[\"ABCB1 Substrate\"] = \"\"\n","fill_sub_mask = need_fill & m[\"MergeSource\"].isin([\"base+fda\",\"fda_file\"])\n","empty_sub = m[\"ABCB1 Substrate\"].astype(str).str.strip().isin([\"\", \"nan\", \"None\", \"NA\"])\n","m.loc[fill_sub_mask & empty_sub, \"ABCB1 Substrate\"] = \"1\"\n","\n","# è¡çªãƒ•ãƒ©ã‚°ï¼ˆç›£æŸ»ç”¨ï¼‰\n","conflict = (\n","    (m[\"BestAvailableSMILES\"].str.len()>0) &\n","    (m[\"FDA_SMILES\"].str.len()>0) &\n","    (m[\"BestAvailableSMILES\"] != m[\"FDA_SMILES\"])\n",")\n","m[\"SMILES_conflict\"] = np.where(conflict, 1, 0)\n","\n","# === â˜… ã“ã“ã‹ã‚‰ï¼šé‡ã¿åˆ—ã‚’è¿½åŠ ï¼ˆFDAç”±æ¥=5.0ã€ãã®ä»–=1.0ï¼‰ ===\n","m[\"SampleWeight\"] = np.where(m[\"MergeSource\"].isin([\"base+fda\", \"fda_file\"]), 5.0, 1.0)\n","\n","# --- å‡ºåŠ›ã‚«ãƒ©ãƒ ï¼ˆå…ƒCSVã®åˆ—ã‚’ä¿æŒã—ã€MergeSourceã¨SampleWeightã‚’è¿½åŠ ã€‚FDA_SMILESã¯ç›£æŸ»CSVã«ã®ã¿ï¼‰ ---\n","out_cols = [c for c in base_cols if c in m.columns] + [\"MergeSource\", \"SampleWeight\"]  # â˜… SampleWeight è¿½åŠ \n","out = m[out_cols].copy()\n","\n","# å®Œå…¨é‡è¤‡é™¤å»ï¼ˆä¿å®ˆçš„ã«ä¸»è¦3åˆ—ã§ï¼‰\n","out = out.drop_duplicates(subset=[\"Drug_name\",\"Chosen_CID\",\"BestAvailableSMILES\"], keep=\"first\").reset_index(drop=True)\n","\n","# ä¿å­˜\n","out.to_csv(OUT_MERGED, index=False, quoting=csv.QUOTE_MINIMAL, encoding=\"utf-8\")\n","\n","# --- å·®åˆ†ãƒ¬ãƒãƒ¼ãƒˆï¼ˆæ–°è¦è¿½åŠ ãƒ»SMILESã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆï¼‰ ---\n","diff_rows = []\n","# è¿½åŠ ï¼ˆfrom_fdaï¼‰\n","added_mask = (m.get(\"MatchType\",\"\")==\"from_fda\") | (m[\"MergeSource\"]==\"fda_file\")\n","for _, r in m[added_mask].iterrows():\n","    diff_rows.append({\n","        \"type\":\"added_from_fda\",\n","        \"Drug_name\": r.get(\"Drug_name\",\"\"),\n","        \"Chosen_CID\": r.get(\"Chosen_CID\",\"\"),\n","        \"BestAvailableSMILES\": r.get(\"BestAvailableSMILES\",\"\"),\n","        \"FDA_SMILES\": r.get(\"FDA_SMILES\",\"\"),\n","        \"ABCB1_Substrate_out\": r.get(\"ABCB1 Substrate\",\"\"),\n","        \"MergeSource\": r.get(\"MergeSource\",\"\"),\n","        \"SampleWeight\": r.get(\"SampleWeight\",\"\"),\n","    })\n","\n","# SMILESã‚³ãƒ³ãƒ•ãƒªã‚¯ãƒˆ\n","for _, r in m[m[\"SMILES_conflict\"]==1].iterrows():\n","    diff_rows.append({\n","        \"type\":\"smiles_conflict\",\n","        \"Drug_name\": r.get(\"Drug_name\",\"\"),\n","        \"Chosen_CID\": r.get(\"Chosen_CID\",\"\"),\n","        \"BestAvailableSMILES\": r.get(\"BestAvailableSMILES\",\"\"),\n","        \"FDA_SMILES\": r.get(\"FDA_SMILES\",\"\"),\n","        \"ABCB1_Substrate_out\": r.get(\"ABCB1 Substrate\",\"\"),\n","        \"MergeSource\": r.get(\"MergeSource\",\"\"),\n","        \"SampleWeight\": r.get(\"SampleWeight\",\"\"),\n","    })\n","\n","pd.DataFrame(diff_rows).to_csv(OUT_DIFF, index=False, encoding=\"utf-8\")\n","\n","print(f\"âœ… Merged CSV saved: {OUT_MERGED}  (rows={len(out)})\")\n","print(f\"ğŸ“ Diff report    : {OUT_DIFF}   (rows={len(diff_rows)})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A6Vt1hqwQDna","executionInfo":{"status":"ok","timestamp":1760622052750,"user_tz":-540,"elapsed":5323,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"5d641197-d014-4bf2-a6c6-df40f4b00b94"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Merged CSV saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged.csv  (rows=235)\n","ğŸ“ Diff report    : /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged_diff_report.csv   (rows=235)\n"]}]},{"cell_type":"code","source":["# =========================================\n","# å¡©/æ°´å’Œç‰©/æº¶åª’å’Œã‚’ã€ŒåŒä¸€è–¬ç‰©ï¼ˆå¡©ã§ãªã„è¦ªåˆ†å­ï¼‰ã€ã«çµ±åˆï¼ˆå„ªå…ˆè–¬ç‰©å¯¾å¿œ + ABCB1é›†è¨ˆ + Sample_Weightå‡ºåŠ›ï¼‰\n","# =========================================\n","\n","# 1) è¨­å®šï¼ˆçœç•¥éƒ¨ã¯ãã®ã¾ã¾ï¼‰\n","IN_CSV   = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged.csv\"\n","OUT_BASE = IN_CSV.rsplit(\".\",1)[0]\n","OUT_CONS = OUT_BASE + \"_consolidated.csv\"\n","OUT_CHILD= OUT_BASE + \"_children_expanded.csv\"\n","\n","# 2) å®Ÿè£…ï¼ˆçœç•¥éƒ¨ã¯ãã®ã¾ã¾ï¼‰\n","import re, csv, time, random, numpy as np\n","import pandas as pd\n","import requests\n","from typing import Optional, List, Tuple, Dict, Any\n","from functools import lru_cache\n","from rdkit import Chem\n","from rdkit.Chem.MolStandardize import rdMolStandardize as STD\n","\n","# ...ï¼ˆPRIORITY_PAIRS, _norm_name ãªã©æ—¢å­˜ã®å®šç¾©ã¯ãã®ã¾ã¾ï¼‰...\n","\n","# ---- åˆ—åã‚†ã‚Œã‚’å¸å ----\n","def find_col(df: pd.DataFrame, candidates: List[str]) -> Optional[str]:\n","    low = {str(c).strip().lower(): c for c in df.columns}\n","    for name in candidates:\n","        c = low.get(name.strip().lower())\n","        if c: return c\n","    return None\n","\n","# ...ï¼ˆPubChem utils ã¨ RDKit æ­£è¦åŒ–é–¢æ•°ã¯ãã®ã¾ã¾ï¼‰...\n","\n","# ---- ABCB1 Substrate æ­£è¦åŒ–ï¼ˆ0/1/æ¬ æï¼‰----\n","def norm_abcb1(x):\n","    if pd.isna(x): return pd.NA\n","    s = str(x).strip().lower()\n","    if s in {\"1\", \"true\", \"yes\", \"y\"}: return 1\n","    if s in {\"0\", \"false\", \"no\", \"n\"}: return 0\n","    return pd.NA\n","\n","# 3) å…¥åŠ›èª­ã¿è¾¼ã¿ï¼†åˆ—ã®åŒå®š\n","df = pd.read_csv(IN_CSV)\n","\n","col_name  = find_col(df, [\"Drug_name\",\"Drug\",\"Drug Name\"])\n","col_cid   = find_col(df, [\"PubChem_CID\",\"Chosen_CID\",\"CID\"])\n","col_smi   = find_col(df, [\"SMILES\",\"BestAvailableSMILES\",\"CanonicalSMILES\",\"CanonicalSMILES_raw\"])\n","col_abcb1 = find_col(df, [\"ABCB1 Substrate\",\"abcb1 substrate\",\"ABCB1_Substrate\",\"abcb1_substrate\"])\n","# â˜… SampleWeight åˆ—ã®åŒå®šï¼ˆãªã‘ã‚Œã°ä½œæˆã—ã¦ 1.0ï¼‰\n","col_sw_in = find_col(df, [\"SampleWeight\",\"Sample_Weight\",\"sampleweight\"])\n","if col_sw_in is None:\n","    df[\"Sample_Weight\"] = 1.0\n","    col_sw_in = \"Sample_Weight\"\n","else:\n","    # å‡ºåŠ›ã¯åˆ—åã‚’ \"Sample_Weight\" ã«çµ±ä¸€\n","    df[\"Sample_Weight\"] = pd.to_numeric(df[col_sw_in], errors=\"coerce\").fillna(1.0).astype(float).clip(lower=0.0)\n","\n","if not (col_name and col_smi):\n","    raise RuntimeError(f\"å¿…è¦åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: Drug_name/Drug ã¨ SMILESç³»ï¼ˆè¦‹ã¤ã‹ã£ãŸåˆ—: {df.columns.tolist()})\")\n","\n","# ABCB1åˆ—ãŒç„¡ãã¦ã‚‚å‹•ãã‚ˆã†ã«\n","if col_abcb1 is None:\n","    df[\"__ABCB1_tmp__\"] = pd.NA\n","    col_abcb1 = \"__ABCB1_tmp__\"\n","\n","# 4) å­â†’è¦ªã®ãƒãƒƒãƒ”ãƒ³ã‚°ç”Ÿæˆï¼ˆâ˜… å­ã« Sample_Weight ã‚’ä¿æŒï¼‰\n","rows_child: List[Dict[str,Any]] = []\n","for i, r in df.iterrows():\n","    name = str(r[col_name]).strip()\n","    smi  = str(r[col_smi]).strip()\n","    cid  = int(r[col_cid]) if (col_cid and pd.notna(r[col_cid])) else None\n","    if not smi or smi.lower() in (\"nan\",\"none\"):\n","        continue\n","\n","    pkey, psm = parent_key_and_smiles(smi)\n","    if not (pkey and psm):\n","        continue\n","\n","    pcid = None\n","    if LOOKUP_PARENT_CID:\n","        cands = smiles_to_cids(psm); pcid = int(cands[0]) if cands else None\n","\n","    rows_child.append({\n","        \"Child_Name\": name,\n","        \"Child_CID\": cid,\n","        \"Child_SMILES\": smi,\n","        \"Parent_Key\": pkey,\n","        \"Parent_SMILES\": psm,\n","        \"Parent_CID\": pcid,\n","        \"Name_Stripped\": strip_saltish(name),\n","        \"PreferredFlag\": False,\n","        \"ABCB1_Substrate\": norm_abcb1(r[col_abcb1]),\n","        # â˜… ã“ã“ã§å„å­è¡Œã® Sample_Weight ã‚’ä¿æŒï¼ˆæ—¢ã«1.0è£œå®Œæ¸ˆï¼‰\n","        \"Sample_Weight\": float(r[\"Sample_Weight\"])\n","    })\n","\n","    if (i+1) % 50 == 0:\n","        print(f\"[prog] processed {i+1}/{len(df)}\")\n","\n","child_df = pd.DataFrame(rows_child)\n","\n","# 5) è¦ªã¸é›†ç´„ï¼ˆâ˜… Sample_Weight ã¯å­ã®æœ€å¤§å€¤ã‚’æ¡ç”¨ï¼‰\n","cons_rows: List[Dict[str,Any]] = []\n","pref_indices: List[int] = []\n","\n","for pkey, g in child_df.groupby(\"Parent_Key\", dropna=True):\n","    parent_smiles = g[\"Parent_SMILES\"].iloc[0]\n","\n","    # --- ä»£è¡¨å€™è£œã®æ±ºå®šï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ã®ã¾ã¾ï¼‰---\n","    norm_names = g[\"Child_Name\"].astype(str).map(_norm_name)\n","    cid_series = g[\"Child_CID\"]\n","    mask_cid  = cid_series.isin(PRIORITY_CID_SET)\n","    mask_name = norm_names.isin({s.lower() for s in [_norm_name(d[\"name\"]) for d in PRIORITY_PAIRS]})\n","    mask_pref = (mask_cid | mask_name)\n","\n","    if mask_pref.any():\n","        pref_idx = None\n","        for pr in PRIORITY_PAIRS:\n","            cand_mask = (cid_series.eq(pr[\"cid\"])) | (norm_names.eq(_norm_name(pr[\"name\"])))\n","            hit = g.index[cand_mask]\n","            if len(hit) > 0:\n","                pref_idx = int(hit[0]); break\n","        if pref_idx is None: pref_idx = int(g.index[0])\n","        rep_row = child_df.loc[pref_idx]\n","        rep_name = str(rep_row[\"Child_Name\"])\n","        rep_cid  = int(rep_row[\"Child_CID\"]) if pd.notna(rep_row[\"Child_CID\"]) else None\n","        pref_indices.append(pref_idx)\n","    else:\n","        parent_cid_mode = g[\"Parent_CID\"].dropna().astype(int)\n","        rep_cid = parent_cid_mode.mode().iloc[0] if len(parent_cid_mode)>0 else None\n","        rep_name = None\n","        if rep_cid is not None:\n","            t = cid_title(rep_cid);\n","            if t: rep_name = t\n","        if not rep_name:\n","            stripped = g[\"Name_Stripped\"].str.lower().value_counts()\n","            rep_name = stripped.index[0] if len(stripped)>0 else g[\"Child_Name\"].iloc[0]\n","\n","    if \"rep_cid\" not in locals() or rep_cid is None:\n","        parent_cid_mode = g[\"Parent_CID\"].dropna().astype(int)\n","        rep_cid = parent_cid_mode.mode().iloc[0] if len(parent_cid_mode)>0 else None\n","\n","    # --- ABCB1(A=any=1) é›†ç´„ ---\n","    ab = g[\"ABCB1_Substrate\"]\n","    vals = ab[ab.isin([0,1])]\n","    if (vals == 1).any():\n","        parent_abcb1 = 1\n","    elif (vals == 0).any():\n","        parent_abcb1 = 0\n","    else:\n","        parent_abcb1 = pd.NA\n","\n","    # â˜… Sample_Weight é›†ç´„ï¼ˆmaxï¼šFDA=5.0ãŒ1ã¤ã§ã‚‚ã‚ã‚Œã°è¦ªã‚‚5.0ï¼‰\n","    parent_sw = float(g[\"Sample_Weight\"].fillna(1.0).max())\n","\n","    cons_rows.append({\n","        \"Drug_Name\": rep_name,\n","        \"PubChem_CID\": rep_cid,\n","        \"SMILES\": parent_smiles,\n","        \"Parent_Key\": pkey,\n","        \"Children_N\": int(len(g)),\n","        \"Children_Names\": \"; \".join(sorted(set(g[\"Child_Name\"]))),\n","        \"Children_CIDs\": \"; \".join(sorted({str(int(x)) for x in g[\"Child_CID\"].dropna().tolist()})) if g[\"Child_CID\"].notna().any() else \"\",\n","        \"ABCB1 Substrate\": parent_abcb1,\n","        \"Sample_Weight\": parent_sw,  # â˜… è¿½åŠ \n","    })\n","\n","# å„ªå…ˆè¡Œãƒ•ãƒ©ã‚°\n","if len(pref_indices)>0:\n","    child_df.loc[pref_indices, \"PreferredFlag\"] = True\n","\n","# 6) ä¿å­˜ï¼ˆâ˜… å­/è¦ªã¨ã‚‚ã« Sample_Weight ã‚’å«ã‚ã¦å‡ºåŠ›ï¼‰\n","child_cols = [\n","    \"Child_Name\",\"Child_CID\",\"Child_SMILES\",\n","    \"Parent_Key\",\"Parent_SMILES\",\"Parent_CID\",\n","    \"PreferredFlag\",\"ABCB1_Substrate\",\"Name_Stripped\",\n","    \"Sample_Weight\"  # â˜… è¿½åŠ \n","]\n","child_df.to_csv(OUT_CHILD, index=False, encoding=\"utf-8\", quoting=csv.QUOTE_MINIMAL)\n","\n","cons_df = pd.DataFrame(cons_rows, columns=[\n","    \"Drug_Name\",\"PubChem_CID\",\"SMILES\",\"Parent_Key\",\n","    \"Children_N\",\"Children_Names\",\"Children_CIDs\",\n","    \"ABCB1 Substrate\",\"Sample_Weight\"  # â˜… è¿½åŠ \n","]).sort_values([\"Drug_Name\",\"Children_N\"], ascending=[True, False])\n","\n","cons_df.to_csv(OUT_CONS, index=False, encoding=\"utf-8\", quoting=csv.QUOTE_MINIMAL)\n","\n","print(f\"âœ… è¦ªåˆ†å­ã¸çµ±åˆã—ã¦ä¿å­˜: {OUT_CONS}  (rows={len(cons_df)})\")\n","print(f\"   å­å±•é–‹ï¼ˆå„ªå…ˆãƒ•ãƒ©ã‚° + ABCB1ä¿æŒ + Sample_Weightï¼‰: {OUT_CHILD}  (rows={len(child_df)})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4EGYhaaPgTT1","executionInfo":{"status":"ok","timestamp":1760623487259,"user_tz":-540,"elapsed":12354,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"2bd838f8-2b88-4fcb-a2a4-9742ec9c6b1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Fragment: Nc1nc([O-])c2ncn(COCCO)c2n1\n","[14:04:34] New largest fragment: Nc1nc([O-])c2ncn(COCCO)c2n1 (26)\n","[14:04:34] Fragment: [Na+]\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Removed negative charge.\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Fragment: CN(C)C/C=C/C(=O)Nc1cc2c(Nc3ccc(F)c(Cl)c3)ncnc2cc1O[C@H]1CCOC1\n","[14:04:34] New largest fragment: CN(C)C/C=C/C(=O)Nc1cc2c(Nc3ccc(F)c(Cl)c3)ncnc2cc1O[C@H]1CCOC1 (59)\n","[14:04:34] Fragment: O=C(O)/C=C\\C(=O)O\n","[14:04:34] Fragment: O=C(O)/C=C\\C(=O)O\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Fragment: COCCCOc1cc(C[C@@H](C[C@H](N)[C@@H](O)C[C@H](C(=O)NCC(C)(C)C(N)=O)C(C)C)C(C)C)ccc1OC\n","[14:04:34] New largest fragment: COCCCOc1cc(C[C@@H](C[C@H](N)[C@@H](O)C[C@H](C(=O)NCC(C)(C)C(N)=O)C(C)C)C(C)C)ccc1OC (92)\n","[14:04:34] Fragment: COCCCOc1cc(C[C@@H](C[C@H](N)[C@@H](O)C[C@H](C(=O)NCC(C)(C)C(N)=O)C(C)C)C(C)C)ccc1OC\n","[14:04:34] New largest fragment: COCCCOc1cc(C[C@@H](C[C@H](N)[C@@H](O)C[C@H](C(=O)NCC(C)(C)C(N)=O)C(C)C)C(C)C)ccc1OC (92)\n","[14:04:34] Fragment: O=C(O)/C=C/C(=O)O\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Fragment: Cl\n","[14:04:34] New largest fragment: Cl (2)\n","[14:04:34] Fragment: NC12CC3CC(CC(C3)C1)C2\n","[14:04:34] New largest fragment: NC12CC3CC(CC(C3)C1)C2 (28)\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Fragment: Nc1ccc(C(=O)NCC(=O)[O-])cc1\n","[14:04:34] New largest fragment: Nc1ccc(C(=O)NCC(=O)[O-])cc1 (23)\n","[14:04:34] Fragment: [Na+]\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Removed negative charge.\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:34] Running LargestFragmentChooser\n","[14:04:34] Running Normalizer\n","[14:04:34] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:35] New largest fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-] (75)\n","[14:04:35] Fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:35] New largest fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-] (75)\n","[14:04:35] Fragment: [Ca+2]\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Removed negative charge.\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:35] New largest fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-] (75)\n","[14:04:35] Fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:35] New largest fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-] (75)\n","[14:04:35] Fragment: [Ca+2]\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Removed negative charge.\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:35] New largest fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-] (75)\n","[14:04:35] Fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:35] New largest fragment: CC(C)c1c(C(=O)Nc2ccccc2)c(-c2ccccc2)c(-c2ccc(F)cc2)n1CC[C@@H](O)C[C@@H](O)CC(=O)[O-] (75)\n","[14:04:35] Fragment: CC(O)CO\n","[14:04:35] Fragment: [Ca+2]\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Removed negative charge.\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)C(C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)CN(C)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:35] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)C(C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)CN(C)[C@H](C)[C@@H](O)[C@]1(C)O (124)\n","[14:04:35] Fragment: O\n","[14:04:35] Fragment: O\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: Cl\n","[14:04:35] New largest fragment: Cl (2)\n","[14:04:35] Fragment: Cl\n","[14:04:35] New largest fragment: Cl (2)\n","[14:04:35] Fragment: N#Cc1cccc([C@@H](NCC2CC2)c2ccc(F)c(NC(=O)c3cc(C(F)(F)F)nn3-c3cccc(CN)c3)c2)c1\n","[14:04:35] New largest fragment: N#Cc1cccc([C@@H](NCC2CC2)c2ccc(F)c(NC(=O)c3cc(C(F)(F)F)nn3-c3cccc(CN)c3)c2)c1 (67)\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: COc1ccccc1OCCNCC(O)COc1cccc2[nH]c3ccccc3c12\n","[14:04:35] New largest fragment: COc1ccccc1OCCNCC(O)COc1cccc2[nH]c3ccccc3c12 (56)\n","[14:04:35] Fragment: COc1ccccc1OCCNCC(O)COc1cccc2[nH]c3ccccc3c12\n","[14:04:35] New largest fragment: COc1ccccc1OCCNCC(O)COc1cccc2[nH]c3ccccc3c12 (56)\n","[14:04:35] Fragment: O\n","[14:04:35] Fragment: O=P(O)(O)O\n","[14:04:35] Fragment: O=P(O)(O)O\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=CCS[C@H]12)c1csc(N)n1\n","[14:04:35] New largest fragment: CO/N=C(\\C(=O)N[C@@H]1C(=O)N2C(C(=O)[O-])=CCS[C@H]12)c1csc(N)n1 (37)\n","[14:04:35] Fragment: [Na+]\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Removed negative charge.\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: Cl\n","[14:04:35] New largest fragment: Cl (2)\n","[14:04:35] Fragment: Cl\n","[14:04:35] New largest fragment: Cl (2)\n","[14:04:35] Fragment: O=C(O)COCCN1CCN(C(c2ccccc2)c2ccc(Cl)cc2)CC1\n","[14:04:35] New largest fragment: O=C(O)COCCN1CCN(C(c2ccccc2)c2ccc(Cl)cc2)CC1 (52)\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: N\n","[14:04:35] New largest fragment: N (4)\n","[14:04:35] Fragment: N\n","[14:04:35] New largest fragment: N (4)\n","[14:04:35] Fragment: [Cl][Pt][Cl]\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: Br\n","[14:04:35] New largest fragment: Br (2)\n","[14:04:35] Fragment: CN(C)CCCC1(c2ccc(F)cc2)OCc2cc(C#N)ccc21\n","[14:04:35] New largest fragment: CN(C)CCCC1(c2ccc(F)cc2)OCc2cc(C#N)ccc21 (45)\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CN(C)CCCC1(c2ccc(F)cc2)OCc2cc(C#N)ccc21\n","[14:04:35] New largest fragment: CN(C)CCCC1(c2ccc(F)cc2)OCc2cc(C#N)ccc21 (45)\n","[14:04:35] Fragment: Cl\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(OC)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:35] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(OC)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (121)\n","[14:04:35] Fragment: O=C(O)[C@H](O)[C@@H](O)[C@H](O[C@@H]1O[C@H](CO)[C@H](O)[C@H](O)[C@H]1O)[C@H](O)CO\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Fragment: COc1cc(Cc2cnc(N)nc2N)cc(OC)c1OC\n","[14:04:35] New largest fragment: COc1cc(Cc2cnc(N)nc2N)cc(OC)c1OC (39)\n","[14:04:35] Fragment: Cc1cc(NS(=O)(=O)c2ccc(N)cc2)no1\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:35] Running LargestFragmentChooser\n","[14:04:35] Running Normalizer\n","[14:04:35] Running Uncharger\n","[14:04:37] Tautomer enumeration stopped at 974 tautomers: max transforms reached\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: CS(=O)(=O)O\n","[14:04:37] New largest fragment: CS(=O)(=O)O (9)\n","[14:04:37] Fragment: [H]/N=C(\\NC(=O)OCCCCCC)c1ccc(NCc2nc3cc(C(=O)N(CCC(=O)OCC)c4ccccn4)ccc3n2C)cc1\n","[14:04:37] New largest fragment: [H]/N=C(\\NC(=O)OCCCCCC)c1ccc(NCc2nc3cc(C(=O)N(CCC(=O)OCC)c4ccccn4)ccc3n2C)cc1 (87)\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: COC(=O)N[C@H](C(=O)N1CCC[C@H]1c1ncc(-c2ccc(-c3ccc(-c4cnc([C@@H]5CCCN5C(=O)[C@@H](NC(=O)OC)C(C)C)[nH]4)cc3)cc2)[nH]1)C(C)C\n","[14:04:37] New largest fragment: COC(=O)N[C@H](C(=O)N1CCC[C@H]1c1ncc(-c2ccc(-c3ccc(-c4cnc([C@@H]5CCCN5C(=O)[C@@H](NC(=O)OC)C(C)C)[nH]4)cc3)cc2)[nH]1)C(C)C (104)\n","[14:04:37] Fragment: Cl\n","[14:04:37] Fragment: Cl\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl\n","[14:04:37] New largest fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl (29)\n","[14:04:37] Fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl\n","[14:04:37] New largest fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl (29)\n","[14:04:37] Fragment: [Ca+2]\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Removed negative charge.\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: CCNCC\n","[14:04:37] New largest fragment: CCNCC (16)\n","[14:04:37] Fragment: O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl\n","[14:04:37] New largest fragment: O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl (30)\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl\n","[14:04:37] New largest fragment: O=C(O)Cc1ccccc1Nc1c(Cl)cccc1Cl (30)\n","[14:04:37] Fragment: OCCN1CCCC1\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl\n","[14:04:37] New largest fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl (29)\n","[14:04:37] Fragment: [K+]\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Removed negative charge.\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl\n","[14:04:37] New largest fragment: O=C([O-])Cc1ccccc1Nc1c(Cl)cccc1Cl (29)\n","[14:04:37] Fragment: [Na+]\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Removed negative charge.\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: C[C@@H]1CCO[C@H]2Cn3cc(C(=O)NCc4ccc(F)cc4F)c(=O)c([O-])c3C(=O)N12\n","[14:04:37] New largest fragment: C[C@@H]1CCO[C@H]2Cn3cc(C(=O)NCc4ccc(F)cc4F)c(=O)c([O-])c3C(=O)N12 (48)\n","[14:04:37] Fragment: [Na+]\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Removed negative charge.\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: Cl\n","[14:04:37] New largest fragment: Cl (2)\n","[14:04:37] Fragment: NCCc1ccc(O)c(O)c1\n","[14:04:37] New largest fragment: NCCc1ccc(O)c(O)c1 (22)\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Fragment: CCCCc1oc2ccc(NS(C)(=O)=O)cc2c1C(=O)c1ccc(OCCCN(CCCC)CCCC)cc1\n","[14:04:37] New largest fragment: CCCCc1oc2ccc(NS(C)(=O)=O)cc2c1C(=O)c1ccc(OCCCN(CCCC)CCCC)cc1 (83)\n","[14:04:37] Fragment: Cl\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:37] Running LargestFragmentChooser\n","[14:04:37] Running Normalizer\n","[14:04:37] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CN1CCc2nc(C(=O)N[C@@H]3C[C@@H](C(=O)N(C)C)CC[C@@H]3NC(=O)C(=O)Nc3ccc(Cl)cn3)sc2C1\n","[14:04:38] New largest fragment: CN1CCc2nc(C(=O)N[C@@H]3C[C@@H](C(=O)N(C)C)CC[C@@H]3NC(=O)C(=O)Nc3ccc(Cl)cn3)sc2C1 (67)\n","[14:04:38] Fragment: Cc1ccc(S(=O)(=O)O)cc1\n","[14:04:38] Fragment: O\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CN1CCc2nc(C(=O)N[C@@H]3C[C@@H](C(=O)N(C)C)CC[C@@H]3NC(=O)C(=O)Nc3ccc(Cl)cn3)sc2C1\n","[14:04:38] New largest fragment: CN1CCc2nc(C(=O)N[C@@H]3C[C@@H](C(=O)N(C)C)CC[C@@H]3NC(=O)C(=O)Nc3ccc(Cl)cn3)sc2C1 (67)\n","[14:04:38] Fragment: Cc1ccc(S(=O)(=O)O)cc1\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n"]},{"output_type":"stream","name":"stdout","text":["[prog] processed 50/235\n"]},{"output_type":"stream","name":"stderr","text":["[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1)OCCO2\n","[14:04:38] New largest fragment: CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1)OCCO2 (65)\n","[14:04:38] Fragment: CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1)OCCO2\n","[14:04:38] New largest fragment: CCCCCCCC(=O)N[C@H](CN1CCCC1)[C@H](O)c1ccc2c(c1)OCCO2 (65)\n","[14:04:38] Fragment: O=C(O)[C@H](O)[C@@H](O)C(=O)O\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CCCCC1(CCCC)CN(c2ccccc2)c2cc(SC)c(OCC(=O)N[C@@H](C(=O)NCC(=O)O)c3ccccc3)cc2S(=O)(=O)C1\n","[14:04:38] New largest fragment: CCCCC1(CCCC)CN(c2ccccc2)c2cc(SC)c(OCC(=O)N[C@@H](C(=O)NCC(=O)O)c3ccccc3)cc2S(=O)(=O)C1 (93)\n","[14:04:38] Fragment: O\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: Cn1cnc(Cn2c(=O)nc(Nc3cc4cn(C)nc4cc3Cl)n(Cc3cc(F)c(F)cc3F)c2=O)n1\n","[14:04:38] New largest fragment: Cn1cnc(Cn2c(=O)nc(Nc3cc4cn(C)nc4cc3Cl)n(Cc3cc(F)c(F)cc3F)c2=O)n1 (54)\n","[14:04:38] Fragment: O=C(O)/C=C/C(=O)O\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CCCCCCCCCCCCCCCCCC(=O)O\n","[14:04:38] New largest fragment: CCCCCCCCCCCCCCCCCC(=O)O (56)\n","[14:04:38] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2OC(C)=O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:38] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2OC(C)=O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (123)\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CCC(=O)O[C@H]1[C@H](O[C@@H]2[C@@H](C)[C@H](O[C@H]3C[C@@](C)(OC)[C@@H](O)[C@H](C)O3)[C@@H](C)C(=O)O[C@H](CC)[C@@](C)(O)[C@H](O)[C@@H](C)C(=O)[C@H](C)C[C@@]2(C)O)O[C@H](C)C[C@@H]1N(C)C\n","[14:04:38] New largest fragment: CCC(=O)O[C@H]1[C@H](O[C@@H]2[C@@H](C)[C@H](O[C@H]3C[C@@](C)(OC)[C@@H](O)[C@H](C)O3)[C@@H](C)C(=O)O[C@H](CC)[C@@](C)(O)[C@H](O)[C@@H](C)C(=O)[C@H](C)C[C@@]2(C)O)O[C@H](C)C[C@@H]1N(C)C (126)\n","[14:04:38] Fragment: CCCCCCCCCCCCOS(=O)(=O)O\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:38] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (118)\n","[14:04:38] Fragment: O=C(O)[C@H](O)[C@H](O)[C@@H](O)[C@H](O)[C@H](O)CO\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:38] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (118)\n","[14:04:38] Fragment: O=C(O)[C@H](O)[C@@H](O)[C@H](O[C@@H]1O[C@H](CO)[C@H](O)[C@H](O)[C@H]1O)[C@H](O)CO\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CC(=O)N[C@@H](CSC(=O)c1ccccc1O)C(=O)O\n","[14:04:38] New largest fragment: CC(=O)N[C@@H](CSC(=O)c1ccccc1O)C(=O)O (32)\n","[14:04:38] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:38] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (118)\n","[14:04:38] Fragment: O\n","[14:04:38] Fragment: O\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CCCCCCCCCCCCCCCCCC(=O)O\n","[14:04:38] New largest fragment: CCCCCCCCCCCCCCCCCC(=O)O (56)\n","[14:04:38] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:38] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (118)\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CC(=O)N[C@@H](CS)C(=O)O\n","[14:04:38] New largest fragment: CC(=O)N[C@@H](CS)C(=O)O (19)\n","[14:04:38] Fragment: CCC(=O)O[C@H]1[C@H](O[C@@H]2[C@@H](C)[C@H](O[C@H]3C[C@@](C)(OC)[C@@H](O)[C@H](C)O3)[C@@H](C)C(=O)O[C@H](CC)[C@@](C)(O)[C@H](O)[C@@H](C)C(=O)[C@H](C)C[C@@]2(C)O)O[C@H](C)C[C@@H]1N(C)C\n","[14:04:38] New largest fragment: CCC(=O)O[C@H]1[C@H](O[C@@H]2[C@@H](C)[C@H](O[C@H]3C[C@@](C)(OC)[C@@H](O)[C@H](C)O3)[C@@H](C)C(=O)O[C@H](CC)[C@@](C)(O)[C@H](O)[C@@H](C)C(=O)[C@H](C)C[C@@]2(C)O)O[C@H](C)C[C@@H]1N(C)C (126)\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O\n","[14:04:38] New largest fragment: CC[C@H]1OC(=O)[C@H](C)[C@@H](O[C@H]2C[C@@](C)(OC)[C@@H](O)[C@H](C)O2)[C@H](C)[C@@H](O[C@@H]2O[C@H](C)C[C@H](N(C)C)[C@H]2O)[C@](C)(O)C[C@@H](C)C(=O)[C@H](C)[C@@H](O)[C@]1(C)O (118)\n","[14:04:38] Fragment: N#CS\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:38] Running LargestFragmentChooser\n","[14:04:38] Running Normalizer\n","[14:04:38] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Fragment: CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1\n","[14:04:39] New largest fragment: CNCCC(Oc1ccc(C(F)(F)F)cc1)c1ccccc1 (40)\n","[14:04:39] Fragment: Cl\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Fragment: CC(C)n1c(/C=C/[C@H](O)C[C@H](O)CC(=O)[O-])c(-c2ccc(F)cc2)c2ccccc21\n","[14:04:39] New largest fragment: CC(C)n1c(/C=C/[C@H](O)C[C@H](O)CC(=O)[O-])c(-c2ccc(F)cc2)c2ccccc21 (55)\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Removed negative charge.\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Fragment: O=C1NC(c2ccccc2)(c2ccccc2)C(=O)N1COP(=O)([O-])[O-]\n","[14:04:39] New largest fragment: O=C1NC(c2ccccc2)(c2ccccc2)C(=O)N1COP(=O)([O-])[O-] (38)\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Removed negative charge.\n","[14:04:39] Removed negative charge.\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O\n","[14:04:39] New largest fragment: O (3)\n","[14:04:39] Fragment: O=C1NC(c2ccccc2)(c2ccccc2)C(=O)N1COP(=O)([O-])[O-]\n","[14:04:39] New largest fragment: O=C1NC(c2ccccc2)(c2ccccc2)C(=O)N1COP(=O)([O-])[O-] (38)\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Removed negative charge.\n","[14:04:39] Removed negative charge.\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Running LargestFragmentChooser\n","[14:04:39] Fragment: COc1cc(Nc2ncc(F)c(Nc3ccc4c(n3)N(COP(=O)([O-])[O-])C(=O)C(C)(C)O4)n2)cc(OC)c1OC\n","[14:04:39] New largest fragment: COc1cc(Nc2ncc(F)c(Nc3ccc4c(n3)N(COP(=O)([O-])[O-])C(=O)C(C)(C)O4)n2)cc(OC)c1OC (64)\n","[14:04:39] Fragment: O\n","[14:04:39] Fragment: O\n","[14:04:39] Fragment: O\n","[14:04:39] Fragment: O\n","[14:04:39] Fragment: O\n","[14:04:39] Fragment: O\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Fragment: [Na+]\n","[14:04:39] Running Normalizer\n","[14:04:39] Running Uncharger\n","[14:04:39] Removed negative charge.\n","[14:04:39] Removed negative charge.\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: COc1cnc(-n2cnc(C)n2)c2c1c(C(=O)C(=O)N1CCN(C(=O)c3ccccc3)CC1)cn2COP(=O)(O)O\n","[14:04:40] New largest fragment: COc1cnc(-n2cnc(C)n2)c2c1c(C(=O)C(=O)N1CCN(C(=O)c3ccccc3)CC1)cn2COP(=O)(O)O (67)\n","[14:04:40] Fragment: NC(CO)(CO)CO\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: NS(=O)(=O)c1cc(C(=O)O)c(NCc2ccco2)cc1Cl\n","[14:04:40] New largest fragment: NS(=O)(=O)c1cc(C(=O)O)c(NCc2ccco2)cc1Cl (32)\n","[14:04:40] Fragment: OCCNCCO\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n"]},{"output_type":"stream","name":"stdout","text":["[prog] processed 100/235\n"]},{"output_type":"stream","name":"stderr","text":["[14:04:40] Can't kekulize mol.  Unkekulized atoms: 4 32\n","[14:04:40] Can't kekulize mol.  Unkekulized atoms: 4 32\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CCc1nc(C(N)=O)c(Nc2ccc(N3CCC(N4CCN(C)CC4)CC3)c(OC)c2)nc1NC1CCOCC1\n","[14:04:40] New largest fragment: CCc1nc(C(N)=O)c(Nc2ccc(N3CCC(N4CCN(C)CC4)CC3)c(OC)c2)nc1NC1CCOCC1 (84)\n","[14:04:40] Fragment: CCc1nc(C(N)=O)c(Nc2ccc(N3CCC(N4CCN(C)CC4)CC3)c(OC)c2)nc1NC1CCOCC1\n","[14:04:40] New largest fragment: CCc1nc(C(N)=O)c(Nc2ccc(N3CCC(N4CCN(C)CC4)CC3)c(OC)c2)nc1NC1CCOCC1 (84)\n","[14:04:40] Fragment: O=C(O)/C=C/C(=O)O\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Can't kekulize mol.  Unkekulized atoms: 4 32\n","[14:04:40] Can't kekulize mol.  Unkekulized atoms: 4 32\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CC(=O)O\n","[14:04:40] New largest fragment: CC(=O)O (8)\n","[14:04:40] Fragment: CCc1cc2c(cc1CC)CC(NC[C@H](O)c1ccc(O)c3[nH]c(=O)ccc13)C2\n","[14:04:40] New largest fragment: CCc1cc2c(cc1CC)CC(NC[C@H](O)c1ccc(O)c3[nH]c(=O)ccc13)C2 (57)\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CCc1cc2c(cc1CC)CC(NC[C@H](O)c1ccc(O)c3[nH]c(=O)ccc13)C2\n","[14:04:40] New largest fragment: CCc1cc2c(cc1CC)CC(NC[C@H](O)c1ccc(O)c3[nH]c(=O)ccc13)C2 (57)\n","[14:04:40] Fragment: O=C(O)/C=C\\C(=O)O\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CNCC(=O)OCc1cccnc1N(C)C(=O)OC(C)[n+]1cnn(C[C@](O)(c2cc(F)ccc2F)[C@@H](C)c2nc(-c3ccc(C#N)cc3)cs2)c1\n","[14:04:40] New largest fragment: CNCC(=O)OCc1cccnc1N(C)C(=O)OC(C)[n+]1cnn(C[C@](O)(c2cc(F)ccc2F)[C@@H](C)c2nc(-c3ccc(C#N)cc3)cs2)c1 (86)\n","[14:04:40] Fragment: O=S(=O)([O-])O\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CC(C(=O)O)c1cccc(C(=O)c2ccccc2)c1\n","[14:04:40] New largest fragment: CC(C(=O)O)c1cccc(C(=O)c2ccccc2)c1 (33)\n","[14:04:40] Fragment: NCCCC[C@H](N)C(=O)O\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CC(C(=O)[O-])c1cccc(C(=O)c2ccccc2)c1\n","[14:04:40] New largest fragment: CC(C(=O)[O-])c1cccc(C(=O)c2ccccc2)c1 (32)\n","[14:04:40] Fragment: [Na+]\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Removed negative charge.\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Rule applied: Sulfoxide to -S+(O-)-\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CS(=O)(=O)CCNCc1ccc(-c2ccc3ncnc(Nc4ccc(OCc5cccc(F)c5)c(Cl)c4)c3c2)o1\n","[14:04:40] New largest fragment: CS(=O)(=O)CCNCc1ccc(-c2ccc3ncnc(Nc4ccc(OCc5cccc(F)c5)c(Cl)c4)c3c2)o1 (66)\n","[14:04:40] Fragment: Cc1ccc(S(=O)(=O)O)cc1\n","[14:04:40] Fragment: Cc1ccc(S(=O)(=O)O)cc1\n","[14:04:40] Fragment: O\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CC(C)(C#Cc1ccc(-c2ccc(Cl)c3c([N-]S(C)(=O)=O)nn(CC(F)(F)F)c23)c([C@H](Cc2cc(F)cc(F)c2)NC(=O)Cn2nc(C(F)(F)F)c3c2C(F)(F)[C@@H]2C[C@H]32)n1)S(C)(=O)=O\n","[14:04:40] New largest fragment: CC(C)(C#Cc1ccc(-c2ccc(Cl)c3c([N-]S(C)(=O)=O)nn(CC(F)(F)F)c23)c([C@H](Cc2cc(F)cc(F)c2)NC(=O)Cn2nc(C(F)(F)F)c3c2C(F)(F)[C@@H]2C[C@H]32)n1)S(C)(=O)=O (95)\n","[14:04:40] Fragment: [Na+]\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Removed negative charge.\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: COc1cc2nccc(Oc3ccc(NC(=O)NC4CC4)c(Cl)c3)c2cc1C(N)=O\n","[14:04:40] New largest fragment: COc1cc2nccc(Oc3ccc(NC(=O)NC4CC4)c(Cl)c3)c2cc1C(N)=O (49)\n","[14:04:40] Fragment: CS(=O)(=O)O\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CN(C)C(=O)C(CCN1CCC(O)(c2ccc(Cl)cc2)CC1)(c1ccccc1)c1ccccc1\n","[14:04:40] New largest fragment: CN(C)C(=O)C(CCN1CCC(O)(c2ccc(Cl)cc2)CC1)(c1ccccc1)c1ccccc1 (67)\n","[14:04:40] Fragment: Cl\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CC12CC3CC(C)(C1)CC(N)(C3)C2\n","[14:04:40] New largest fragment: CC12CC3CC(C)(C1)CC(N)(C3)C2 (34)\n","[14:04:40] Fragment: Cl\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: CCC(=O)C(CC(C)N(C)C)(c1ccccc1)c1ccccc1\n","[14:04:40] New largest fragment: CCC(=O)C(CC(C)N(C)C)(c1ccccc1)c1ccccc1 (50)\n","[14:04:40] Fragment: Cl\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:40] Running LargestFragmentChooser\n","[14:04:40] Fragment: Cl\n","[14:04:40] New largest fragment: Cl (2)\n","[14:04:40] Fragment: Cl\n","[14:04:40] New largest fragment: Cl (2)\n","[14:04:40] Fragment: O=C1c2c(O)ccc(O)c2C(=O)c2c(NCCNCCO)ccc(NCCNCCO)c21\n","[14:04:40] New largest fragment: O=C1c2c(O)ccc(O)c2C(=O)c2c(NCCNCCO)ccc(NCCNCCO)c21 (60)\n","[14:04:40] Running Normalizer\n","[14:04:40] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Fragment: Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)n4)c3)cc(C(F)(F)F)c2)cn1\n","[14:04:41] New largest fragment: Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)n4)c3)cc(C(F)(F)F)c2)cn1 (61)\n","[14:04:41] Fragment: Cl\n","[14:04:41] Fragment: O\n","[14:04:41] Fragment: O\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Fragment: Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)n4)c3)cc(C(F)(F)F)c2)cn1\n","[14:04:41] New largest fragment: Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)n4)c3)cc(C(F)(F)F)c2)cn1 (61)\n","[14:04:41] Fragment: Cl\n","[14:04:41] Fragment: O\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Fragment: CCCCCCCCCCCCOS(=O)(=O)O\n","[14:04:41] New largest fragment: CCCCCCCCCCCCOS(=O)(=O)O (43)\n","[14:04:41] Fragment: Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)n4)c3)cc(C(F)(F)F)c2)cn1\n","[14:04:41] New largest fragment: Cc1cn(-c2cc(NC(=O)c3ccc(C)c(Nc4nccc(-c5cccnc5)n4)c3)cc(C(F)(F)F)c2)cn1 (61)\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Fragment: CCS(=O)(=O)O\n","[14:04:41] New largest fragment: CCS(=O)(=O)O (12)\n","[14:04:41] Fragment: COC(=O)c1ccc2c(/C(=N/c3ccc(N(C)C(=O)CN4CCN(C)CC4)cc3)c3ccccc3)c(O)[nH]c2c1\n","[14:04:41] New largest fragment: COC(=O)c1ccc2c(/C(=N/c3ccc(N(C)C(=O)CN4CCN(C)CC4)cc3)c3ccccc3)c(O)[nH]c2c1 (73)\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n"]},{"output_type":"stream","name":"stdout","text":["[prog] processed 150/235\n"]},{"output_type":"stream","name":"stderr","text":["[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Fragment: CO[C@@H]1[C@@H](OC(N)=O)[C@@H](O)[C@H](Oc2ccc3c([O-])c(NC(=O)c4ccc(O)c(CC=C(C)C)c4)c(=O)oc3c2C)OC1(C)C\n","[14:04:41] New largest fragment: CO[C@@H]1[C@@H](OC(N)=O)[C@@H](O)[C@H](Oc2ccc3c([O-])c(NC(=O)c4ccc(O)c(CC=C(C)C)c4)c(=O)oc3c2C)OC1(C)C (79)\n","[14:04:41] Fragment: [Na+]\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Removed negative charge.\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:41] Running LargestFragmentChooser\n","[14:04:41] Fragment: C=CC(=O)Nc1cc(Nc2nccc(-c3cn(C)c4ccccc34)n2)c(OC)cc1N(C)CCN(C)C\n","[14:04:41] New largest fragment: C=CC(=O)Nc1cc(Nc2nccc(-c3cn(C)c4ccccc34)n2)c(OC)cc1N(C)CCN(C)C (70)\n","[14:04:41] Fragment: CS(=O)(=O)O\n","[14:04:41] Running Normalizer\n","[14:04:41] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: N[C@@H]1CCCC[C@H]1N\n","[14:04:42] New largest fragment: N[C@@H]1CCCC[C@H]1N (22)\n","[14:04:42] Fragment: O=C([O-])C(=O)[O-]\n","[14:04:42] Fragment: [Pt+2]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)[O-]\n","[14:04:42] New largest fragment: CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)[O-] (40)\n","[14:04:42] Fragment: [K+]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Removed negative charge.\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)[O-]\n","[14:04:42] New largest fragment: CC1(C)S[C@@H]2[C@H](NC(=O)Cc3ccccc3)C(=O)N2[C@H]1C(=O)[O-] (40)\n","[14:04:42] Fragment: [Na+]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Removed negative charge.\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: O=C1[N-]C(=O)C(c2ccccc2)(c2ccccc2)N1\n","[14:04:42] New largest fragment: O=C1[N-]C(=O)C(c2ccccc2)(c2ccccc2)N1 (30)\n","[14:04:42] Fragment: [Na+]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Removed negative charge.\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CC[C@H](C)C(=O)O[C@H]1C[C@H](O)C=C2C=C[C@H](C)[C@H](CC[C@@H](O)C[C@@H](O)CC(=O)[O-])[C@H]21\n","[14:04:42] New largest fragment: CC[C@H](C)C(=O)O[C@H]1C[C@H](O)C=C2C=C[C@H](C)[C@H](CC[C@@H](O)C[C@@H](O)CC(=O)[O-])[C@H]21 (65)\n","[14:04:42] Fragment: [Na+]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Removed negative charge.\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC\n","[14:04:42] New largest fragment: COc1cc2nc(N3CCN(C(=O)c4ccco4)CC3)nc(N)c2cc1OC (49)\n","[14:04:42] Fragment: Cl\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CCN(CC)CCNC(=O)c1ccc(N)cc1\n","[14:04:42] New largest fragment: CCN(CC)CCNC(=O)c1ccc(N)cc1 (38)\n","[14:04:42] Fragment: Cl\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12\n","[14:04:42] New largest fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12 (48)\n","[14:04:42] Fragment: O=C1O[C@H]([C@@H](O)CO)C(O)=C1O\n","[14:04:42] Fragment: O=C1O[C@H]([C@@H](O)CO)C(O)=C1O\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12\n","[14:04:42] New largest fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12 (48)\n","[14:04:42] Fragment: Cl\n","[14:04:42] Fragment: Cl\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12\n","[14:04:42] New largest fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12 (48)\n","[14:04:42] Fragment: Cl\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12\n","[14:04:42] New largest fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12 (48)\n","[14:04:42] Fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12\n","[14:04:42] New largest fragment: C=C[C@H]1CN2CC[C@H]1C[C@H]2[C@H](O)c1ccnc2ccc(OC)cc12 (48)\n","[14:04:42] Fragment: O=S(=O)(O)O\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CNC(=C[N+](=O)[O-])NCCSCc1ccc(CN(C)C)o1\n","[14:04:42] New largest fragment: CNC(=C[N+](=O)[O-])NCCSCc1ccc(CN(C)C)o1 (43)\n","[14:04:42] Fragment: O=C([O-])CC(O)(CC(=O)[O-])C(=O)[O-]\n","[14:04:42] Fragment: [Bi+3]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CN/C(=C\\[N+](=O)[O-])NCCSCc1ccc(CN(C)C)o1\n","[14:04:42] New largest fragment: CN/C(=C\\[N+](=O)[O-])NCCSCc1ccc(CN(C)C)o1 (43)\n","[14:04:42] Fragment: Cl\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: COc1ccccc1OCC(O)CN1CCN(CC(=O)Nc2c(C)cccc2C)CC1\n","[14:04:42] New largest fragment: COc1ccccc1OCC(O)CN1CCN(CC(=O)Nc2c(C)cccc2C)CC1 (64)\n","[14:04:42] Fragment: Cl\n","[14:04:42] Fragment: Cl\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CNC(=O)c1cc(Oc2ccc(NC(=O)Nc3ccc(Cl)c(C(F)(F)F)c3)c(F)c2)ccn1\n","[14:04:42] New largest fragment: CNC(=O)c1cc(Oc2ccc(NC(=O)Nc3ccc(Cl)c(C(F)(F)F)c3)c(F)c2)ccn1 (48)\n","[14:04:42] Fragment: O\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Running LargestFragmentChooser\n","[14:04:42] Fragment: CO[C@H]1/C=C/O[C@@]2(C)Oc3c(C)c(O)c4c(O)c(c(/C=N/N5CCN(C)CC5)c([O-])c4c3C2=O)NC(=O)/C(C)=C\\C=C\\[C@H](C)[C@H](O)[C@@H](C)[C@@H](O)[C@@H](C)[C@H](OC(C)=O)[C@@H]1C\n","[14:04:42] New largest fragment: CO[C@H]1/C=C/O[C@@]2(C)Oc3c(C)c(O)c4c(O)c(c(/C=N/N5CCN(C)CC5)c([O-])c4c3C2=O)NC(=O)/C(C)=C\\C=C\\[C@H](C)[C@H](O)[C@@H](C)[C@@H](O)[C@@H](C)[C@H](OC(C)=O)[C@@H]1C (116)\n","[14:04:42] Fragment: [Na+]\n","[14:04:42] Running Normalizer\n","[14:04:42] Running Uncharger\n","[14:04:42] Removed negative charge.\n","[14:04:43] Tautomer enumeration stopped at 376 tautomers: max transforms reached\n","[14:04:43] Running LargestFragmentChooser\n","[14:04:43] Running Normalizer\n","[14:04:43] Running Uncharger\n","[14:04:43] Tautomer enumeration stopped at 376 tautomers: max transforms reached\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Tautomer enumeration stopped at 289 tautomers: max transforms reached\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Fragment: CC(C)c1nc(N(C)S(C)(=O)=O)nc(-c2ccc(F)cc2)c1/C=C/[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:44] New largest fragment: CC(C)c1nc(N(C)S(C)(=O)=O)nc(-c2ccc(F)cc2)c1/C=C/[C@@H](O)C[C@@H](O)CC(=O)[O-] (60)\n","[14:04:44] Fragment: CC(C)c1nc(N(C)S(C)(=O)=O)nc(-c2ccc(F)cc2)c1/C=C/[C@@H](O)C[C@@H](O)CC(=O)[O-]\n","[14:04:44] New largest fragment: CC(C)c1nc(N(C)S(C)(=O)=O)nc(-c2ccc(F)cc2)c1/C=C/[C@@H](O)C[C@@H](O)CC(=O)[O-] (60)\n","[14:04:44] Fragment: [Ca+2]\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Removed negative charge.\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n","[14:04:44] Running LargestFragmentChooser\n","[14:04:44] Running Normalizer\n","[14:04:44] Running Uncharger\n"]},{"output_type":"stream","name":"stdout","text":["[prog] processed 200/235\n"]},{"output_type":"stream","name":"stderr","text":["[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Fragment: CC(C)(C)NC(=O)[C@@H]1C[C@@H]2CCCC[C@@H]2CN1C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)[C@H](CC(N)=O)NC(=O)c1ccc2ccccc2n1\n","[14:04:45] New largest fragment: CC(C)(C)NC(=O)[C@@H]1C[C@@H]2CCCC[C@@H]2CN1C[C@@H](O)[C@H](Cc1ccccc1)NC(=O)[C@H](CC(N)=O)NC(=O)c1ccc2ccccc2n1 (99)\n","[14:04:45] Fragment: CS(=O)(=O)O\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Fragment: COc1ccc2c(O[C@@H]3C[C@H]4C(=O)N[C@]5(C(=O)[N-]S(=O)(=O)C6CC6)C[C@H]5/C=C\\CCCCN(C)C(=O)[C@@H]4C3)cc(-c3nc(C(C)C)cs3)nc2c1C\n","[14:04:45] New largest fragment: COc1ccc2c(O[C@@H]3C[C@H]4C(=O)N[C@]5(C(=O)[N-]S(=O)(=O)C6CC6)C[C@H]5/C=C\\CCCCN(C)C(=O)[C@@H]4C3)cc(-c3nc(C(C)C)cs3)nc2c1C (98)\n","[14:04:45] Fragment: [Na+]\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Removed negative charge.\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Fragment: NS(=O)(=O)c1cc(C(=O)[O-])c(NCc2ccco2)cc1Cl\n","[14:04:45] New largest fragment: NS(=O)(=O)c1cc(C(=O)[O-])c(NCc2ccco2)cc1Cl (31)\n","[14:04:45] Fragment: [Na+]\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Removed negative charge.\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Fragment: O=C1OC(c2ccc(O)c(S(=O)(=O)[O-])c2)(c2ccc(O)c(S(=O)(=O)[O-])c2)c2c(Br)c(Br)c(Br)c(Br)c21\n","[14:04:45] New largest fragment: O=C1OC(c2ccc(O)c(S(=O)(=O)[O-])c2)(c2ccc(O)c(S(=O)(=O)[O-])c2)c2c(Br)c(Br)c(Br)c(Br)c21 (44)\n","[14:04:45] Fragment: [Na+]\n","[14:04:45] Fragment: [Na+]\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Removed negative charge.\n","[14:04:45] Removed negative charge.\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Fragment: Br\n","[14:04:45] New largest fragment: Br (2)\n","[14:04:45] Fragment: CCN(c1cc(-c2ccc(CN3CCOCC3)cc2)cc(C(=O)NCc2c(C)cc(C)[nH]c2=O)c1C)C1CCOCC1\n","[14:04:45] New largest fragment: CCN(c1cc(-c2ccc(CN3CCOCC3)cc2)cc(C(=O)NCc2c(C)cc(C)[nH]c2=O)c1C)C1CCOCC1 (86)\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:45] Running LargestFragmentChooser\n","[14:04:45] Running Normalizer\n","[14:04:45] Running Uncharger\n","[14:04:46] Tautomer enumeration stopped at 336 tautomers: max transforms reached\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Fragment: CC(C)OC(=O)[C@H](C)N[P@](=O)(CO[C@H](C)Cn1cnc2c(N)ncnc21)Oc1ccccc1\n","[14:04:46] New largest fragment: CC(C)OC(=O)[C@H](C)N[P@](=O)(CO[C@H](C)Cn1cnc2c(N)ncnc21)Oc1ccccc1 (62)\n","[14:04:46] Fragment: CC(C)OC(=O)[C@H](C)N[P@](=O)(CO[C@H](C)Cn1cnc2c(N)ncnc21)Oc1ccccc1\n","[14:04:46] New largest fragment: CC(C)OC(=O)[C@H](C)N[P@](=O)(CO[C@H](C)Cn1cnc2c(N)ncnc21)Oc1ccccc1 (62)\n","[14:04:46] Fragment: O=C(O)/C=C/C(=O)O\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Fragment: CC[C@@]1(O)C(=O)OCc2c1cc1n(c2=O)Cc2cc3c(CN(C)C)c(O)ccc3nc2-1\n","[14:04:46] New largest fragment: CC[C@@]1(O)C(=O)OCc2c1cc1n(c2=O)Cc2cc3c(CN(C)C)c(O)ccc3nc2-1 (54)\n","[14:04:46] Fragment: Cl\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Fragment: COc1ccc(CCN(C)CCCC(C#N)(c2ccc(OC)c(OC)c2)C(C)C)cc1OC\n","[14:04:46] New largest fragment: COc1ccc(CCN(C)CCCC(C#N)(c2ccc(OC)c(OC)c2)C(C)C)cc1OC (71)\n","[14:04:46] Fragment: Cl\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n","[14:04:46] Running LargestFragmentChooser\n","[14:04:46] Running Normalizer\n","[14:04:46] Running Uncharger\n"]},{"output_type":"stream","name":"stdout","text":["âœ… è¦ªåˆ†å­ã¸çµ±åˆã—ã¦ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged_consolidated.csv  (rows=148)\n","   å­å±•é–‹ï¼ˆå„ªå…ˆãƒ•ãƒ©ã‚° + ABCB1ä¿æŒ + Sample_Weightï¼‰: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged_children_expanded.csv  (rows=235)\n"]}]},{"cell_type":"code","source":["# === Check presence of specific PubChem CIDs in a CSV column ===\n","# Target file/column:\n","CSV_PATH = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged_consolidated.csv\"\n","CID_COL  = \"PubChem_CID\"\n","\n","# CIDs to check (as provided)\n","TARGET_CIDS = [3348, 3955, 2724385, 10315094, 68770, 13342, 441074]\n","\n","import pandas as pd\n","import numpy as np\n","\n","# --- load ---\n","df = pd.read_csv(CSV_PATH)\n","\n","# --- safety: column existence ---\n","if CID_COL not in df.columns:\n","    raise RuntimeError(f\"åˆ— '{CID_COL}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­˜åœ¨åˆ—: {list(df.columns)}\")\n","\n","# --- normalize the PubChem_CID column to a comparable set (both int and str) ---\n","# 1) æ•°å€¤åŒ–ã§ãã‚‹ã‚‚ã®ã¯æ•°å€¤ï¼ˆInt64ï¼‰ã«ã€ã§ããªã„ã‚‚ã®ã¯NaN\n","cid_num = pd.to_numeric(df[CID_COL], errors=\"coerce\")\n","# 2) æ•°å€¤ã¨ã—ã¦ã®é›†åˆï¼ˆæ¬ æé™¤å¤–ï¼‰\n","cid_int_set = set(int(x) for x in cid_num.dropna().astype(\"int64\").tolist())\n","# 3) æ–‡å­—åˆ—ã¨ã—ã¦ã®é›†åˆï¼ˆå‰å¾Œç©ºç™½å‰Šé™¤ãƒ»å°æ–‡å­—åŒ–ï¼‰\n","cid_str_set = set(str(x).strip().lower() for x in df[CID_COL].astype(str).tolist())\n","\n","def present(cid):\n","    # æ•°å€¤ä¸€è‡´ or æ–‡å­—åˆ—ä¸€è‡´ï¼ˆ\"3348\"ã®ã‚ˆã†ãªã‚±ãƒ¼ã‚¹ï¼‰\n","    return (cid in cid_int_set) or (str(cid).strip().lower() in cid_str_set)\n","\n","# --- report ---\n","print(f\"File: {CSV_PATH}\")\n","print(f\"Rows: {len(df)}  | Unique {CID_COL} (numeric): {len(cid_int_set)}\")\n","\n","results = []\n","for cid in TARGET_CIDS:\n","    is_present = present(cid)\n","    results.append((cid, is_present))\n","    print(f\"CID {cid}: {'FOUND' if is_present else 'NOT FOUND'}\")\n","\n","# è¿½åŠ : è¦‹ã¤ã‹ã£ãŸè¡Œç•ªå·ï¼ˆä¸Šä½æ•°ä»¶ã®ã¿è¡¨ç¤ºï¼‰\n","show_examples = True\n","if show_examples:\n","    for cid, ok in results:\n","        if ok:\n","            mask = (pd.to_numeric(df[CID_COL], errors=\"coerce\")==cid) | \\\n","                   (df[CID_COL].astype(str).str.strip().str.lower()==str(cid).strip().lower())\n","            idxs = df.index[mask].tolist()\n","            print(f\"  -> indices for CID {cid}: {idxs[:10]}{' ...' if len(idxs)>10 else ''}\")\n","\n","# ã‚ªãƒ—ã‚·ãƒ§ãƒ³: ã‚µãƒãƒªãƒ¼ã‚’DataFrameåŒ–ï¼ˆå¿…è¦ãªã‚‰ä¿å­˜ã—ã¦ãã ã•ã„ï¼‰\n","summary = pd.DataFrame(results, columns=[\"CID\", \"present\"])\n","# summary.to_csv(CSV_PATH.replace(\".csv\", \"_cid_check_summary.csv\"), index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gPZbgOVpwu7q","executionInfo":{"status":"ok","timestamp":1760623522354,"user_tz":-540,"elapsed":22,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"05deffa4-962d-471e-8c14-1a8b7e6a6ed4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["File: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged_consolidated.csv\n","Rows: 148  | Unique PubChem_CID (numeric): 124\n","CID 3348: FOUND\n","CID 3955: FOUND\n","CID 2724385: FOUND\n","CID 10315094: FOUND\n","CID 68770: FOUND\n","CID 13342: FOUND\n","CID 441074: FOUND\n","  -> indices for CID 3348: [46]\n","  -> indices for CID 3955: [66]\n","  -> indices for CID 2724385: [35]\n","  -> indices for CID 10315094: [77]\n","  -> indices for CID 68770: [105]\n","  -> indices for CID 13342: [114]\n","  -> indices for CID 441074: [94]\n"]}]},{"cell_type":"code","source":["# ============================\n","# KEGG + AID â†’ master ç”Ÿæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ\n","#  - å‡ºåŠ›ã®åˆ—é †ã¯ã‚¹ã‚¯ãƒªãƒ—ãƒˆå†…ã§å›ºå®šï¼ˆãƒ†ãƒ³ãƒ—ãƒ¬ä¾å­˜ãªã—ï¼‰\n","#  - ãƒ©ãƒ™ãƒ«: KEGGæœ€å„ªå…ˆ (ABCB1 Substrate=1) / AIDã¯å¼±è£œå®Œ\n","#  - SampleWeight: KEGGã®å€¤ > AIDã®å€¤ > æ—¢å®šï¼ˆAIDã®ã¿æ—¢å®š=0.7ã€æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯=1.0ï¼‰\n","#  - AIDã®SampleWeightåˆ—ã‚’å¼•ãç¶™ãï¼ˆç„¡ã„å ´åˆã¯AIDè¡Œã¯0.7ã§è£œå®Œï¼‰\n","#  - â˜… yåˆ—: Substrate_kegg ãŒã‚ã‚Œã°ãã‚Œã‚’ã€ç„¡ã‘ã‚Œã° Substrate_aid ã‚’è»¢è¨˜\n","# ============================\n","\n","import sys, subprocess, pandas as pd, numpy as np\n","\n","# ===== å…¥å‡ºåŠ›ãƒ‘ã‚¹ =====\n","FILE1_KEGG = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/kegg_pubchem_smiles_merged_consolidated.csv\"\n","FILE2_AID  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/AID_1346986_1346987_labels_fold4.csv\"\n","FILE3_OUT  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/integrated_labels_master.csv\"\n","\n","# ===== å›ºå®šã®å‡ºåŠ›åˆ—é † =====\n","OUTPUT_COLS = [\n","    \"join_key\",\n","    \"CID\",\"SMILES_aid\",\"dlogAC50\",\n","    \"PubChem_CID\",\"SMILES_kegg\",\"Drug_name\",\n","    \"Substrate_aid\",\"Substrate_kegg\",\n","    \"tier\",\"y\",\"weight\",\"from_AID\",\"from_KEGG\",\n","    \"SampleWeight\"\n","]\n","\n","# ===== ã‚ªãƒ—ã‚·ãƒ§ãƒ³ =====\n","AID_SAMPLE_WEIGHT_DEFAULT = 0.7\n","GLOBAL_SAMPLE_WEIGHT_FALLBACK = 1.0\n","WEAK_WEIGHT = 1.0\n","AID_NEG_COUNTS_AS_NEG = False  # tier/weightç®—å‡ºã«ã®ã¿å½±éŸ¿ï¼ˆyã®å®šç¾©ã«ã¯å½±éŸ¿ã—ã¾ã›ã‚“ï¼‰\n","\n","# ===== RDKitï¼ˆã‚ã‚Œã°ä½¿ã†ï¼ç„¡ã‘ã‚Œã°ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰ =====\n","HAS_RDKIT = False\n","try:\n","    from rdkit import Chem, RDLogger\n","    HAS_RDKIT = True\n","except Exception:\n","    for pkg in (\"rdkit\", \"rdkit-pypi\"):\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n","            from rdkit import Chem, RDLogger\n","            HAS_RDKIT = True\n","            break\n","        except Exception:\n","            pass\n","if HAS_RDKIT:\n","    RDLogger.DisableLog('rdApp.*')\n","\n","def safe_str_strip(s):\n","    if pd.isna(s): return \"\"\n","    s = str(s).strip()\n","    return \"\" if s.lower() in {\"nan\",\"none\",\"null\"} else s\n","\n","def smiles_to_ikey1(smiles: str) -> str:\n","    if not HAS_RDKIT or not smiles: return \"\"\n","    try:\n","        m = Chem.MolFromSmiles(smiles)\n","        if m is None: return \"\"\n","        ik = Chem.inchi.MolToInchiKey(m)\n","        return ik.split(\"-\")[0] if ik else \"\"\n","    except Exception:\n","        return \"\"\n","\n","def norm_label_aid_weak(x):\n","    if pd.isna(x): return np.nan\n","    try:\n","        v = int(x); return v if v in (0,1) else np.nan\n","    except Exception:\n","        return np.nan\n","\n","def norm_label_kegg_strong(x):\n","    if pd.isna(x): return np.nan\n","    s = str(x).strip().lower()\n","    return 1 if s in {\"1\",\"true\",\"yes\",\"y\",\"pos\",\"positive\",\"substrate\"} else np.nan\n","\n","def make_join_key(df, cid_col, smiles_col, ikey_col):\n","    keys = []\n","    iks = df[ikey_col] if ikey_col in df.columns else [\"\" for _ in range(len(df))]\n","    smis = df[smiles_col] if smiles_col in df.columns else [\"\" for _ in range(len(df))]\n","    cids = df[cid_col] if cid_col in df.columns else [np.nan for _ in range(len(df))]\n","    for ik, smi, cid in zip(iks, smis, cids):\n","        if isinstance(ik, str) and ik:\n","            keys.append(f\"IK:{ik}\")\n","        elif isinstance(smi, str) and smi:\n","            keys.append(f\"SMI:{smi}\")\n","        else:\n","            keys.append(f\"CID:{cid}\" if pd.notna(cid) else \"\")\n","    return keys\n","\n","# ===== 1) èª­ã¿è¾¼ã¿ =====\n","kegg = pd.read_csv(FILE1_KEGG)\n","aid  = pd.read_csv(FILE2_AID)\n","\n","# ===== 2) æ­£è¦åŒ–ï¼ˆAIDï¼‰ =====\n","req_aid = [\"CID\",\"SMILES\",\"Substrate\"]\n","missing = [c for c in req_aid if c not in aid.columns]\n","if missing:\n","    raise ValueError(f\"AIDã«å¿…é ˆåˆ—ãŒä¸è¶³: {missing}\")\n","\n","aid = aid.copy()\n","aid[\"CID\"] = pd.to_numeric(aid[\"CID\"], errors=\"coerce\").astype(\"Int64\")\n","aid[\"SMILES\"] = aid[\"SMILES\"].apply(safe_str_strip)\n","aid[\"dlogAC50\"] = pd.to_numeric(aid.get(\"dlogAC50\", np.nan), errors=\"coerce\")\n","aid[\"Substrate_aid\"] = aid[\"Substrate\"].apply(norm_label_aid_weak)\n","\n","# AIDå´ SampleWeight\n","if \"SampleWeight\" in aid.columns:\n","    aid[\"SampleWeight_AID\"] = pd.to_numeric(aid[\"SampleWeight\"], errors=\"coerce\")\n","else:\n","    aid[\"SampleWeight_AID\"] = np.nan\n","aid[\"SampleWeight_AID\"] = aid[\"SampleWeight_AID\"].fillna(AID_SAMPLE_WEIGHT_DEFAULT).astype(float).clip(lower=0.0)\n","\n","# ===== 3) æ­£è¦åŒ–ï¼ˆKEGGï¼‰ =====\n","if \"PubChem_CID\" not in kegg.columns or \"SMILES\" not in kegg.columns:\n","    raise ValueError(\"KEGGã«å¿…é ˆåˆ— PubChem_CID / SMILES ãŒã‚ã‚Šã¾ã›ã‚“\")\n","\n","# ABCB1 Substrate åˆ—ã®æ¢ç´¢\n","label_col = None\n","for c in kegg.columns:\n","    if c.strip().lower() in {\"abcb1 substrate\",\"abcb1_substrate\",\"abcb1substrate\"}:\n","        label_col = c; break\n","\n","kegg = kegg.copy()\n","kegg[\"PubChem_CID\"] = pd.to_numeric(kegg[\"PubChem_CID\"], errors=\"coerce\").astype(\"Int64\")\n","kegg[\"SMILES\"] = kegg[\"SMILES\"].apply(safe_str_strip)\n","kegg[\"Drug_name\"] = kegg[\"Drug_name\"].apply(safe_str_strip) if \"Drug_name\" in kegg.columns else \"\"\n","kegg[\"Substrate_kegg\"] = kegg[label_col].apply(norm_label_kegg_strong) if label_col else np.nan\n","\n","# KEGGã®SampleWeightï¼ˆã‚ã‚Œã°å°Šé‡ã€ãªã‘ã‚Œã°1.0ï¼‰\n","sw_in = None\n","for c in kegg.columns:\n","    if c.strip().lower() in {\"sampleweight\",\"sample_weight\"}:\n","        sw_in = c; break\n","kegg[\"SampleWeight\"] = (\n","    pd.to_numeric(kegg[sw_in], errors=\"coerce\").fillna(1.0).astype(float).clip(lower=0.0)\n","    if sw_in else 1.0\n",")\n","\n","# ===== 4) ã‚­ãƒ¼ç”Ÿæˆï¼ˆIKâ†’SMILESâ†’CID ã®å„ªå…ˆé †ï¼‰ =====\n","aid[\"ikey1\"]  = aid[\"SMILES\"].apply(smiles_to_ikey1) if HAS_RDKIT else \"\"\n","kegg[\"ikey1\"] = kegg[\"SMILES\"].apply(smiles_to_ikey1) if HAS_RDKIT else \"\"\n","\n","aid[\"join_key\"]  = make_join_key(aid,  \"CID\",         \"SMILES\", \"ikey1\")\n","kegg[\"join_key\"] = make_join_key(kegg, \"PubChem_CID\", \"SMILES\", \"ikey1\")\n","\n","aid  = aid[aid[\"join_key\"]!=\"\"].copy()\n","kegg = kegg[kegg[\"join_key\"]!=\"\"].copy()\n","\n","# é‡è¤‡æ’é™¤\n","aid_u  = aid.sort_values(\"join_key\").drop_duplicates(subset=[\"join_key\"], keep=\"first\")\n","kegg_u = kegg.sort_values(\"join_key\").drop_duplicates(subset=[\"join_key\"], keep=\"first\")\n","\n","# ===== 5) ãƒãƒ¼ã‚¸ï¼ˆouterï¼‰ =====\n","master = pd.merge(\n","    aid_u[[\"join_key\",\"CID\",\"SMILES\",\"dlogAC50\",\"Substrate_aid\",\"SampleWeight_AID\"]],\n","    kegg_u[[\"join_key\",\"PubChem_CID\",\"SMILES\",\"Drug_name\",\"Substrate_kegg\",\"SampleWeight\"]],\n","    on=\"join_key\", how=\"outer\", suffixes=(\"_aid\",\"_kegg\")\n",")\n","\n","# ===== 6) tierï¼ˆå‚è€ƒæƒ…å ±ï¼‰ =====\n","def decide_tier(row):\n","    s_kegg = row[\"Substrate_kegg\"]  # 1 or NaN\n","    s_aid  = row[\"Substrate_aid\"]   # 0/1/NaN\n","    if pd.notna(s_kegg) and int(s_kegg)==1:\n","        return \"kegg_pos\"\n","    if pd.notna(s_aid) and int(s_aid)==1:\n","        return \"aid_weak_pos\"\n","    if pd.notna(s_aid) and int(s_aid)==0:\n","        return \"aid_weak_neg\"\n","    return \"unknown\"\n","\n","master[\"tier\"] = master.apply(decide_tier, axis=1)\n","\n","# ===== â˜… 7) y ã®å®šç¾©ï¼ˆã”æŒ‡å®šä»•æ§˜ï¼‰ =====\n","# Substrate_kegg ã«å€¤ãŒã‚ã‚Œã°ãã‚Œã‚’ã€æ¬ æãªã‚‰ Substrate_aid ã‚’ä½¿ã†ï¼ˆä¸¡æ–¹æ¬ æãªã‚‰ y ã‚‚æ¬ æï¼‰\n","y_raw = master[\"Substrate_kegg\"].where(master[\"Substrate_kegg\"].notna(), master[\"Substrate_aid\"])\n","master[\"y\"] = pd.to_numeric(y_raw, errors=\"coerce\").astype(\"Int64\")\n","\n","# ===== 8) weight/tagsï¼ˆtierãƒ™ãƒ¼ã‚¹ï¼šyå®šç¾©ã¨ã¯ç‹¬ç«‹ï¼‰ =====\n","def tier_to_weight(t):\n","    if t == \"kegg_pos\": return 1.0\n","    if t.startswith(\"aid_weak\"): return WEAK_WEIGHT\n","    return np.nan\n","\n","master[\"weight\"] = master[\"tier\"].map(tier_to_weight)\n","master[\"from_AID\"]  = master[\"Substrate_aid\"].notna().astype(int)\n","master[\"from_KEGG\"] = master[\"Substrate_kegg\"].notna().astype(int)\n","\n","# ===== 9) SampleWeight ã®æœ€çµ‚ç¢ºå®š =====\n","#   å„ªå…ˆåº¦: KEGG > AID > æœ€çµ‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n","master[\"SampleWeight\"] = pd.to_numeric(master.get(\"SampleWeight\", np.nan), errors=\"coerce\")\n","master[\"SampleWeight\"] = np.where(\n","    master[\"SampleWeight\"].notna(), master[\"SampleWeight\"], master.get(\"SampleWeight_AID\", np.nan)\n",")\n","master[\"SampleWeight\"] = master[\"SampleWeight\"].fillna(GLOBAL_SAMPLE_WEIGHT_FALLBACK).astype(float).clip(lower=0.0)\n","\n","# ===== 10) å‡ºåŠ›åˆ—ã®å›ºå®š =====\n","for c in OUTPUT_COLS:\n","    if c not in master.columns:\n","        master[c] = np.nan\n","\n","out = master[OUTPUT_COLS].copy()\n","out.to_csv(FILE3_OUT, index=False)\n","\n","print(\"âœ… çµ±åˆå®Œäº† â†’ ä¿å­˜:\", FILE3_OUT)\n","print(\"è¡Œæ•°/åˆ—æ•°:\", out.shape)\n","print(\"tierå†…è¨³:\\n\", out[\"tier\"].value_counts(dropna=False))\n","print(\"yé›†è¨ˆ:\\n\", out[\"y\"].value_counts(dropna=False))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AYRXB8_BTvIk","executionInfo":{"status":"ok","timestamp":1760677676802,"user_tz":-540,"elapsed":7542,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"7a2416c0-cd55-4996-aefc-da0faf2079b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… çµ±åˆå®Œäº† â†’ ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/integrated_labels_master.csv\n","è¡Œæ•°/åˆ—æ•°: (7397, 15)\n","tierå†…è¨³:\n"," tier\n","aid_weak_neg    7097\n","aid_weak_pos     212\n","kegg_pos          57\n","unknown           31\n","Name: count, dtype: int64\n","yé›†è¨ˆ:\n"," y\n","0       7097\n","1        269\n","<NA>      31\n","Name: count, dtype: Int64\n"]}]},{"cell_type":"code","source":["# ==========================================\n","# Murckoã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰åˆ†å‰²ï¼ˆå¤–éƒ¨20%ï¼‰ï¼‹è¿‘ç¸é®æ–­\n","# ã‹ã¤ å¤–éƒ¨ã« strong_pos=15, weak_pos=5 ã‚’ç¢ºä¿ï¼ˆå¯èƒ½ãªé™ã‚Šå³å®ˆï¼‰\n","# å„ªå…ˆè–¬ç‰©ã¯å¿…ãšå­¦ç¿’ã¸å›ºå®š\n","# å…¥åŠ› : integrated_labels_master.csv\n","# å‡ºåŠ› :\n","#   train_split.csv\n","#   external10_union.csv        â† æ—¢å­˜åã‚’è¸è¥²ï¼ˆä¸­èº«ã¯20%ï¼‰\n","#   external10_kegg_only.csv\n","#   split_summary.txt\n","#   ï¼ˆâ˜… ã™ã¹ã¦ã®å‡ºåŠ›ã« SampleWeight ã‚’æ®‹ã™ï¼‰\n","# ==========================================\n","\n","import sys, subprocess, pandas as pd, numpy as np, math, io, re\n","\n","# RDKit\n","try:\n","    from rdkit import Chem\n","    from rdkit.Chem.Scaffolds import MurckoScaffold\n","    from rdkit.Chem import AllChem, DataStructs\n","    from rdkit import RDLogger\n","    RDLogger.DisableLog('rdApp.*')\n","    print(\"âœ… RDKit available\")\n","except Exception as e:\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit\"])\n","    from rdkit import Chem\n","    from rdkit.Chem.Scaffolds import MurckoScaffold\n","    from rdkit.Chem import AllChem, DataStructs\n","    from rdkit import RDLogger\n","    RDLogger.DisableLog('rdApp.*')\n","    print(\"âœ… RDKit installed\")\n","\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","MASTER = f\"{ROOT}/integrated_labels_master.csv\"\n","\n","OUT_TRAIN   = f\"{ROOT}/train_split.csv\"\n","OUT_EXT_U   = f\"{ROOT}/external10_union.csv\"       # ãƒ•ã‚¡ã‚¤ãƒ«åã¯æ—¢å­˜è¸è¥²\n","OUT_EXT_K   = f\"{ROOT}/external10_kegg_only.csv\"\n","OUT_REPORT  = f\"{ROOT}/split_summary.txt\"\n","\n","# ---- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ----\n","SEED = 42\n","TARGET_EXT_RATIO = 0.20\n","TARGET_STRONG_POS = 15\n","TARGET_WEAK_POS   = 5\n","MIN_SCAF_SIZE = 3\n","SIM_THRESHOLD = 0.70\n","FP_RADIUS = 2\n","FP_BITS = 2048\n","MAX_REPAIR_ITERS = 120\n","\n","PRIORITY_PAIRS = [\n","    {\"name\": \"Digoxin\",              \"cid\": 2724385},\n","    {\"name\": \"Loperamide\",           \"cid\": 3955},\n","    {\"name\": \"Fexofenadine\",         \"cid\": 3348},\n","    {\"name\": \"N-Methyl-Quinidine\",   \"cid\": 10315094},\n","    {\"name\": \"Talinolol\",            \"cid\": 68770},\n","    {\"name\": \"Vinblastine\",          \"cid\": 13342},\n","    {\"name\": \"Quinidine\",            \"cid\": 441074},\n","]\n","\n","rng = np.random.default_rng(SEED)\n","\n","# ---- åˆ—åã‚†ã‚Œå¯¾å¿œï¼ˆCID/Drugåï¼‰ ----\n","def find_col(df, candidates):\n","    low = {str(c).strip().lower(): c for c in df.columns}\n","    for nm in candidates:\n","        c = low.get(nm.strip().lower())\n","        if c: return c\n","    return None\n","\n","def pick_smiles(row):\n","    sa = str(row.get(\"SMILES_aid\")) if pd.notna(row.get(\"SMILES_aid\")) else \"\"\n","    sk = str(row.get(\"SMILES_kegg\")) if pd.notna(row.get(\"SMILES_kegg\")) else \"\"\n","    sa = \"\" if sa.lower() in {\"nan\",\"none\",\"\"} else sa\n","    sk = \"\" if sk.lower() in {\"nan\",\"none\",\"\"} else sk\n","    return sa if sa else sk\n","\n","def norm_name(s: str) -> str:\n","    s = (s or \"\").strip()\n","    s = re.sub(r\"\\s+\", \" \", s)\n","    return s.lower()\n","\n","PRIORITY_NAME_SET = {norm_name(d[\"name\"]) for d in PRIORITY_PAIRS}\n","PRIORITY_CID_SET  = {int(d[\"cid\"]) for d in PRIORITY_PAIRS if d.get(\"cid\") is not None}\n","\n","def to_mol(smi):\n","    if not isinstance(smi, str) or smi==\"\":\n","        return None\n","    try:\n","        return Chem.MolFromSmiles(smi)\n","    except Exception:\n","        return None\n","\n","def to_scaffold_smiles(smi):\n","    m = to_mol(smi)\n","    if m is None:\n","        return \"\"\n","    try:\n","        scaf = MurckoScaffold.GetScaffoldForMol(m)\n","        return Chem.MolToSmiles(scaf) if scaf is not None else \"\"\n","    except Exception:\n","        return \"\"\n","\n","def morgan_fp(smi):\n","    m = to_mol(smi)\n","    if m is None:\n","        return None\n","    try:\n","        return AllChem.GetMorganFingerprintAsBitVect(m, FP_RADIUS, nBits=FP_BITS)\n","    except Exception:\n","        return None\n","\n","def max_tanimoto(fp, fps):\n","    if fp is None or not fps:\n","        return 0.0\n","    sims = DataStructs.BulkTanimotoSimilarity(fp, fps)\n","    return max(sims) if sims else 0.0\n","\n","# ====== 0) èª­ã¿è¾¼ã¿ & å‰å‡¦ç† ======\n","df = pd.read_csv(MASTER)\n","\n","# â˜… SampleWeight ã®æ­£è¦åŒ–ï¼ˆç„¡ã‘ã‚Œã° 1.0 ã‚’ä»˜ä¸ï¼‰\n","sw_col = find_col(df, [\"SampleWeight\",\"Sample_Weight\"])\n","if sw_col is None:\n","    df[\"SampleWeight\"] = 1.0\n","else:\n","    df[\"SampleWeight\"] = pd.to_numeric(df[sw_col], errors=\"coerce\").fillna(1.0).astype(float).clip(lower=0.0)\n","\n","# çµ±ä¸€SMILESåˆ—ã‚’ä»˜ä¸\n","df[\"SMILES\"] = df.apply(pick_smiles, axis=1)\n","df = df[(df[\"SMILES\"].notna()) & (df[\"SMILES\"]!=\"\")].copy()\n","\n","# tier å¿…é ˆ\n","if \"tier\" not in df.columns:\n","    raise RuntimeError(\"MASTERã« 'tier' åˆ—ãŒå¿…è¦ã§ã™ï¼ˆstrong_pos/strong_neg/weak_pos/unknownï¼‰ã€‚\")\n","\n","# CID/Drugå\n","col_cid  = find_col(df, [\"PubChem_CID\",\"CID\",\"Chosen_CID\"])\n","col_name = find_col(df, [\"Drug_name\",\"Drug\",\"Drug Name\"])\n","\n","if col_name:\n","    df[\"_name_norm\"] = df[col_name].astype(str).map(norm_name)\n","else:\n","    df[\"_name_norm\"] = \"\"\n","\n","if col_cid:\n","    def _to_int_or_nan(x):\n","        try:\n","            return int(x)\n","        except Exception:\n","            return np.nan\n","    df[\"_cid_int\"] = df[col_cid].apply(_to_int_or_nan)\n","else:\n","    df[\"_cid_int\"] = np.nan\n","\n","# å„ªå…ˆãƒ•ãƒ©ã‚°\n","df[\"_priority_flag\"] = (\n","    df[\"_cid_int\"].isin(PRIORITY_CID_SET) |\n","    df[\"_name_norm\"].isin(PRIORITY_NAME_SET)\n",")\n","\n","# ====== 1) ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰è¨ˆç®— ======\n","df[\"scaffold\"] = df[\"SMILES\"].apply(to_scaffold_smiles)\n","mask_empty_scaf = (df[\"scaffold\"]==\"\")\n","df.loc[mask_empty_scaf, \"scaffold\"] = df.loc[mask_empty_scaf, \"SMILES\"].apply(lambda s: f\"NOSCAF::{s[:24]}\")\n","protected_scaffolds = set(df.loc[df[\"_priority_flag\"], \"scaffold\"])\n","\n","scaf_counts = df[\"scaffold\"].value_counts()\n","candidates = [\n","    s for s,n in scaf_counts.items()\n","    if (n >= MIN_SCAF_SIZE) and (s not in protected_scaffolds)\n","]\n","\n","# ====== 2) ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã”ã¨ã®ãƒ©ãƒ™ãƒ«é›†è¨ˆ ======\n","def tier_counts_for_scaffold(s):\n","    g = df[df[\"scaffold\"]==s]\n","    sp = int((g[\"tier\"]==\"strong_pos\").sum())\n","    sn = int((g[\"tier\"]==\"strong_neg\").sum())\n","    wp = int((g[\"tier\"]==\"weak_pos\").sum())\n","    un = int((g[\"tier\"]==\"unknown\").sum())\n","    total = len(g)\n","    return {\"strong_pos\":sp, \"strong_neg\":sn, \"weak_pos\":wp, \"unknown\":un, \"total\":total}\n","\n","scaf_stats = {s: tier_counts_for_scaffold(s) for s in candidates}\n","target_total = int(round(len(df) * TARGET_EXT_RATIO))\n","\n","# ====== 3) åˆæœŸé¸æŠ ======\n","picked = set()\n","need_sp = TARGET_STRONG_POS\n","need_wp = TARGET_WEAK_POS\n","\n","for s in rng.permutation(candidates):\n","    if s in picked: continue\n","    if need_sp <= 0: break\n","    if scaf_stats[s][\"strong_pos\"] > 0:\n","        picked.add(s)\n","        need_sp -= scaf_stats[s][\"strong_pos\"]\n","\n","for s in rng.permutation([x for x in candidates if x not in picked]):\n","    if need_wp <= 0: break\n","    if scaf_stats[s][\"weak_pos\"] > 0:\n","        picked.add(s)\n","        need_wp -= scaf_stats[s][\"weak_pos\"]\n","\n","def current_tot(scafs):\n","    return sum(scaf_stats[s][\"total\"] for s in scafs)\n","\n","while current_tot(picked) < target_total:\n","    remaining = [x for x in candidates if x not in picked]\n","    if not remaining: break\n","    best, best_gap = None, float(\"inf\")\n","    for s in rng.permutation(remaining):\n","        new_tot = current_tot(picked | {s})\n","        gap = abs(target_total - new_tot)\n","        if gap < best_gap:\n","            best_gap = gap; best = s\n","    if best is None: break\n","    picked.add(best)\n","\n","# ====== 4) ä¸€æ—¦ ext/train ======\n","ext_mask = df[\"scaffold\"].isin(picked)\n","ext = df[ext_mask].copy().reset_index(drop=True)\n","train = df[~ext_mask].copy().reset_index(drop=True)\n","\n","# å„ªå…ˆè–¬ç‰©ã¯å¿…ãštrainã¸\n","move_priority = ext[ext[\"_priority_flag\"]].copy()\n","if len(move_priority) > 0:\n","    ext = ext[~ext.index.isin(move_priority.index)].copy()\n","    train = pd.concat([train, move_priority], ignore_index=True)\n","\n","# ====== 5) è¿‘ç¸é®æ–­ ======\n","train_fps = [morgan_fp(s) for s in train[\"SMILES\"]]\n","train_fps = [fp for fp in train_fps if fp is not None]\n","\n","def too_close(smi):\n","    fp = morgan_fp(smi)\n","    if fp is None or len(train_fps)==0:\n","        return False\n","    return max_tanimoto(fp, train_fps) >= SIM_THRESHOLD\n","\n","ext[\"too_close\"] = ext[\"SMILES\"].apply(too_close)\n","move_nn = ext[ext[\"too_close\"]].copy()\n","ext  = ext[~ext[\"too_close\"]].copy()\n","train = pd.concat([train, move_nn.drop(columns=[\"too_close\"])], ignore_index=True)\n","\n","# ====== 6) ä¿®å¾©ãƒ«ãƒ¼ãƒ— ======\n","def count_labels(df_part):\n","    sp = int((df_part[\"tier\"]==\"strong_pos\").sum())\n","    wp = int((df_part[\"tier\"]==\"weak_pos\").sum())\n","    tot = len(df_part)\n","    return sp, wp, tot\n","\n","def scaffold_of_rows(df_part):\n","    return set(df_part[\"scaffold\"].unique().tolist())\n","\n","def pick_scaffolds_to_add(have_scafs, need_sp_left, need_wp_left, max_add=3):\n","    pool = [s for s in candidates if s not in have_scafs]\n","    rng.shuffle(pool)\n","    chosen = []\n","    for s in pool:\n","        if len(chosen) >= max_add: break\n","        add_sp = scaf_stats[s][\"strong_pos\"]\n","        add_wp = scaf_stats[s][\"weak_pos\"]\n","        if (need_sp_left > 0 and add_sp > 0) or (need_wp_left > 0 and add_wp > 0) or (need_sp_left<=0 and need_wp_left<=0):\n","            chosen.append(s)\n","    return chosen\n","\n","def drop_scaffolds_to_reduce(have_scafs, target_size):\n","    cur_size = sum(scaf_stats[s][\"total\"] for s in have_scafs)\n","    if cur_size <= target_size: return []\n","    order = sorted(list(have_scafs), key=lambda s: (scaf_stats[s][\"strong_pos\"], scaf_stats[s][\"weak_pos\"], scaf_stats[s][\"total\"]))\n","    dropping, size_now = [], cur_size\n","    for s in order:\n","        if size_now <= target_size: break\n","        dropping.append(s); size_now -= scaf_stats[s][\"total\"]\n","    return dropping\n","\n","ext_scafs = scaffold_of_rows(ext)\n","for it in range(MAX_REPAIR_ITERS):\n","    sp, wp, tot = count_labels(ext)\n","    need_sp = max(0, TARGET_STRONG_POS - sp)\n","    need_wp = max(0, TARGET_WEAK_POS   - wp)\n","    if (sp >= TARGET_STRONG_POS) and (wp >= TARGET_WEAK_POS) and (tot == target_total):\n","        break\n","    changed = False\n","    if need_sp > 0 or need_wp > 0:\n","        to_add = pick_scaffolds_to_add(ext_scafs, need_sp, need_wp, max_add=3)\n","        if to_add:\n","            ext_scafs |= set(to_add)\n","            ext = df[df[\"scaffold\"].isin(ext_scafs)].copy().reset_index(drop=True)\n","            if ext[\"_priority_flag\"].any():\n","                move_back = ext[ext[\"_priority_flag\"]].copy()\n","                ext = ext[~ext[\"_priority_flag\"]].copy()\n","                train = pd.concat([train, move_back], ignore_index=True)\n","            changed = True\n","    sp, wp, tot = count_labels(ext)\n","    size_gap = target_total - tot\n","    if size_gap < 0:\n","        drops = drop_scaffolds_to_reduce(ext_scafs, target_total)\n","        if drops:\n","            ext_scafs -= set(drops)\n","            ext = df[df[\"scaffold\"].isin(ext_scafs)].copy().reset_index(drop=True)\n","            changed = True\n","    elif size_gap > 0:\n","        add_pool = [s for s in candidates if s not in ext_scafs]\n","        add_pool = sorted(add_pool, key=lambda s: (scaf_stats[s][\"strong_pos\"], scaf_stats[s][\"weak_pos\"], scaf_stats[s][\"total\"]))\n","        for s in add_pool:\n","            if sum(scaf_stats[x][\"total\"] for x in ext_scafs) >= target_total:\n","                break\n","            ext_scafs.add(s); changed = True\n","        if changed:\n","            ext = df[df[\"scaffold\"].isin(ext_scafs)].copy().reset_index(drop=True)\n","    if not changed: break\n","\n","if ext[\"_priority_flag\"].any():\n","    move_priority2 = ext[ext[\"_priority_flag\"]].copy()\n","    ext = ext[~ext[\"_priority_flag\"]].copy()\n","    train = pd.concat([train, move_priority2], ignore_index=True)\n","\n","# ====== 7) å‡ºåŠ› ======\n","keep_cols = [\n","    \"join_key\",\"SMILES\",\n","    \"CID\",\"SMILES_aid\",\"PubChem_CID\",\"SMILES_kegg\",\"Drug_name\",\n","    \"tier\",\"y\",\"weight\",\"from_AID\",\"from_KEGG\",\n","    \"Substrate_strong\",\"Substrate_weak\",\"dlogAC50\",\"scaffold\",\n","    \"SampleWeight\"  # â˜… è¿½åŠ ï¼šé‡ã¿ã‚’å‡ºåŠ›ã«æ®‹ã™\n","]\n","keep_cols = [c for c in keep_cols if c in df.columns] + [\"SMILES\",\"scaffold\"]\n","\n","train_out = train.drop(columns=[c for c in train.columns if c not in keep_cols]).copy()\n","ext_out   = ext.drop(columns=[c for c in ext.columns if c not in keep_cols]).copy()\n","\n","# KEGG-onlyï¼ˆweak_posã®ã¿ï¼‰ã‚’å¤–éƒ¨ã‹ã‚‰æŠ½å‡ºï¼ˆPUè©•ä¾¡ç”¨ï¼‰\n","ext_kegg_only = ext_out[(ext_out[\"tier\"]==\"weak_pos\")].copy() if \"tier\" in ext_out.columns else ext_out.iloc[0:0].copy()\n","\n","train_out.to_csv(OUT_TRAIN, index=False)\n","ext_out.to_csv(OUT_EXT_U, index=False)\n","ext_kegg_only.to_csv(OUT_EXT_K, index=False)\n","\n","# ====== 8) ãƒ¬ãƒãƒ¼ãƒˆ ======\n","def _count_priority(df_part):\n","    coln = find_col(df_part, [\"Drug_name\",\"Drug\",\"Drug Name\"])\n","    colc = find_col(df_part, [\"PubChem_CID\",\"CID\",\"Chosen_CID\"])\n","    name_norm = df_part[coln].astype(str).map(norm_name) if coln else pd.Series([\"\"]*len(df_part))\n","    cid_int = pd.to_numeric(df_part[colc], errors=\"coerce\").astype(\"Int64\") if colc else pd.Series([pd.NA]*len(df_part), dtype=\"Int64\")\n","    return int(((cid_int.isin(list(PRIORITY_CID_SET))) | (name_norm.isin(list(PRIORITY_NAME_SET)))).sum())\n","\n","def _lbl_counts(df_part):\n","    return df_part[\"tier\"].value_counts(dropna=False).to_dict() if \"tier\" in df_part.columns else {}\n","\n","sp_e, wp_e, tot_e = (ext_out[\"tier\"]==\"strong_pos\").sum(), (ext_out[\"tier\"]==\"weak_pos\").sum(), len(ext_out)\n","\n","buf = io.StringIO()\n","def wln(s=\"\"): buf.write(str(s)+\"\\n\")\n","wln(\"=== Split Summary (20% target with label constraints) ===\")\n","wln(f\"All (with usable SMILES)      : {len(df):,}\")\n","wln(f\"Target external total (20%)   : {target_total:,}\")\n","wln(f\"Protected scaffolds (priority): {len(protected_scaffolds):,}\")\n","wln(f\"Moved extâ†’train by NN filter  : {len(move_nn):,} (Tanimotoâ‰¥{SIM_THRESHOLD})\")\n","wln(\"\")\n","wln(f\"[External final] size={tot_e:,} | strong_pos={int(sp_e)} (target={TARGET_STRONG_POS}) | weak_pos={int(wp_e)} (target={TARGET_WEAK_POS})\")\n","wln(f\"  priority in ext = {_count_priority(ext_out)}\")\n","wln(f\"[Train   final] size={len(train_out):,}\")\n","wln(f\"  priority in train = {_count_priority(train_out)}\")\n","wln(\"\")\n","if \"tier\" in ext_out.columns:\n","    wln(\"[External tier counts]\"); wln(ext_out[\"tier\"].value_counts(dropna=False).to_string()); wln(\"\")\n","if \"tier\" in train_out.columns:\n","    wln(\"[Train tier counts]\"); wln(train_out[\"tier\"].value_counts(dropna=False).to_string()); wln(\"\")\n","wln(f\"KEGG-only in External (weak_pos): {len(ext_kegg_only):,}\")\n","\n","if sp_e != TARGET_STRONG_POS or wp_e != TARGET_WEAK_POS or tot_e != target_total:\n","    wln(\"\\n[NOTE] Exact constraints not fully met. This can happen if dataset composition makes it impossible.\")\n","    wln(\"      The script selected the closest feasible split under scaffold grouping & NN filtering.\")\n","\n","with open(OUT_REPORT, \"w\") as f:\n","    f.write(buf.getvalue())\n","\n","print(buf.getvalue())\n","print(\"ä¿å­˜:\", OUT_TRAIN)\n","print(\"ä¿å­˜:\", OUT_EXT_U)\n","print(\"ä¿å­˜:\", OUT_EXT_K)\n","print(\"ä¿å­˜:\", OUT_REPORT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AF2YXus-NZy2","executionInfo":{"status":"ok","timestamp":1760679360969,"user_tz":-540,"elapsed":11417,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"ee6ffc79-0c58-476d-a23f-638f1322f41e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… RDKit available\n","=== Split Summary (20% target with label constraints) ===\n","All (with usable SMILES)      : 7,397\n","Target external total (20%)   : 1,479\n","Protected scaffolds (priority): 7\n","Moved extâ†’train by NN filter  : 163 (Tanimotoâ‰¥0.7)\n","\n","[External final] size=1,478 | strong_pos=0 (target=15) | weak_pos=0 (target=5)\n","  priority in ext = 0\n","[Train   final] size=6,081\n","  priority in train = 7\n","\n","[External tier counts]\n","tier\n","aid_weak_neg    1453\n","aid_weak_pos      16\n","kegg_pos           6\n","unknown            3\n","\n","[Train tier counts]\n","tier\n","aid_weak_neg    5799\n","aid_weak_pos     201\n","kegg_pos          53\n","unknown           28\n","\n","KEGG-only in External (weak_pos): 0\n","\n","[NOTE] Exact constraints not fully met. This can happen if dataset composition makes it impossible.\n","      The script selected the closest feasible split under scaffold grouping & NN filtering.\n","\n","ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/train_split.csv\n","ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/external10_union.csv\n","ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/external10_kegg_only.csv\n","ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/split_summary.txt\n"]}]},{"cell_type":"code","source":["# ===============================\n","# PyGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆd.x + d.g + d.r + cidï¼‰ver7å¯¾å¿œ\n","# å…¥åŠ›: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/train_split.csv\n","# - å¿…é ˆåˆ—: SMILES, tier, y(0/1), weight\n","# - CIDã¯ row ã”ã¨ã«ã€ŒCID ã‚’æœ€å„ªå…ˆã€æ¬ æãªã‚‰ PubChem_CIDã€ã‚’ä½¿ç”¨\n","# ä»•æ§˜:\n","# - unknownã‚’å­¦ç¿’ã‹ã‚‰é™¤å¤–\n","# - y==1ï¼ˆé™½æ€§ï¼‰ã®ã¿SMILESãƒ©ãƒ³ãƒ€ãƒ åŒ–ã§æ‹¡å¼µï¼ˆ5å€ï¼‰\n","# - RDKitè¨˜è¿°å­ (gfeat7, rdesc10) ã‚’æ¨™æº–åŒ–ã—ã¦ d.g, d.r ã«æ ¼ç´\n","# - ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã‚’ d.w ã«ä¿å­˜\n","# - CIDã‚’ d.cid ã¨ã—ã¦ä¿å­˜ï¼ˆæ¬ æã¯ -1ï¼‰\n","# å‡ºåŠ›: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\n","# ===============================\n","# ===============================\n","# PyGãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆd.x + d.g + d.r + cidï¼‰ver7å¯¾å¿œ + SampleWeightä¿æŒ\n","# ===============================\n","import torch, pandas as pd, numpy as np\n","from rdkit import Chem\n","from rdkit.Chem import Descriptors\n","from rdkit.Chem import rdchem\n","from sklearn.preprocessing import StandardScaler\n","from torch_geometric.data import Data\n","\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PATH = f\"{ROOT}/train_split.csv\"\n","SAVE_PATH = f\"{ROOT}/data_graph_with_smiles.pt\"\n","INDEX_CSV = f\"{ROOT}/data_graph_with_smiles_index.csv\"  # â˜… è¿½åŠ : ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å‡ºåŠ›ï¼ˆåˆ—: SampleWeight å«ã‚€ï¼‰\n","\n","# --- åˆ†å­ç‰¹å¾´é‡ï¼ˆd.g, d.rï¼‰ ---\n","def gfeat7(mol):\n","    return [\n","        Descriptors.MolWt(mol),\n","        Descriptors.MolLogP(mol),\n","        Descriptors.NumHDonors(mol),\n","        Descriptors.NumHAcceptors(mol),\n","        Descriptors.TPSA(mol),\n","        Descriptors.HeavyAtomCount(mol),\n","        Descriptors.RingCount(mol),\n","    ]\n","\n","def rdesc10(mol):\n","    return [\n","        Descriptors.FpDensityMorgan1(mol),\n","        Descriptors.FpDensityMorgan2(mol),\n","        Descriptors.FpDensityMorgan3(mol),\n","        Descriptors.NumAliphaticRings(mol),\n","        Descriptors.NumAromaticRings(mol),\n","        Descriptors.NumRotatableBonds(mol),\n","        Descriptors.NumValenceElectrons(mol),\n","        Descriptors.BalabanJ(mol),\n","        Descriptors.BertzCT(mol),\n","        Descriptors.FractionCSP3(mol),\n","    ]\n","\n","# --- åŸå­ãƒ»çµåˆç‰¹å¾´é‡ ---\n","def atom_f(atom: rdchem.Atom):\n","    return torch.tensor([\n","        atom.GetAtomicNum(),\n","        atom.GetTotalDegree(),\n","        atom.GetFormalCharge(),\n","        float(atom.GetIsAromatic()),\n","        atom.GetTotalNumHs(includeNeighbors=True),\n","    ], dtype=torch.float)\n","\n","def bond_f(bond: rdchem.Bond):\n","    return torch.tensor([\n","        bond.GetBondTypeAsDouble(),\n","        float(bond.GetIsConjugated()),\n","        float(bond.IsInRing()),\n","        int(bond.GetStereo()),\n","        bond.GetBeginAtom().GetAtomicNum(),\n","        bond.GetEndAtom().GetAtomicNum(),\n","    ], dtype=torch.float)\n","\n","# --- 1) èª­ã¿è¾¼ã¿ï¼†CIDåˆ—ã®å„ªå…ˆãƒ«ãƒ¼ãƒ«é©ç”¨ï¼ˆCID -> PubChem_CIDï¼‰ ---\n","df0 = pd.read_csv(DATA_PATH)\n","\n","# å¿…é ˆåˆ—ãƒã‚§ãƒƒã‚¯ï¼ˆCIDåˆ—ã¯å¾Œã§ç¢ºèªï¼‰\n","need_cols = {\"SMILES\",\"tier\",\"y\",\"weight\"}\n","missing = need_cols - set(df0.columns)\n","if missing:\n","    raise ValueError(f\"å¿…é ˆåˆ—ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {missing}\")\n","\n","# â˜… SampleWeight åˆ—ã‚’æ­£è¦åŒ–ï¼ˆç„¡ã‘ã‚Œã° 1.0 ã§è¿½åŠ ï¼‰\n","sw_col = None\n","for c in df0.columns:\n","    if str(c).strip().lower() in {\"sampleweight\",\"sample_weight\"}:\n","        sw_col = c; break\n","if sw_col is None:\n","    df0[\"SampleWeight\"] = 1.0\n","else:\n","    df0[\"SampleWeight\"] = pd.to_numeric(df0[sw_col], errors=\"coerce\").fillna(1.0).astype(float).clip(lower=0.0)\n","\n","has_cid = \"CID\" in df0.columns\n","has_pub = \"PubChem_CID\" in df0.columns\n","if not (has_cid or has_pub):\n","    raise ValueError(\"CID åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å°‘ãªãã¨ã‚‚ 'CID' ã‹ 'PubChem_CID' ã®ã©ã¡ã‚‰ã‹ã‚’å«ã‚ã¦ãã ã•ã„ã€‚\")\n","\n","print(\"âœ… CIDå„ªå…ˆé †: CID â†’ PubChem_CID\")\n","print(f\"  - CID åˆ—ã‚ã‚Š? {has_cid}\")\n","print(f\"  - PubChem_CID åˆ—ã‚ã‚Š? {has_pub}\")\n","\n","def choose_cid_row(row):\n","    v1 = pd.to_numeric(row[\"CID\"], errors=\"coerce\") if has_cid else np.nan\n","    if pd.notna(v1):\n","        return int(v1)\n","    v2 = pd.to_numeric(row[\"PubChem_CID\"], errors=\"coerce\") if has_pub else np.nan\n","    if pd.notna(v2):\n","        return int(v2)\n","    return -1  # ã„ãšã‚Œã‚‚æ¬ æ\n","\n","# unknownã‚’é™¤å¤–ã€yâˆˆ{0,1}ã®ã¿\n","df0 = df0[(df0[\"tier\"]!=\"unknown\") & df0[\"y\"].isin([0,1])].copy()\n","df0[\"y\"] = df0[\"y\"].astype(int)\n","df0[\"weight\"] = pd.to_numeric(df0[\"weight\"], errors=\"coerce\").fillna(1.0)\n","\n","# å„ªå…ˆé †ã§CIDæ±ºå®š\n","df0[\"_cid_int\"] = df0.apply(choose_cid_row, axis=1)\n","\n","# çµ±è¨ˆè¡¨ç¤ºï¼ˆæƒ…å ±æºã®å†…è¨³ï¼‰\n","def cid_source(row):\n","    v1 = pd.to_numeric(row[\"CID\"], errors=\"coerce\") if has_cid else np.nan\n","    if pd.notna(v1): return \"CID\"\n","    v2 = pd.to_numeric(row[\"PubChem_CID\"], errors=\"coerce\") if has_pub else np.nan\n","    if pd.notna(v2): return \"PubChem_CID\"\n","    return \"none\"\n","\n","src_counts = df0.apply(cid_source, axis=1).value_counts()\n","print(\"ğŸ” CID ã‚½ãƒ¼ã‚¹åˆ¥ä»¶æ•°:\\n\", src_counts.to_string())\n","print(f\"ğŸ” CIDæ¬ æ(-1)ä»¶æ•°: {(df0['_cid_int'] == -1).sum()}\")\n","\n","# --- 2) é™½æ€§ã®ã¿SMILESæ‹¡å¼µï¼ˆCIDãƒ»Weightãƒ»SampleWeight ã‚‚è¤‡è£½ï¼‰ ---\n","def aug_smiles(sm, k=5):\n","    m = Chem.MolFromSmiles(sm)\n","    if m is None:\n","        return []\n","    return [Chem.MolToSmiles(m, doRandom=True) for _ in range(k)]\n","\n","rows = []\n","for sm, y, w_cls, sw, cidv in zip(df0[\"SMILES\"], df0[\"y\"], df0[\"weight\"], df0[\"SampleWeight\"], df0[\"_cid_int\"]):\n","    sm = \"\" if pd.isna(sm) else str(sm)\n","    if not sm:\n","        continue\n","    cidv_int = int(cidv)  # -1 or int\n","    if y == 1:\n","        aug = aug_smiles(sm, k=5)\n","        for s in [sm] + aug:\n","            rows.append((s, y, w_cls, float(sw), cidv_int))\n","    else:\n","        rows.append((sm, y, w_cls, float(sw), cidv_int))\n","\n","df = pd.DataFrame(rows, columns=[\"SMILES\",\"Label\",\"Weight\",\"SampleWeight\",\"CID\"])\n","print(f\"âœ… Augmented size: {len(df)} (original {len(df0)})\")\n","print(f\"ğŸ” Augå¾Œ CIDæ¬ æ(-1)ä»¶æ•°: {(df['CID'] == -1).sum()}\")\n","\n","# --- 3) RDKitå¤‰æ›ï¼†è¨˜è¿°å­ï¼ˆç„¡åŠ¹SMILESã¯é™¤å¤–ï¼‰ ---\n","mols, keep, g7_raw, r10_raw = [], [], [], []\n","for i, (sm, _, _, _, _) in enumerate(df.itertuples(index=False)):\n","    m = Chem.MolFromSmiles(sm)\n","    if m is None or m.GetNumAtoms() == 0:\n","        continue\n","    mols.append(m); keep.append(i)\n","    g7_raw.append(gfeat7(m))\n","    r10_raw.append(rdesc10(m))\n","df = df.iloc[keep].reset_index(drop=True)\n","\n","# --- 4) æ¨™æº–åŒ– ---\n","scaler_g = StandardScaler().fit(g7_raw)\n","scaler_r = StandardScaler().fit(r10_raw)\n","g7_scaled = scaler_g.transform(g7_raw)\n","r10_scaled = scaler_r.transform(r10_raw)\n","\n","# --- 5) ã‚°ãƒ©ãƒ•ä½œæˆï¼ˆbondã‹ã‚‰edgeã‚’ä½œã‚Šã€åŒæ–¹å‘ã«å±•é–‹ï¼‰ ---\n","data_list = []\n","for row_idx, m in enumerate(mols):\n","    y  = int(df.loc[row_idx, \"Label\"])\n","    w  = float(df.loc[row_idx, \"Weight\"])        # æ—¢å­˜ã®å­¦ç¿’ã‚¯ãƒ©ã‚¹é‡ã¿ï¼ˆå¼±ãƒ©ãƒ™ãƒ«ãªã©ï¼‰\n","    sw = float(df.loc[row_idx, \"SampleWeight\"])  # â˜… æ–°è¦: ã‚µãƒ³ãƒ—ãƒ«é‡è¦åº¦é‡ã¿ï¼ˆFDA=5.0 ãªã©ï¼‰\n","    sm = df.loc[row_idx, \"SMILES\"]\n","    cid_val = int(df.loc[row_idx, \"CID\"])  # -1 or int\n","\n","    # ã‚¨ãƒƒã‚¸ç„¡ã—ã¯ä»Šå›ã¯ã‚¹ã‚­ãƒƒãƒ—\n","    if m.GetNumBonds() == 0:\n","        continue\n","\n","    # ãƒãƒ¼ãƒ‰\n","    x = torch.stack([atom_f(a) for a in m.GetAtoms()])  # [N,5]\n","\n","    # ã‚¨ãƒƒã‚¸ï¼ˆåŒæ–¹å‘ï¼‰\n","    src, dst, eattr = [], [], []\n","    for b in m.GetBonds():\n","        i = b.GetBeginAtomIdx(); j = b.GetEndAtomIdx()\n","        f = bond_f(b)\n","        src += [i, j]\n","        dst += [j, i]\n","        eattr += [f, f]\n","    edge_index = torch.tensor([src, dst], dtype=torch.long)      # [2, 2E]\n","    edge_attr  = torch.stack(eattr)                              # [2E, 6]\n","\n","    # PyG Data\n","    d = Data(\n","        x=x,\n","        edge_index=edge_index,\n","        edge_attr=edge_attr,\n","        y=torch.tensor([y], dtype=torch.float32)\n","    )\n","    d.g = torch.tensor(g7_scaled[row_idx], dtype=torch.float32).unsqueeze(0)  # [1,7]\n","    d.r = torch.tensor(r10_scaled[row_idx], dtype=torch.float32).unsqueeze(0) # [1,10]\n","    d.w = torch.tensor([w], dtype=torch.float32)                 # æ—¢å­˜: å­¦ç¿’ç”¨é‡ã¿\n","    d.sample_weight = torch.tensor([sw], dtype=torch.float32)    # â˜… è¿½åŠ : FDAãªã©ã®ã‚µãƒ³ãƒ—ãƒ«é‡ã¿\n","    d.smiles = sm\n","    d.cid = int(cid_val)  # æ¬ æã¯ -1\n","\n","    data_list.append(d)\n","\n","print(f\"âœ… ã‚°ãƒ©ãƒ•æ•°: {len(data_list)}\")\n","lbl = [int(d.y.item()) for d in data_list]\n","print(f\"ğŸ” ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {pd.Series(lbl).value_counts().to_dict()}\")\n","\n","# --- 6) ä¿å­˜ï¼ˆ.pt ã¨å‚ç…§ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹CSVï¼‰ ---\n","torch.save(data_list, SAVE_PATH)\n","print(f\"âœ… PyGãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {SAVE_PATH}\")\n","\n","# â˜… å‚ç…§ç”¨ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆSMILES, Label, Weight, SampleWeight, CIDï¼‰\n","idx_df = pd.DataFrame({\n","    \"SMILES\": [d.smiles for d in data_list],\n","    \"Label\":  [int(d.y.item()) for d in data_list],\n","    \"Weight\": [float(d.w.item()) for d in data_list],\n","    \"SampleWeight\": [float(d.sample_weight.item()) for d in data_list],\n","    \"CID\":    [int(getattr(d, \"cid\", -1)) for d in data_list],\n","})\n","idx_df.to_csv(INDEX_CSV, index=False)\n","print(f\"âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹CSVä¿å­˜: {INDEX_CSV}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_sbzLJrt9opz","executionInfo":{"status":"ok","timestamp":1760679434024,"user_tz":-540,"elapsed":42294,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"d7f99303-c738-42ca-ce7b-a6de61f21da4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… CIDå„ªå…ˆé †: CID â†’ PubChem_CID\n","  - CID åˆ—ã‚ã‚Š? True\n","  - PubChem_CID åˆ—ã‚ã‚Š? True\n","ğŸ” CID ã‚½ãƒ¼ã‚¹åˆ¥ä»¶æ•°:\n"," CID            6030\n","PubChem_CID      21\n","none              2\n","ğŸ” CIDæ¬ æ(-1)ä»¶æ•°: 2\n","âœ… Augmented size: 7323 (original 6053)\n","ğŸ” Augå¾Œ CIDæ¬ æ(-1)ä»¶æ•°: 12\n","âœ… ã‚°ãƒ©ãƒ•æ•°: 7321\n","ğŸ” ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {0: 5797, 1: 1524}\n","âœ… PyGãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\n","âœ… ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹CSVä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles_index.csv\n"]}]},{"cell_type":"code","source":["# --- ã‚¹ã‚±ãƒ¼ãƒ©ä¿å­˜ ---\n","import joblib, os\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","os.makedirs(ROOT, exist_ok=True)\n","joblib.dump(scaler_g, f\"{ROOT}/scaler_g.joblib\")\n","joblib.dump(scaler_r, f\"{ROOT}/scaler_r.joblib\")\n","print(\"âœ… Saved scalers:\", f\"{ROOT}/scaler_g.joblib\", f\"{ROOT}/scaler_r.joblib\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IPbjZWyFSeiO","executionInfo":{"status":"ok","timestamp":1760679434255,"user_tz":-540,"elapsed":107,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"408e9b24-ec29-4393-93cf-bf1ac2a25320"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… Saved scalers: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/scaler_g.joblib /content/drive/MyDrive/Chemoinfo_MDR1_ver7/scaler_r.joblib\n"]}]},{"cell_type":"code","source":["# === Colab: g(7) + r(10) ç‰¹å¾´é‡è¾æ›¸ã‚’ä½œæˆãƒ»ä¿å­˜ãƒ»è¡¨ç¤ºï¼ˆãƒ¯ãƒ³ã‚»ãƒ«ï¼‰ ===\n","# å‡ºåŠ›å…ˆ: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/metadata/\n","# ç”Ÿæˆç‰©: feature_dictionary_gr17.csv / feature_dictionary_gr17.md\n","\n","import os, pandas as pd\n","\n","# 1) Google Drive ã‚’ãƒã‚¦ãƒ³ãƒˆï¼ˆåˆå›ã®ã¿èªè¨¼ãŒå‡ºã¾ã™ï¼‰\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","# 2) å‡ºåŠ›å…ˆï¼ˆå¿…è¦ãªã‚‰å¤‰æ›´ï¼‰\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","OUT_DIR = f\"{ROOT}/metadata\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# 3) ç‰¹å¾´é‡å®šç¾©ï¼ˆg=7, r=10ï¼‰\n","rows = [\n","    # g(7)\n","    {\"feature_id\":\"g1\",\"group\":\"g\",\"name\":\"Molecular Weight\",\"rdkit_func\":\"Descriptors.MolWt\",\"unit\":\"g/mol\",\n","     \"description\":\"åˆ†å­å…¨ä½“ã®è³ªé‡ã€‚å¤§ãã„ã»ã©è¡¨é¢ç©ã‚„çµåˆæ•°ãŒå¢—ãˆã‚„ã™ã„ã€‚\",\n","     \"interpretation_hint\":\"ä¸€èˆ¬ã«é«˜åˆ†å­é‡ã¯è†œé€éæ€§ã‚’ä½ä¸‹ã•ã›ã‚‹å‚¾å‘ï¼ˆP-gpåŸºè³ªæ€§ã¨ã¯ä¸€æ¦‚ã«ç›´çµã—ãªã„ï¼‰ã€‚\",\n","     \"typical_range\":\"100â€“800\",\"notes\":\"æ¥µç«¯ã«å¤§ãã„/å°ã•ã„å ´åˆã¯ä»–ç‰¹å¾´ã¨ã®ç›¸äº’ä½œç”¨ã«æ³¨æ„ã€‚\"},\n","    {\"feature_id\":\"g2\",\"group\":\"g\",\"name\":\"LogP (octanol/water)\",\"rdkit_func\":\"Descriptors.MolLogP\",\"unit\":\"â€”\",\n","     \"description\":\"ç–æ°´æ€§ã®å°ºåº¦ï¼ˆåˆ†é…ä¿‚æ•°ã®å¯¾æ•°ï¼‰ã€‚\",\n","     \"interpretation_hint\":\"ä¸­ã€œé«˜ã„ç–æ°´æ€§ã¯è†œæŒ¿å…¥ãƒ»çµåˆéƒ¨ä½ç›¸äº’ä½œç”¨ã‚’å¼·ã‚ã‚‹å¯èƒ½æ€§ã€‚æ¥µç«¯ã«é«˜ã„ã¨æº¶è§£æ€§ä½ä¸‹ã€‚\",\n","     \"typical_range\":\"âˆ’2â€“7\",\"notes\":\"ã‚¤ã‚ªãƒ³åŒ–çŠ¶æ…‹ã‚„æ¥µæ€§è¡¨é¢ç©ã¨ä½µã›ã¦è©•ä¾¡ã€‚\"},\n","    {\"feature_id\":\"g3\",\"group\":\"g\",\"name\":\"H-bond Donors\",\"rdkit_func\":\"Descriptors.NumHDonors\",\"unit\":\"count\",\n","     \"description\":\"æ°´ç´ çµåˆä¾›ä¸åŸºã®å€‹æ•°ã€‚\",\n","     \"interpretation_hint\":\"ãƒ‰ãƒŠãƒ¼ãŒå¤šã„ã¨é€éæ€§ã¯ä¸‹ãŒã‚Šã‚„ã™ã„ãŒã€ç›¸äº’ä½œç”¨éƒ¨ä½ã®å½¢æˆã«ã¯æœ‰åˆ©ãªå ´åˆã‚‚ã€‚\",\n","     \"typical_range\":\"0â€“6\",\"notes\":\"Lipinskiè¦å‰‡ãªã©ã®ç¯„å›²æ„Ÿå‚ç…§ã€‚\"},\n","    {\"feature_id\":\"g4\",\"group\":\"g\",\"name\":\"H-bond Acceptors\",\"rdkit_func\":\"Descriptors.NumHAcceptors\",\"unit\":\"count\",\n","     \"description\":\"æ°´ç´ çµåˆå—å®¹åŸºã®å€‹æ•°ã€‚\",\n","     \"interpretation_hint\":\"å—å®¹åŸºãŒå¤šã„ã¨æ¥µæ€§ãŒå¢—ã—ã€å—å‹•é€éã¯ä½ä¸‹ã—ã‚„ã™ã„ã€‚\",\n","     \"typical_range\":\"0â€“10\",\"notes\":\"å®˜èƒ½åŸºã®ç¨®é¡ã«ä¾å­˜ã€‚\"},\n","    {\"feature_id\":\"g5\",\"group\":\"g\",\"name\":\"Topological Polar Surface Area (TPSA)\",\"rdkit_func\":\"Descriptors.TPSA\",\"unit\":\"Ã…Â²\",\n","     \"description\":\"æ¥µæ€§è¡¨é¢ç©ã®è¿‘ä¼¼ã€‚æ°´ç´ çµåˆå¯èƒ½åŸå­ã«åŸºã¥ãã€‚\",\n","     \"interpretation_hint\":\"é«˜TPSAã¯è†œé€éæ€§ã®ä½ä¸‹ã¨ç›¸é–¢ã—ã‚„ã™ã„ã€‚\",\n","     \"typical_range\":\"0â€“200\",\"notes\":\"<60â€“90 Ã…Â²ã§é«˜ã„çµŒå£å¸åãŒæœŸå¾…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚\"},\n","    {\"feature_id\":\"g6\",\"group\":\"g\",\"name\":\"Heavy Atom Count\",\"rdkit_func\":\"Descriptors.HeavyAtomCount\",\"unit\":\"count\",\n","     \"description\":\"æ°´ç´ ä»¥å¤–ã®åŸå­æ•°ã€‚\",\n","     \"interpretation_hint\":\"åˆ†å­ã®ã‚µã‚¤ã‚ºãƒ»è¤‡é›‘ã•ã®ç²—æŒ‡æ¨™ã€‚\",\n","     \"typical_range\":\"5â€“80\",\"notes\":\"åˆ†å²/ç’°æ§‹é€ ã§åŒã‚«ã‚¦ãƒ³ãƒˆã§ã‚‚å½¢çŠ¶å·®ãŒå‡ºã‚‹ã€‚\"},\n","    {\"feature_id\":\"g7\",\"group\":\"g\",\"name\":\"Ring Count\",\"rdkit_func\":\"Descriptors.RingCount\",\"unit\":\"count\",\n","     \"description\":\"ç’°ã®å€‹æ•°ï¼ˆèŠ³é¦™æ—/è„‚è‚ªæ—ã‚’å«ã‚€ï¼‰ã€‚\",\n","     \"interpretation_hint\":\"ç’°ã®å¢—åŠ ã¯å‰›ç›´æ€§â†‘ãƒ»ç–æ°´æ€§â†‘ã«ã¤ãªãŒã‚Šã†ã‚‹ã€‚\",\n","     \"typical_range\":\"0â€“6\",\"notes\":\"ç¸®åˆç’°ã‚„å¤šç’°ã¯ç«‹ä½“çš„ãªå½±éŸ¿ãŒå¤§ãã„ã€‚\"},\n","\n","    # r(10)\n","    {\"feature_id\":\"r1\",\"group\":\"r\",\"name\":\"FpDensity Morgan1\",\"rdkit_func\":\"Descriptors.FpDensityMorgan1\",\"unit\":\"â€”\",\n","     \"description\":\"MorganåŠå¾„1ã®ãƒ“ãƒƒãƒˆå¯†åº¦ï¼ˆæ§‹é€ å¤šæ§˜æ€§ã®å°ºåº¦ï¼‰ã€‚\",\n","     \"interpretation_hint\":\"éƒ¨åˆ†æ§‹é€ ã®è±Šå¯Œã•ãƒ»ç½®æ›å¯†åº¦ã®ç²—æŒ‡æ¨™ã€‚\",\n","     \"typical_range\":\"0â€“1\",\"notes\":\"åˆ†å­ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ã¦å¤‰å‹•ã€‚\"},\n","    {\"feature_id\":\"r2\",\"group\":\"r\",\"name\":\"FpDensity Morgan2\",\"rdkit_func\":\"Descriptors.FpDensityMorgan2\",\"unit\":\"â€”\",\n","     \"description\":\"MorganåŠå¾„2ã®ãƒ“ãƒƒãƒˆå¯†åº¦ã€‚\",\n","     \"interpretation_hint\":\"è¿‘å‚ï¼ˆ~2çµåˆï¼‰ã¾ã§ã®å¤šæ§˜æ€§ã€‚\",\n","     \"typical_range\":\"0â€“1\",\"notes\":\"r1ã¨ã®åŒæ™‚è§£é‡ˆãŒæœ‰åŠ¹ã€‚\"},\n","    {\"feature_id\":\"r3\",\"group\":\"r\",\"name\":\"FpDensity Morgan3\",\"rdkit_func\":\"Descriptors.FpDensityMorgan3\",\"unit\":\"â€”\",\n","     \"description\":\"MorganåŠå¾„3ã®ãƒ“ãƒƒãƒˆå¯†åº¦ã€‚\",\n","     \"interpretation_hint\":\"ã‚ˆã‚Šåºƒã„è¿‘å‚ã®å¤šæ§˜æ€§ï¼ˆéª¨æ ¼ãƒ»ç½®æ›ã®è¤‡åˆï¼‰ã€‚\",\n","     \"typical_range\":\"0â€“1\",\"notes\":\"æ–°è¦æ€§è©•ä¾¡ã®è£œåŠ©ã€‚\"},\n","    {\"feature_id\":\"r4\",\"group\":\"r\",\"name\":\"Num Aliphatic Rings\",\"rdkit_func\":\"Descriptors.NumAliphaticRings\",\"unit\":\"count\",\n","     \"description\":\"è„‚è‚ªæ—ç’°ã®å€‹æ•°ã€‚\",\n","     \"interpretation_hint\":\"ç«‹ä½“çš„åµ©é«˜ã•ã‚„æŸ”è»Ÿæ€§ã«å½±éŸ¿ã€‚\",\n","     \"typical_range\":\"0â€“6\",\"notes\":\"ã‚¹ãƒ”ãƒ­/æ¶æ©‹ã§æ€§è³ªãŒå¤‰ã‚ã‚‹ã€‚\"},\n","    {\"feature_id\":\"r5\",\"group\":\"r\",\"name\":\"Num Aromatic Rings\",\"rdkit_func\":\"Descriptors.NumAromaticRings\",\"unit\":\"count\",\n","     \"description\":\"èŠ³é¦™æ—ç’°ã®å€‹æ•°ã€‚\",\n","     \"interpretation_hint\":\"Ï€-Ï€ç›¸äº’ä½œç”¨ãƒ»ç–æ°´æ€§ã«å¯„ä¸ã€‚\",\n","     \"typical_range\":\"0â€“4\",\"notes\":\"å¤šç’°èŠ³é¦™æ—ã¯ä»£è¬æ€§ã‚„æ¯’æ€§ã®æ‡¸å¿µã‚‚ã€‚\"},\n","    {\"feature_id\":\"r6\",\"group\":\"r\",\"name\":\"Num Rotatable Bonds\",\"rdkit_func\":\"Descriptors.NumRotatableBonds\",\"unit\":\"count\",\n","     \"description\":\"å›è»¢å¯èƒ½çµåˆã®å€‹æ•°ã€‚\",\n","     \"interpretation_hint\":\"è‡ªç”±åº¦â†‘ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±â†‘ãƒ»é€éæ€§â†“ã®å‚¾å‘ã€‚\",\n","     \"typical_range\":\"0â€“15\",\"notes\":\"VeberåŸºæº–ï¼ˆå›è»¢çµåˆâ‰¤10ï¼‰ãªã©å‚ç…§ã€‚\"},\n","    {\"feature_id\":\"r7\",\"group\":\"r\",\"name\":\"Num Valence Electrons\",\"rdkit_func\":\"Descriptors.NumValenceElectrons\",\"unit\":\"count\",\n","     \"description\":\"ä¾¡é›»å­ã®ç·æ•°ã€‚\",\n","     \"interpretation_hint\":\"å…¨ä½“ã®é›»å­ä¾›ä¸/å—å®¹èƒ½ã®ç²—æŒ‡æ¨™ã€‚\",\n","     \"typical_range\":\"â€”\",\"notes\":\"åŸå­çµ„æˆã«ä¾å­˜ã€‚\"},\n","    {\"feature_id\":\"r8\",\"group\":\"r\",\"name\":\"Balaban J Index\",\"rdkit_func\":\"Descriptors.BalabanJ\",\"unit\":\"â€”\",\n","     \"description\":\"åˆ†å­ã‚°ãƒ©ãƒ•ã®æ¥ç¶šæ€§æŒ‡æ•°ï¼ˆä½ç›¸çš„è¤‡é›‘ã•ï¼‰ã€‚\",\n","     \"interpretation_hint\":\"éª¨æ ¼ã®åˆ†å²/ç’°æ§‹é€ ã®è¤‡é›‘ã•ã‚’åæ˜ ã€‚\",\n","     \"typical_range\":\"~0â€“10\",\"notes\":\"ã‚¹ã‚±ãƒ¼ãƒ«ã¯åˆ†å­ã«ã‚ˆã‚Šå¤§ããå¤‰å‹•ã€‚\"},\n","    {\"feature_id\":\"r9\",\"group\":\"r\",\"name\":\"Bertz CT\",\"rdkit_func\":\"Descriptors.BertzCT\",\"unit\":\"â€”\",\n","     \"description\":\"åˆ†å­è¤‡é›‘æ€§æŒ‡æ•°ã€‚\",\n","     \"interpretation_hint\":\"é«˜å€¤ã¯æ§‹é€ å¤šæ§˜æ€§ãƒ»ç½®æ›ã®å¤šã•ã‚’ç¤ºå”†ã€‚\",\n","     \"typical_range\":\"~0â€“4000\",\"notes\":\"ã‚µã‚¤ã‚ºä¾å­˜æ€§ãŒå¼·ã„ã€‚\"},\n","    {\"feature_id\":\"r10\",\"group\":\"r\",\"name\":\"Fraction Csp3\",\"rdkit_func\":\"Descriptors.FractionCSP3\",\"unit\":\"â€”\",\n","     \"description\":\"sp3ç‚­ç´ ã®æ¯”ç‡ï¼ˆ3Dæ€§ã®æŒ‡æ¨™ï¼‰ã€‚\",\n","     \"interpretation_hint\":\"sp3æ¯”ç‡â†‘ã¯3Dæ€§â†‘ã§æº¶è§£æ€§ãƒ»ç‰©æ€§ãŒå¤‰åŒ–ã€‚åŸºè³ªæ€§ã«å½±éŸ¿ã—å¾—ã‚‹ã€‚\",\n","     \"typical_range\":\"0â€“1\",\"notes\":\"èŠ³é¦™æ—ãŒå¤šã„ã¨ä½ä¸‹ã€‚\"},\n","]\n","\n","df = pd.DataFrame(rows, columns=[\n","    \"feature_id\",\"group\",\"name\",\"rdkit_func\",\"unit\",\"description\",\"interpretation_hint\",\"typical_range\",\"notes\"\n","])\n","\n","# 4) ä¿å­˜\n","csv_path = f\"{OUT_DIR}/feature_dictionary_gr17.csv\"\n","md_path  = f\"{OUT_DIR}/feature_dictionary_gr17.md\"\n","df.to_csv(csv_path, index=False)\n","\n","with open(md_path, \"w\", encoding=\"utf-8\") as f:\n","    f.write(\"| feature_id | group | name | rdkit_func | unit | description | interpretation_hint | typical_range | notes |\\n\")\n","    f.write(\"|---|---|---|---|---|---|---|---|---|\\n\")\n","    for _, r in df.iterrows():\n","        f.write(f\"| {r['feature_id']} | {r['group']} | {r['name']} | {r['rdkit_func']} | {r['unit']} | {r['description']} | {r['interpretation_hint']} | {r['typical_range']} | {r['notes']} |\\n\")\n","\n","# 5) è¡¨ç¤º & ãƒ‘ã‚¹ç¢ºèª\n","from IPython.display import display, Markdown\n","display(df)\n","print(\"Saved CSV:\", csv_path)\n","print(\"Saved MD :\", md_path)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":707},"id":"-ZGqJnltfsTt","executionInfo":{"status":"ok","timestamp":1759217211847,"user_tz":-540,"elapsed":4713,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"3bfbe61c-8f50-40b3-f956-aa4daccc1dbf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]},{"output_type":"display_data","data":{"text/plain":["   feature_id group                                   name  \\\n","0          g1     g                       Molecular Weight   \n","1          g2     g                   LogP (octanol/water)   \n","2          g3     g                          H-bond Donors   \n","3          g4     g                       H-bond Acceptors   \n","4          g5     g  Topological Polar Surface Area (TPSA)   \n","5          g6     g                       Heavy Atom Count   \n","6          g7     g                             Ring Count   \n","7          r1     r                      FpDensity Morgan1   \n","8          r2     r                      FpDensity Morgan2   \n","9          r3     r                      FpDensity Morgan3   \n","10         r4     r                    Num Aliphatic Rings   \n","11         r5     r                     Num Aromatic Rings   \n","12         r6     r                    Num Rotatable Bonds   \n","13         r7     r                  Num Valence Electrons   \n","14         r8     r                        Balaban J Index   \n","15         r9     r                               Bertz CT   \n","16        r10     r                          Fraction Csp3   \n","\n","                         rdkit_func   unit                  description  \\\n","0                 Descriptors.MolWt  g/mol  åˆ†å­å…¨ä½“ã®è³ªé‡ã€‚å¤§ãã„ã»ã©è¡¨é¢ç©ã‚„çµåˆæ•°ãŒå¢—ãˆã‚„ã™ã„ã€‚   \n","1               Descriptors.MolLogP      â€”             ç–æ°´æ€§ã®å°ºåº¦ï¼ˆåˆ†é…ä¿‚æ•°ã®å¯¾æ•°ï¼‰ã€‚   \n","2            Descriptors.NumHDonors  count                  æ°´ç´ çµåˆä¾›ä¸åŸºã®å€‹æ•°ã€‚   \n","3         Descriptors.NumHAcceptors  count                  æ°´ç´ çµåˆå—å®¹åŸºã®å€‹æ•°ã€‚   \n","4                  Descriptors.TPSA     Ã…Â²       æ¥µæ€§è¡¨é¢ç©ã®è¿‘ä¼¼ã€‚æ°´ç´ çµåˆå¯èƒ½åŸå­ã«åŸºã¥ãã€‚   \n","5        Descriptors.HeavyAtomCount  count                    æ°´ç´ ä»¥å¤–ã®åŸå­æ•°ã€‚   \n","6             Descriptors.RingCount  count            ç’°ã®å€‹æ•°ï¼ˆèŠ³é¦™æ—/è„‚è‚ªæ—ã‚’å«ã‚€ï¼‰ã€‚   \n","7      Descriptors.FpDensityMorgan1      â€”   MorganåŠå¾„1ã®ãƒ“ãƒƒãƒˆå¯†åº¦ï¼ˆæ§‹é€ å¤šæ§˜æ€§ã®å°ºåº¦ï¼‰ã€‚   \n","8      Descriptors.FpDensityMorgan2      â€”             MorganåŠå¾„2ã®ãƒ“ãƒƒãƒˆå¯†åº¦ã€‚   \n","9      Descriptors.FpDensityMorgan3      â€”             MorganåŠå¾„3ã®ãƒ“ãƒƒãƒˆå¯†åº¦ã€‚   \n","10    Descriptors.NumAliphaticRings  count                     è„‚è‚ªæ—ç’°ã®å€‹æ•°ã€‚   \n","11     Descriptors.NumAromaticRings  count                     èŠ³é¦™æ—ç’°ã®å€‹æ•°ã€‚   \n","12    Descriptors.NumRotatableBonds  count                   å›è»¢å¯èƒ½çµåˆã®å€‹æ•°ã€‚   \n","13  Descriptors.NumValenceElectrons  count                      ä¾¡é›»å­ã®ç·æ•°ã€‚   \n","14             Descriptors.BalabanJ      â€”         åˆ†å­ã‚°ãƒ©ãƒ•ã®æ¥ç¶šæ€§æŒ‡æ•°ï¼ˆä½ç›¸çš„è¤‡é›‘ã•ï¼‰ã€‚   \n","15              Descriptors.BertzCT      â€”                     åˆ†å­è¤‡é›‘æ€§æŒ‡æ•°ã€‚   \n","16         Descriptors.FractionCSP3      â€”            sp3ç‚­ç´ ã®æ¯”ç‡ï¼ˆ3Dæ€§ã®æŒ‡æ¨™ï¼‰ã€‚   \n","\n","                         interpretation_hint typical_range  \\\n","0   ä¸€èˆ¬ã«é«˜åˆ†å­é‡ã¯è†œé€éæ€§ã‚’ä½ä¸‹ã•ã›ã‚‹å‚¾å‘ï¼ˆP-gpåŸºè³ªæ€§ã¨ã¯ä¸€æ¦‚ã«ç›´çµã—ãªã„ï¼‰ã€‚       100â€“800   \n","1   ä¸­ã€œé«˜ã„ç–æ°´æ€§ã¯è†œæŒ¿å…¥ãƒ»çµåˆéƒ¨ä½ç›¸äº’ä½œç”¨ã‚’å¼·ã‚ã‚‹å¯èƒ½æ€§ã€‚æ¥µç«¯ã«é«˜ã„ã¨æº¶è§£æ€§ä½ä¸‹ã€‚          âˆ’2â€“7   \n","2      ãƒ‰ãƒŠãƒ¼ãŒå¤šã„ã¨é€éæ€§ã¯ä¸‹ãŒã‚Šã‚„ã™ã„ãŒã€ç›¸äº’ä½œç”¨éƒ¨ä½ã®å½¢æˆã«ã¯æœ‰åˆ©ãªå ´åˆã‚‚ã€‚           0â€“6   \n","3                  å—å®¹åŸºãŒå¤šã„ã¨æ¥µæ€§ãŒå¢—ã—ã€å—å‹•é€éã¯ä½ä¸‹ã—ã‚„ã™ã„ã€‚          0â€“10   \n","4                      é«˜TPSAã¯è†œé€éæ€§ã®ä½ä¸‹ã¨ç›¸é–¢ã—ã‚„ã™ã„ã€‚         0â€“200   \n","5                            åˆ†å­ã®ã‚µã‚¤ã‚ºãƒ»è¤‡é›‘ã•ã®ç²—æŒ‡æ¨™ã€‚          5â€“80   \n","6                     ç’°ã®å¢—åŠ ã¯å‰›ç›´æ€§â†‘ãƒ»ç–æ°´æ€§â†‘ã«ã¤ãªãŒã‚Šã†ã‚‹ã€‚           0â€“6   \n","7                         éƒ¨åˆ†æ§‹é€ ã®è±Šå¯Œã•ãƒ»ç½®æ›å¯†åº¦ã®ç²—æŒ‡æ¨™ã€‚           0â€“1   \n","8                            è¿‘å‚ï¼ˆ~2çµåˆï¼‰ã¾ã§ã®å¤šæ§˜æ€§ã€‚           0â€“1   \n","9                      ã‚ˆã‚Šåºƒã„è¿‘å‚ã®å¤šæ§˜æ€§ï¼ˆéª¨æ ¼ãƒ»ç½®æ›ã®è¤‡åˆï¼‰ã€‚           0â€“1   \n","10                            ç«‹ä½“çš„åµ©é«˜ã•ã‚„æŸ”è»Ÿæ€§ã«å½±éŸ¿ã€‚           0â€“6   \n","11                           Ï€-Ï€ç›¸äº’ä½œç”¨ãƒ»ç–æ°´æ€§ã«å¯„ä¸ã€‚           0â€“4   \n","12                   è‡ªç”±åº¦â†‘ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±â†‘ãƒ»é€éæ€§â†“ã®å‚¾å‘ã€‚          0â€“15   \n","13                          å…¨ä½“ã®é›»å­ä¾›ä¸/å—å®¹èƒ½ã®ç²—æŒ‡æ¨™ã€‚             â€”   \n","14                         éª¨æ ¼ã®åˆ†å²/ç’°æ§‹é€ ã®è¤‡é›‘ã•ã‚’åæ˜ ã€‚         ~0â€“10   \n","15                        é«˜å€¤ã¯æ§‹é€ å¤šæ§˜æ€§ãƒ»ç½®æ›ã®å¤šã•ã‚’ç¤ºå”†ã€‚       ~0â€“4000   \n","16          sp3æ¯”ç‡â†‘ã¯3Dæ€§â†‘ã§æº¶è§£æ€§ãƒ»ç‰©æ€§ãŒå¤‰åŒ–ã€‚åŸºè³ªæ€§ã«å½±éŸ¿ã—å¾—ã‚‹ã€‚           0â€“1   \n","\n","                           notes  \n","0     æ¥µç«¯ã«å¤§ãã„/å°ã•ã„å ´åˆã¯ä»–ç‰¹å¾´ã¨ã®ç›¸äº’ä½œç”¨ã«æ³¨æ„ã€‚  \n","1            ã‚¤ã‚ªãƒ³åŒ–çŠ¶æ…‹ã‚„æ¥µæ€§è¡¨é¢ç©ã¨ä½µã›ã¦è©•ä¾¡ã€‚  \n","2            Lipinskiè¦å‰‡ãªã©ã®ç¯„å›²æ„Ÿå‚ç…§ã€‚  \n","3                     å®˜èƒ½åŸºã®ç¨®é¡ã«ä¾å­˜ã€‚  \n","4   <60â€“90 Ã…Â²ã§é«˜ã„çµŒå£å¸åãŒæœŸå¾…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚  \n","5          åˆ†å²/ç’°æ§‹é€ ã§åŒã‚«ã‚¦ãƒ³ãƒˆã§ã‚‚å½¢çŠ¶å·®ãŒå‡ºã‚‹ã€‚  \n","6             ç¸®åˆç’°ã‚„å¤šç’°ã¯ç«‹ä½“çš„ãªå½±éŸ¿ãŒå¤§ãã„ã€‚  \n","7                  åˆ†å­ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ã¦å¤‰å‹•ã€‚  \n","8                   r1ã¨ã®åŒæ™‚è§£é‡ˆãŒæœ‰åŠ¹ã€‚  \n","9                      æ–°è¦æ€§è©•ä¾¡ã®è£œåŠ©ã€‚  \n","10                ã‚¹ãƒ”ãƒ­/æ¶æ©‹ã§æ€§è³ªãŒå¤‰ã‚ã‚‹ã€‚  \n","11             å¤šç’°èŠ³é¦™æ—ã¯ä»£è¬æ€§ã‚„æ¯’æ€§ã®æ‡¸å¿µã‚‚ã€‚  \n","12         VeberåŸºæº–ï¼ˆå›è»¢çµåˆâ‰¤10ï¼‰ãªã©å‚ç…§ã€‚  \n","13                      åŸå­çµ„æˆã«ä¾å­˜ã€‚  \n","14              ã‚¹ã‚±ãƒ¼ãƒ«ã¯åˆ†å­ã«ã‚ˆã‚Šå¤§ããå¤‰å‹•ã€‚  \n","15                    ã‚µã‚¤ã‚ºä¾å­˜æ€§ãŒå¼·ã„ã€‚  \n","16                    èŠ³é¦™æ—ãŒå¤šã„ã¨ä½ä¸‹ã€‚  "],"text/html":["\n","  <div id=\"df-fb771f52-b1b3-47f0-be32-72d30ea7be0e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>feature_id</th>\n","      <th>group</th>\n","      <th>name</th>\n","      <th>rdkit_func</th>\n","      <th>unit</th>\n","      <th>description</th>\n","      <th>interpretation_hint</th>\n","      <th>typical_range</th>\n","      <th>notes</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>g1</td>\n","      <td>g</td>\n","      <td>Molecular Weight</td>\n","      <td>Descriptors.MolWt</td>\n","      <td>g/mol</td>\n","      <td>åˆ†å­å…¨ä½“ã®è³ªé‡ã€‚å¤§ãã„ã»ã©è¡¨é¢ç©ã‚„çµåˆæ•°ãŒå¢—ãˆã‚„ã™ã„ã€‚</td>\n","      <td>ä¸€èˆ¬ã«é«˜åˆ†å­é‡ã¯è†œé€éæ€§ã‚’ä½ä¸‹ã•ã›ã‚‹å‚¾å‘ï¼ˆP-gpåŸºè³ªæ€§ã¨ã¯ä¸€æ¦‚ã«ç›´çµã—ãªã„ï¼‰ã€‚</td>\n","      <td>100â€“800</td>\n","      <td>æ¥µç«¯ã«å¤§ãã„/å°ã•ã„å ´åˆã¯ä»–ç‰¹å¾´ã¨ã®ç›¸äº’ä½œç”¨ã«æ³¨æ„ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>g2</td>\n","      <td>g</td>\n","      <td>LogP (octanol/water)</td>\n","      <td>Descriptors.MolLogP</td>\n","      <td>â€”</td>\n","      <td>ç–æ°´æ€§ã®å°ºåº¦ï¼ˆåˆ†é…ä¿‚æ•°ã®å¯¾æ•°ï¼‰ã€‚</td>\n","      <td>ä¸­ã€œé«˜ã„ç–æ°´æ€§ã¯è†œæŒ¿å…¥ãƒ»çµåˆéƒ¨ä½ç›¸äº’ä½œç”¨ã‚’å¼·ã‚ã‚‹å¯èƒ½æ€§ã€‚æ¥µç«¯ã«é«˜ã„ã¨æº¶è§£æ€§ä½ä¸‹ã€‚</td>\n","      <td>âˆ’2â€“7</td>\n","      <td>ã‚¤ã‚ªãƒ³åŒ–çŠ¶æ…‹ã‚„æ¥µæ€§è¡¨é¢ç©ã¨ä½µã›ã¦è©•ä¾¡ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>g3</td>\n","      <td>g</td>\n","      <td>H-bond Donors</td>\n","      <td>Descriptors.NumHDonors</td>\n","      <td>count</td>\n","      <td>æ°´ç´ çµåˆä¾›ä¸åŸºã®å€‹æ•°ã€‚</td>\n","      <td>ãƒ‰ãƒŠãƒ¼ãŒå¤šã„ã¨é€éæ€§ã¯ä¸‹ãŒã‚Šã‚„ã™ã„ãŒã€ç›¸äº’ä½œç”¨éƒ¨ä½ã®å½¢æˆã«ã¯æœ‰åˆ©ãªå ´åˆã‚‚ã€‚</td>\n","      <td>0â€“6</td>\n","      <td>Lipinskiè¦å‰‡ãªã©ã®ç¯„å›²æ„Ÿå‚ç…§ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>g4</td>\n","      <td>g</td>\n","      <td>H-bond Acceptors</td>\n","      <td>Descriptors.NumHAcceptors</td>\n","      <td>count</td>\n","      <td>æ°´ç´ çµåˆå—å®¹åŸºã®å€‹æ•°ã€‚</td>\n","      <td>å—å®¹åŸºãŒå¤šã„ã¨æ¥µæ€§ãŒå¢—ã—ã€å—å‹•é€éã¯ä½ä¸‹ã—ã‚„ã™ã„ã€‚</td>\n","      <td>0â€“10</td>\n","      <td>å®˜èƒ½åŸºã®ç¨®é¡ã«ä¾å­˜ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>g5</td>\n","      <td>g</td>\n","      <td>Topological Polar Surface Area (TPSA)</td>\n","      <td>Descriptors.TPSA</td>\n","      <td>Ã…Â²</td>\n","      <td>æ¥µæ€§è¡¨é¢ç©ã®è¿‘ä¼¼ã€‚æ°´ç´ çµåˆå¯èƒ½åŸå­ã«åŸºã¥ãã€‚</td>\n","      <td>é«˜TPSAã¯è†œé€éæ€§ã®ä½ä¸‹ã¨ç›¸é–¢ã—ã‚„ã™ã„ã€‚</td>\n","      <td>0â€“200</td>\n","      <td>&lt;60â€“90 Ã…Â²ã§é«˜ã„çµŒå£å¸åãŒæœŸå¾…ã•ã‚Œã‚‹ã“ã¨ãŒå¤šã„ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>g6</td>\n","      <td>g</td>\n","      <td>Heavy Atom Count</td>\n","      <td>Descriptors.HeavyAtomCount</td>\n","      <td>count</td>\n","      <td>æ°´ç´ ä»¥å¤–ã®åŸå­æ•°ã€‚</td>\n","      <td>åˆ†å­ã®ã‚µã‚¤ã‚ºãƒ»è¤‡é›‘ã•ã®ç²—æŒ‡æ¨™ã€‚</td>\n","      <td>5â€“80</td>\n","      <td>åˆ†å²/ç’°æ§‹é€ ã§åŒã‚«ã‚¦ãƒ³ãƒˆã§ã‚‚å½¢çŠ¶å·®ãŒå‡ºã‚‹ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>g7</td>\n","      <td>g</td>\n","      <td>Ring Count</td>\n","      <td>Descriptors.RingCount</td>\n","      <td>count</td>\n","      <td>ç’°ã®å€‹æ•°ï¼ˆèŠ³é¦™æ—/è„‚è‚ªæ—ã‚’å«ã‚€ï¼‰ã€‚</td>\n","      <td>ç’°ã®å¢—åŠ ã¯å‰›ç›´æ€§â†‘ãƒ»ç–æ°´æ€§â†‘ã«ã¤ãªãŒã‚Šã†ã‚‹ã€‚</td>\n","      <td>0â€“6</td>\n","      <td>ç¸®åˆç’°ã‚„å¤šç’°ã¯ç«‹ä½“çš„ãªå½±éŸ¿ãŒå¤§ãã„ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>r1</td>\n","      <td>r</td>\n","      <td>FpDensity Morgan1</td>\n","      <td>Descriptors.FpDensityMorgan1</td>\n","      <td>â€”</td>\n","      <td>MorganåŠå¾„1ã®ãƒ“ãƒƒãƒˆå¯†åº¦ï¼ˆæ§‹é€ å¤šæ§˜æ€§ã®å°ºåº¦ï¼‰ã€‚</td>\n","      <td>éƒ¨åˆ†æ§‹é€ ã®è±Šå¯Œã•ãƒ»ç½®æ›å¯†åº¦ã®ç²—æŒ‡æ¨™ã€‚</td>\n","      <td>0â€“1</td>\n","      <td>åˆ†å­ã‚µã‚¤ã‚ºã«ä¾å­˜ã—ã¦å¤‰å‹•ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>r2</td>\n","      <td>r</td>\n","      <td>FpDensity Morgan2</td>\n","      <td>Descriptors.FpDensityMorgan2</td>\n","      <td>â€”</td>\n","      <td>MorganåŠå¾„2ã®ãƒ“ãƒƒãƒˆå¯†åº¦ã€‚</td>\n","      <td>è¿‘å‚ï¼ˆ~2çµåˆï¼‰ã¾ã§ã®å¤šæ§˜æ€§ã€‚</td>\n","      <td>0â€“1</td>\n","      <td>r1ã¨ã®åŒæ™‚è§£é‡ˆãŒæœ‰åŠ¹ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>r3</td>\n","      <td>r</td>\n","      <td>FpDensity Morgan3</td>\n","      <td>Descriptors.FpDensityMorgan3</td>\n","      <td>â€”</td>\n","      <td>MorganåŠå¾„3ã®ãƒ“ãƒƒãƒˆå¯†åº¦ã€‚</td>\n","      <td>ã‚ˆã‚Šåºƒã„è¿‘å‚ã®å¤šæ§˜æ€§ï¼ˆéª¨æ ¼ãƒ»ç½®æ›ã®è¤‡åˆï¼‰ã€‚</td>\n","      <td>0â€“1</td>\n","      <td>æ–°è¦æ€§è©•ä¾¡ã®è£œåŠ©ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>r4</td>\n","      <td>r</td>\n","      <td>Num Aliphatic Rings</td>\n","      <td>Descriptors.NumAliphaticRings</td>\n","      <td>count</td>\n","      <td>è„‚è‚ªæ—ç’°ã®å€‹æ•°ã€‚</td>\n","      <td>ç«‹ä½“çš„åµ©é«˜ã•ã‚„æŸ”è»Ÿæ€§ã«å½±éŸ¿ã€‚</td>\n","      <td>0â€“6</td>\n","      <td>ã‚¹ãƒ”ãƒ­/æ¶æ©‹ã§æ€§è³ªãŒå¤‰ã‚ã‚‹ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>r5</td>\n","      <td>r</td>\n","      <td>Num Aromatic Rings</td>\n","      <td>Descriptors.NumAromaticRings</td>\n","      <td>count</td>\n","      <td>èŠ³é¦™æ—ç’°ã®å€‹æ•°ã€‚</td>\n","      <td>Ï€-Ï€ç›¸äº’ä½œç”¨ãƒ»ç–æ°´æ€§ã«å¯„ä¸ã€‚</td>\n","      <td>0â€“4</td>\n","      <td>å¤šç’°èŠ³é¦™æ—ã¯ä»£è¬æ€§ã‚„æ¯’æ€§ã®æ‡¸å¿µã‚‚ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>r6</td>\n","      <td>r</td>\n","      <td>Num Rotatable Bonds</td>\n","      <td>Descriptors.NumRotatableBonds</td>\n","      <td>count</td>\n","      <td>å›è»¢å¯èƒ½çµåˆã®å€‹æ•°ã€‚</td>\n","      <td>è‡ªç”±åº¦â†‘ã§ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±â†‘ãƒ»é€éæ€§â†“ã®å‚¾å‘ã€‚</td>\n","      <td>0â€“15</td>\n","      <td>VeberåŸºæº–ï¼ˆå›è»¢çµåˆâ‰¤10ï¼‰ãªã©å‚ç…§ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>r7</td>\n","      <td>r</td>\n","      <td>Num Valence Electrons</td>\n","      <td>Descriptors.NumValenceElectrons</td>\n","      <td>count</td>\n","      <td>ä¾¡é›»å­ã®ç·æ•°ã€‚</td>\n","      <td>å…¨ä½“ã®é›»å­ä¾›ä¸/å—å®¹èƒ½ã®ç²—æŒ‡æ¨™ã€‚</td>\n","      <td>â€”</td>\n","      <td>åŸå­çµ„æˆã«ä¾å­˜ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>r8</td>\n","      <td>r</td>\n","      <td>Balaban J Index</td>\n","      <td>Descriptors.BalabanJ</td>\n","      <td>â€”</td>\n","      <td>åˆ†å­ã‚°ãƒ©ãƒ•ã®æ¥ç¶šæ€§æŒ‡æ•°ï¼ˆä½ç›¸çš„è¤‡é›‘ã•ï¼‰ã€‚</td>\n","      <td>éª¨æ ¼ã®åˆ†å²/ç’°æ§‹é€ ã®è¤‡é›‘ã•ã‚’åæ˜ ã€‚</td>\n","      <td>~0â€“10</td>\n","      <td>ã‚¹ã‚±ãƒ¼ãƒ«ã¯åˆ†å­ã«ã‚ˆã‚Šå¤§ããå¤‰å‹•ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>r9</td>\n","      <td>r</td>\n","      <td>Bertz CT</td>\n","      <td>Descriptors.BertzCT</td>\n","      <td>â€”</td>\n","      <td>åˆ†å­è¤‡é›‘æ€§æŒ‡æ•°ã€‚</td>\n","      <td>é«˜å€¤ã¯æ§‹é€ å¤šæ§˜æ€§ãƒ»ç½®æ›ã®å¤šã•ã‚’ç¤ºå”†ã€‚</td>\n","      <td>~0â€“4000</td>\n","      <td>ã‚µã‚¤ã‚ºä¾å­˜æ€§ãŒå¼·ã„ã€‚</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>r10</td>\n","      <td>r</td>\n","      <td>Fraction Csp3</td>\n","      <td>Descriptors.FractionCSP3</td>\n","      <td>â€”</td>\n","      <td>sp3ç‚­ç´ ã®æ¯”ç‡ï¼ˆ3Dæ€§ã®æŒ‡æ¨™ï¼‰ã€‚</td>\n","      <td>sp3æ¯”ç‡â†‘ã¯3Dæ€§â†‘ã§æº¶è§£æ€§ãƒ»ç‰©æ€§ãŒå¤‰åŒ–ã€‚åŸºè³ªæ€§ã«å½±éŸ¿ã—å¾—ã‚‹ã€‚</td>\n","      <td>0â€“1</td>\n","      <td>èŠ³é¦™æ—ãŒå¤šã„ã¨ä½ä¸‹ã€‚</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb771f52-b1b3-47f0-be32-72d30ea7be0e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fb771f52-b1b3-47f0-be32-72d30ea7be0e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fb771f52-b1b3-47f0-be32-72d30ea7be0e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    <div id=\"df-cf72602e-764a-41dd-9629-045cfd329d57\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf72602e-764a-41dd-9629-045cfd329d57')\"\n","                title=\"Suggest charts\"\n","                style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","      <script>\n","        async function quickchart(key) {\n","          const quickchartButtonEl =\n","            document.querySelector('#' + key + ' button');\n","          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","          quickchartButtonEl.classList.add('colab-df-spinner');\n","          try {\n","            const charts = await google.colab.kernel.invokeFunction(\n","                'suggestCharts', [key], {});\n","          } catch (error) {\n","            console.error('Error during call to suggestCharts:', error);\n","          }\n","          quickchartButtonEl.classList.remove('colab-df-spinner');\n","          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","        }\n","        (() => {\n","          let quickchartButtonEl =\n","            document.querySelector('#df-cf72602e-764a-41dd-9629-045cfd329d57 button');\n","          quickchartButtonEl.style.display =\n","            google.colab.kernel.accessAllowed ? 'block' : 'none';\n","        })();\n","      </script>\n","    </div>\n","\n","  <div id=\"id_d1fee131-d75f-451e-a116-92e4623e4530\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_d1fee131-d75f-451e-a116-92e4623e4530 button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('df');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 17,\n  \"fields\": [\n    {\n      \"column\": \"feature_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"g1\",\n          \"g2\",\n          \"g6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"r\",\n          \"g\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Molecular Weight\",\n          \"LogP (octanol/water)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rdkit_func\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"Descriptors.MolWt\",\n          \"Descriptors.MolLogP\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"unit\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"\\u2014\",\n          \"\\u00c5\\u00b2\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"\\u5206\\u5b50\\u5168\\u4f53\\u306e\\u8cea\\u91cf\\u3002\\u5927\\u304d\\u3044\\u307b\\u3069\\u8868\\u9762\\u7a4d\\u3084\\u7d50\\u5408\\u6570\\u304c\\u5897\\u3048\\u3084\\u3059\\u3044\\u3002\",\n          \"\\u758e\\u6c34\\u6027\\u306e\\u5c3a\\u5ea6\\uff08\\u5206\\u914d\\u4fc2\\u6570\\u306e\\u5bfe\\u6570\\uff09\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"interpretation_hint\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"\\u4e00\\u822c\\u306b\\u9ad8\\u5206\\u5b50\\u91cf\\u306f\\u819c\\u900f\\u904e\\u6027\\u3092\\u4f4e\\u4e0b\\u3055\\u305b\\u308b\\u50be\\u5411\\uff08P-gp\\u57fa\\u8cea\\u6027\\u3068\\u306f\\u4e00\\u6982\\u306b\\u76f4\\u7d50\\u3057\\u306a\\u3044\\uff09\\u3002\",\n          \"\\u4e2d\\u301c\\u9ad8\\u3044\\u758e\\u6c34\\u6027\\u306f\\u819c\\u633f\\u5165\\u30fb\\u7d50\\u5408\\u90e8\\u4f4d\\u76f8\\u4e92\\u4f5c\\u7528\\u3092\\u5f37\\u3081\\u308b\\u53ef\\u80fd\\u6027\\u3002\\u6975\\u7aef\\u306b\\u9ad8\\u3044\\u3068\\u6eb6\\u89e3\\u6027\\u4f4e\\u4e0b\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"typical_range\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"~0\\u201310\",\n          \"\\u2014\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"notes\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"\\u6975\\u7aef\\u306b\\u5927\\u304d\\u3044/\\u5c0f\\u3055\\u3044\\u5834\\u5408\\u306f\\u4ed6\\u7279\\u5fb4\\u3068\\u306e\\u76f8\\u4e92\\u4f5c\\u7528\\u306b\\u6ce8\\u610f\\u3002\",\n          \"\\u30a4\\u30aa\\u30f3\\u5316\\u72b6\\u614b\\u3084\\u6975\\u6027\\u8868\\u9762\\u7a4d\\u3068\\u4f75\\u305b\\u3066\\u8a55\\u4fa1\\u3002\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saved CSV: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/metadata/feature_dictionary_gr17.csv\n","Saved MD : /content/drive/MyDrive/Chemoinfo_MDR1_ver7/metadata/feature_dictionary_gr17.md\n"]}]},{"cell_type":"code","source":["# =============================================================\n","# 4ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ (GINE / GATv2 / NNConv / TransformerConv)\n","# d.x + d.g + d.r ã‚’çµåˆã—ã€edge_attr ã‚‚ä½¿ç”¨\n","# å…¥åŠ›: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\n","# å‡ºåŠ›: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_gnn_dx_dg_dr_cv_edgeall/\n","# å¤‰æ›´ç‚¹:\n","#  - ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ d.w ã¨ d.sample_weight ã‚’æå¤±ã«åæ˜ \n","#  - pos_weightï¼ˆä¸å‡è¡¡å¯¾ç­–ï¼‰ã¨ä½µç”¨ï¼ˆreduction='none' + é‡ã¿å’Œã§æ­£è¦åŒ–ï¼‰\n","#  - å„ªå…ˆCIDã¯å¸¸ã«å­¦ç¿’ã¸å›ºå®šï¼ˆæ¤œè¨¼ã«ã¯å‡ºã•ãªã„ï¼‰\n","# =============================================================\n","\n","import os, random\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.serialization import add_safe_globals\n","from torch_geometric.nn import (\n","    GINEConv, GATv2Conv, NNConv, TransformerConv, AttentionalAggregation\n",")\n","from torch_geometric.loader import DataLoader\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import roc_auc_score, average_precision_score, precision_score, recall_score, f1_score\n","import pandas as pd\n","\n","# ====== è¨­å®š ======\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","SEED   = 42\n","KFOLD  = 3\n","BATCH  = 64\n","HID    = 256\n","LR     = 3e-4\n","PAT    = 5          # æ—©æœŸåœæ­¢ patience\n","TMAX   = 5          # CosineAnnealing ã®å‘¨æœŸ\n","CLIP   = 5\n","WEIGHT_DECAY = 1e-4\n","\n","IN_PYGDATA = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\"\n","SAVE_BASE  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_gnn_dx_dg_dr_cv_edgeall\"\n","os.makedirs(SAVE_BASE, exist_ok=True)\n","ARCHES = [\"GINE\", \"GATv2\", \"NNConv\", \"Transformer\"]\n","for arch in ARCHES:\n","    os.makedirs(os.path.join(SAVE_BASE, arch), exist_ok=True)\n","\n","# â˜…å¿…ãšå­¦ç¿’ã«å«ã‚ãŸã„CID\n","PRIORITY_CIDS = {3348, 3955, 2724385, 10315094, 68770, 13342, 441074}\n","\n","# ====== å†ç¾æ€§ ======\n","def set_seed(seed=SEED):\n","    random.seed(seed); np.random.seed(seed)\n","    torch.manual_seed(seed); torch.cuda.manual_seed_all(seed)\n","set_seed(SEED)\n","\n","# ====== ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆPyTorch 2.6å¯¾ç­–ä»˜ãï¼‰ ======\n","def load_pyg_data(path):\n","    try:\n","        try:\n","            from torch_geometric.data.data import DataEdgeAttr\n","            add_safe_globals([DataEdgeAttr])\n","        except Exception as e:\n","            print(f\"[WARN] add_safe_globals(DataEdgeAttr) å¤±æ•—: {e}\")\n","        obj = torch.load(path)  # æ—¢å®š: weights_only=True\n","        return obj\n","    except Exception as e:\n","        print(f\"[WARN] å®‰å…¨ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ï¼ˆ{e}ï¼‰ã€‚weights_only=False ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã€‚\")\n","        obj = torch.load(path, weights_only=False)\n","        return obj\n","\n","obj = load_pyg_data(IN_PYGDATA)\n","if isinstance(obj, list):\n","    data_list = obj\n","elif isinstance(obj, dict) and \"data_list\" in obj:\n","    data_list = obj[\"data_list\"]\n","else:\n","    try:\n","        data_list = list(obj)\n","    except Exception as e:\n","        raise RuntimeError(f\"æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼ã§ã™: {type(obj)}; liståŒ–ã«å¤±æ•—: {e}\")\n","\n","if len(data_list) == 0:\n","    raise RuntimeError(\"data_list ãŒç©ºã§ã™ã€‚\")\n","\n","sample = data_list[0]\n","req = [\"x\",\"edge_index\",\"edge_attr\",\"g\",\"r\",\"y\"]\n","missing = [k for k in req if not hasattr(sample, k)]\n","if missing:\n","    raise RuntimeError(f\"Dataã«å¿…è¦å±æ€§ãŒã‚ã‚Šã¾ã›ã‚“: {missing}\")\n","\n","def infer_feat_dim(t):\n","    if t is None: return 0\n","    if t.dim() == 1: return t.numel()\n","    if t.dim() in (2,3): return t.size(-1)\n","    raise RuntimeError(f\"æœªçŸ¥ã®ãƒ†ãƒ³ã‚½ãƒ«æ¬¡å…ƒ: dim={t.dim()}\")\n","\n","in_dim   = sample.x.size(-1)\n","edge_dim = sample.edge_attr.size(-1)\n","g_dim    = infer_feat_dim(sample.g)\n","r_dim    = infer_feat_dim(sample.r)\n","\n","# ãƒ©ãƒ™ãƒ« & CID ã‚’æŠ½å‡º\n","labels = [int(d.y.item()) for d in data_list]\n","pos = sum(labels); neg = len(labels) - pos\n","print(f\"[INFO] Graphs: {len(data_list)} | x_dim={in_dim} | edge_dim={edge_dim} | g_dim={g_dim} | r_dim={r_dim}\")\n","print(f\"[INFO] Label balance: pos={pos} neg={neg} (pos_ratio={pos/len(labels):.3f})\")\n","\n","cids = [getattr(d, \"cid\", -1) for d in data_list]\n","has_cid_attr = any(getattr(d, \"cid\", None) is not None for d in data_list)\n","if not has_cid_attr:\n","    print(\"âš  æ³¨æ„: data_list ã®ã‚µãƒ³ãƒ—ãƒ«ã« d.cid ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å„ªå…ˆCIDã®å›ºå®šã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚\")\n","priority_idx = [i for i, c in enumerate(cids) if c in PRIORITY_CIDS] if has_cid_attr else []\n","priority_idx_set = set(priority_idx)\n","print(f\"[INFO] Priority CIDs present: {len(priority_idx)} / {len(PRIORITY_CIDS)}\")\n","if len(priority_idx) > 0:\n","    found = sorted({cids[i] for i in priority_idx})\n","    print(f\"[INFO] Found priority CIDs in data: {found}\")\n","\n","# ====== ç•³ã¿è¾¼ã¿ãƒ¦ãƒ‹ãƒƒãƒˆ ======\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hidden = max(64, min(256, in_attr_dim * 8))\n","    return nn.Sequential(\n","        nn.Linear(in_attr_dim, hidden), nn.ReLU(),\n","        nn.Linear(hidden, in_channels * out_channels)\n","    )\n","\n","def get_conv(name, c_in, c_out, edge_dim):\n","    if name == \"GINE\":\n","        return GINEConv(nn.Sequential(\n","            nn.Linear(c_in, c_out), nn.ReLU(), nn.Linear(c_out, c_out)\n","        ), edge_dim=edge_dim)\n","    if name == \"GATv2\":\n","        return GATv2Conv(c_in, c_out, heads=4, concat=False,\n","                         edge_dim=edge_dim, fill_value='mean')\n","    if name == \"NNConv\":\n","        edge_nn = make_edge_mlp(edge_dim, c_out, c_in)\n","        return NNConv(c_in, c_out, edge_nn, aggr='mean')\n","    if name == \"Transformer\":\n","        return TransformerConv(c_in, c_out, heads=4, concat=False,\n","                               edge_dim=edge_dim, dropout=0.0, beta=False)\n","    raise ValueError(f\"unknown arch: {name}\")\n","\n","# ====== å…±é€šãƒ¢ãƒ‡ãƒ«ï¼ˆd.x â†’ GNN â†’ pool â†’ [g,r]çµåˆ â†’ clsï¼‰ ======\n","class Net(nn.Module):\n","    def __init__(self, arch, in_dim, edge_dim, g_dim, r_dim, hid=256, p_drop=0.2):\n","        super().__init__()\n","        self.arch = arch\n","        self.c1 = get_conv(arch, in_dim, hid, edge_dim)\n","        self.c2 = get_conv(arch, hid, hid, edge_dim)\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(hid, 1))\n","        self.drop = nn.Dropout(p_drop)\n","        self.fc   = nn.Linear(hid + g_dim + r_dim, 1)\n","\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.drop(x)\n","        x = self.pool(x, d.batch)\n","\n","        g = d.g; r = d.r\n","        if g.dim() == 3: g = g.squeeze(1)\n","        elif g.dim() == 1: g = g.view(d.num_graphs, -1)\n","        if r.dim() == 3: r = r.squeeze(1)\n","        elif r.dim() == 1: r = r.view(d.num_graphs, -1)\n","\n","        z = torch.cat([x.float(), g.float(), r.float()], dim=1)\n","        return self.fc(z).view(-1)\n","\n","# ====== å­¦ç¿’é–¢æ•°ï¼ˆd.wãƒ»d.sample_weightãƒ»pos_weight ã‚’åæ˜ ï¼‰ ======\n","def train_fold(net, tr_loader, va_loader, pos_weight, save_path):\n","    bce = nn.BCEWithLogitsLoss(reduction='none')  # å¾Œã§é‡ã¿ä»˜ã‘\n","    opt = torch.optim.AdamW(net.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n","    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, TMAX)\n","\n","    # â˜… é‡ã¿ã‚µãƒãƒªï¼ˆä»»æ„ãƒ­ã‚°ï¼‰\n","    try:\n","        _w_list  = torch.cat([getattr(d, \"w\", torch.tensor([1.0])) for d in tr_loader.dataset]).float().cpu().numpy()\n","    except Exception:\n","        _w_list = np.ones(len(tr_loader.dataset), dtype=float)\n","    try:\n","        _sw_list = torch.cat([getattr(d, \"sample_weight\", torch.tensor([1.0])) for d in tr_loader.dataset]).float().cpu().numpy()\n","    except Exception:\n","        _sw_list = np.ones(len(tr_loader.dataset), dtype=float)\n","    print(f\"[train] mean(w)={np.mean(_w_list):.2f}, mean(SampleWeight)={np.mean(_sw_list):.2f}\")\n","\n","    best_auc, wait, best_state = 0.0, 0, None\n","    max_epochs = 200\n","\n","    for ep in range(1, max_epochs + 1):\n","        net.train()\n","        for bt in tr_loader:\n","            bt = bt.to(DEVICE)\n","            opt.zero_grad()\n","\n","            logits = net(bt)\n","            y = bt.y.float().view(-1)\n","\n","            # åŸºæœ¬ãƒ­ã‚¹ï¼ˆã‚µãƒ³ãƒ—ãƒ«æ¯ï¼‰\n","            loss_vec = bce(logits, y)\n","\n","            # ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡è£œæ­£: æ­£ä¾‹ã« pos_weightã€è² ä¾‹ã« 1\n","            cls_w = torch.where(\n","                y > 0.5,\n","                torch.tensor(pos_weight, device=DEVICE, dtype=loss_vec.dtype),\n","                torch.tensor(1.0,       device=DEVICE, dtype=loss_vec.dtype),\n","            )\n","\n","            # â˜… ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ï¼š d.w Ã— d.sample_weightï¼ˆç„¡ã‘ã‚Œã°1ï¼‰\n","            w1 = bt.w.view(-1) if hasattr(bt, \"w\") else torch.ones_like(y)\n","            w2 = getattr(bt, \"sample_weight\", torch.ones_like(y)).view(-1)\n","            samp_w = (w1 * w2).to(loss_vec.dtype)\n","\n","            # â˜… é‡ã¿ä»˜ãå¹³å‡ï¼ˆåˆ†æ¯ã¯é‡ã¿å’Œï¼‰\n","            loss = (loss_vec * cls_w * samp_w).sum() / (samp_w.sum() + 1e-12)\n","\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(net.parameters(), CLIP)\n","            opt.step()\n","        sch.step()\n","\n","        # æ¤œè¨¼ï¼ˆé‡ã¿ã¯ä½¿ã‚ãšç´ ã®ç¢ºç‡ã§è©•ä¾¡ï¼‰\n","        net.eval(); ys, ps = [], []\n","        with torch.no_grad():\n","            for bt in va_loader:\n","                bt = bt.to(DEVICE)\n","                ys += bt.y.cpu().tolist()\n","                ps += torch.sigmoid(net(bt)).cpu().tolist()\n","        auc = roc_auc_score(ys, ps)\n","\n","        if auc > best_auc:\n","            best_auc, wait = auc, 0\n","            best_state = net.state_dict()\n","            torch.save(best_state, save_path)\n","        else:\n","            wait += 1\n","            if wait >= PAT:\n","                break\n","\n","    if best_state is not None:\n","        net.load_state_dict(best_state)\n","    return net\n","\n","# ====== K-Fold å­¦ç¿’ãƒ»è©•ä¾¡ ======\n","skf = StratifiedKFold(n_splits=KFOLD, shuffle=True, random_state=SEED)\n","all_summary_rows = []\n","\n","def enforce_priority_in_train(tr_idx, va_idx):\n","    \"\"\"æ¤œè¨¼å´ã«æ··å…¥ã—ãŸ priority ã‚’å­¦ç¿’ã¸ç§»ã—ã€å¯èƒ½ãªã‚‰åŒãƒ©ãƒ™ãƒ«ã®éå„ªå…ˆã‚’å­¦ç¿’â†’æ¤œè¨¼ã¸ã‚¹ãƒ¯ãƒƒãƒ—\"\"\"\n","    if len(priority_idx) == 0:\n","        return tr_idx, va_idx, 0, 0\n","    tr_set, va_set = set(tr_idx.tolist()), set(va_idx.tolist())\n","    pri_in_val = [i for i in va_idx.tolist() if i in priority_idx_set]\n","    moved_to_train = 0\n","    swapped = 0\n","    if len(pri_in_val) == 0:\n","        return tr_idx, va_idx, moved_to_train, swapped\n","\n","    tr_list = tr_idx.tolist()\n","    va_list = va_idx.tolist()\n","\n","    for i_pri in pri_in_val:\n","        # ã¾ãš validation ã‹ã‚‰å¤–ã™\n","        if i_pri in va_list:\n","            va_list.remove(i_pri)\n","        # å­¦ç¿’ã¸å…¥ã‚Œã‚‹\n","        if i_pri not in tr_list:\n","            tr_list.append(i_pri)\n","            moved_to_train += 1\n","\n","        # ã‚µã‚¤ã‚ºã¨ãƒãƒ©ãƒ³ã‚¹ã‚’è»½ãç¶­æŒï¼šåŒãƒ©ãƒ™ãƒ«ã®éå„ªå…ˆã‚’ã‚¹ãƒ¯ãƒƒãƒ—ï¼ˆä»»æ„ï¼‰\n","        y_pri = labels[i_pri]\n","        candidate = None\n","        for j in tr_list:\n","            if j in priority_idx_set:\n","                continue\n","            if labels[j] == y_pri and j not in va_list:\n","                candidate = j\n","                break\n","        if candidate is not None:\n","            tr_list.remove(candidate)\n","            va_list.append(candidate)\n","            swapped += 1\n","\n","    return np.array(sorted(set(tr_list))), np.array(sorted(set(va_list))), moved_to_train, swapped\n","\n","for arch in ARCHES:\n","    print(f\"\\n================ {arch} (d.x + d.g + d.r + edge_attr) ================\")\n","    fold_rows = []\n","    arch_dir = os.path.join(SAVE_BASE, arch)\n","\n","    for f, (tr_idx, va_idx) in enumerate(skf.split(np.zeros(len(labels)), labels)):\n","        # â˜… æ¤œè¨¼foldã‹ã‚‰priorityã‚’é™¤å¤–ã—ã¦å­¦ç¿’foldã¸\n","        tr_idx, va_idx, moved_cnt, swap_cnt = enforce_priority_in_train(tr_idx, va_idx)\n","        if moved_cnt > 0:\n","            print(f\"[Fold {f}] moved priority from valâ†’train: {moved_cnt}  | swapped (trainâ†’val): {swap_cnt}\")\n","\n","        tr_ds = [data_list[i] for i in tr_idx]\n","        va_ds = [data_list[i] for i in va_idx]\n","\n","        # pos_weight ã¯ foldã”ã¨ã«ç®—å‡ºï¼ˆéå¤§ã«ãªã‚‰ãªã„ã‚ˆã†ä¸Šé™ï¼‰\n","        ytr = torch.cat([d.y.view(-1) for d in tr_ds]).float()\n","        neg = (ytr == 0).sum().item(); posc = (ytr == 1).sum().item()\n","        w = min((neg / max(posc, 1.0)), 10.0)\n","\n","        tr_loader = DataLoader(tr_ds, batch_size=BATCH, shuffle=True,\n","                               generator=torch.Generator().manual_seed(SEED))\n","        va_loader = DataLoader(va_ds, batch_size=BATCH, shuffle=False)\n","\n","        net = Net(arch, in_dim, edge_dim, g_dim, r_dim, hid=HID).to(DEVICE)\n","        save_model_path = os.path.join(arch_dir, f\"fold{f}.pt\")\n","        net = train_fold(net, tr_loader, va_loader, pos_weight=w, save_path=save_model_path)\n","\n","        # foldå†…æ¤œè¨¼ã‚¹ã‚³ã‚¢\n","        net.eval(); ys, ps = [], []\n","        with torch.no_grad():\n","            for bt in va_loader:\n","                bt = bt.to(DEVICE)\n","                ys += bt.y.cpu().tolist()\n","                ps += torch.sigmoid(net(bt)).cpu().tolist()\n","\n","        y_pred = [int(p >= 0.5) for p in ps]\n","        metrics = {\n","            \"Fold\": f,\n","            \"ROC-AUC\": roc_auc_score(ys, ps),\n","            \"PR-AUC\": average_precision_score(ys, ps),\n","            \"Precision\": precision_score(ys, y_pred, zero_division=0),\n","            \"Recall\": recall_score(ys, y_pred, zero_division=0),\n","            \"F1-Score\": f1_score(ys, y_pred, zero_division=0),\n","            \"Val_Size\": len(va_idx),\n","            \"Train_Size\": len(tr_idx),\n","        }\n","        print(\"Fold{}: ROC {:.4f} | PR {:.4f} | P {:.4f} | R {:.4f} | F1 {:.4f} | Train {} | Val {}\".format(\n","            f, metrics[\"ROC-AUC\"], metrics[\"PR-AUC\"], metrics[\"Precision\"], metrics[\"Recall\"], metrics[\"F1-Score\"],\n","            metrics[\"Train_Size\"], metrics[\"Val_Size\"]\n","        ))\n","        fold_rows.append(metrics)\n","\n","    df_metrics = pd.DataFrame(fold_rows)\n","    df_metrics.to_csv(os.path.join(arch_dir, \"metrics_foldwise.csv\"), index=False)\n","\n","    mean_row = df_metrics[[\"ROC-AUC\",\"PR-AUC\",\"Precision\",\"Recall\",\"F1-Score\"]].mean()\n","    std_row  = df_metrics[[\"ROC-AUC\",\"PR-AUC\",\"Precision\",\"Recall\",\"F1-Score\"]].std()\n","\n","    df_summary = pd.DataFrame({\n","        \"Metric\": [\"ROC-AUC\",\"PR-AUC\",\"Precision\",\"Recall\",\"F1-Score\"],\n","        \"Mean\":   [mean_row[m] for m in mean_row.index],\n","        \"SD\":     [std_row[m]  for m in std_row.index],\n","    })\n","    df_summary.to_csv(os.path.join(arch_dir, \"metrics_summary.csv\"), index=False)\n","\n","    print(\"\\n[{}] å¹³å‡Â±SD\".format(arch))\n","    for col in [\"ROC-AUC\", \"PR-AUC\", \"Precision\", \"Recall\", \"F1-Score\"]:\n","        print(f\"{col}: {mean_row[col]:.4f} Â± {std_row[col]:.4f}\")\n","\n","    all_summary_rows.append({\n","        \"Arch\": arch,\n","        **{f\"{k}_Mean\": mean_row[k] for k in mean_row.index},\n","        **{f\"{k}_SD\":   std_row[k]  for k in std_row.index},\n","    })\n","\n","pd.DataFrame(all_summary_rows).to_csv(\n","    os.path.join(SAVE_BASE, \"metrics_all_summary.csv\"), index=False\n",")\n","\n","print(f\"\\nâœ… å®Œäº†: ä¿å­˜å…ˆ {SAVE_BASE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h5Mocp9eS6Lp","executionInfo":{"status":"ok","timestamp":1760680259954,"user_tz":-540,"elapsed":825698,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"0a575128-2869-42ea-c3a2-7fbe4c7761af"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Graphs: 7321 | x_dim=5 | edge_dim=6 | g_dim=7 | r_dim=10\n","[INFO] Label balance: pos=1524 neg=5797 (pos_ratio=0.208)\n","[INFO] Priority CIDs present: 30 / 7\n","[INFO] Found priority CIDs in data: [3348, 3955, 13342, 68770, 10315094]\n","\n","================ GINE (d.x + d.g + d.r + edge_attr) ================\n","[Fold 0] moved priority from valâ†’train: 9  | swapped (trainâ†’val): 9\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold0: ROC 0.7720 | PR 0.4413 | P 0.3255 | R 0.8406 | F1 0.4692 | Train 4880 | Val 2441\n","[Fold 1] moved priority from valâ†’train: 14  | swapped (trainâ†’val): 14\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold1: ROC 0.8703 | PR 0.6002 | P 0.4438 | R 0.8543 | F1 0.5841 | Train 4881 | Val 2440\n","[Fold 2] moved priority from valâ†’train: 7  | swapped (trainâ†’val): 7\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold2: ROC 0.8499 | PR 0.5394 | P 0.4157 | R 0.8543 | F1 0.5593 | Train 4881 | Val 2440\n","\n","[GINE] å¹³å‡Â±SD\n","ROC-AUC: 0.8308 Â± 0.0519\n","PR-AUC: 0.5270 Â± 0.0802\n","Precision: 0.3950 Â± 0.0618\n","Recall: 0.8497 Â± 0.0080\n","F1-Score: 0.5375 Â± 0.0604\n","\n","================ GATv2 (d.x + d.g + d.r + edge_attr) ================\n","[Fold 0] moved priority from valâ†’train: 9  | swapped (trainâ†’val): 9\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold0: ROC 0.8033 | PR 0.4511 | P 0.3584 | R 0.8720 | F1 0.5080 | Train 4880 | Val 2441\n","[Fold 1] moved priority from valâ†’train: 14  | swapped (trainâ†’val): 14\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold1: ROC 0.8067 | PR 0.4583 | P 0.3698 | R 0.8445 | F1 0.5144 | Train 4881 | Val 2440\n","[Fold 2] moved priority from valâ†’train: 7  | swapped (trainâ†’val): 7\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold2: ROC 0.8813 | PR 0.5735 | P 0.4649 | R 0.8602 | F1 0.6036 | Train 4881 | Val 2440\n","\n","[GATv2] å¹³å‡Â±SD\n","ROC-AUC: 0.8304 Â± 0.0441\n","PR-AUC: 0.4943 Â± 0.0687\n","Precision: 0.3977 Â± 0.0585\n","Recall: 0.8589 Â± 0.0138\n","F1-Score: 0.5420 Â± 0.0534\n","\n","================ NNConv (d.x + d.g + d.r + edge_attr) ================\n","[Fold 0] moved priority from valâ†’train: 9  | swapped (trainâ†’val): 9\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold0: ROC 0.8442 | PR 0.5404 | P 0.4384 | R 0.8406 | F1 0.5762 | Train 4880 | Val 2441\n","[Fold 1] moved priority from valâ†’train: 14  | swapped (trainâ†’val): 14\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold1: ROC 0.8257 | PR 0.5072 | P 0.3967 | R 0.8583 | F1 0.5426 | Train 4881 | Val 2440\n","[Fold 2] moved priority from valâ†’train: 7  | swapped (trainâ†’val): 7\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold2: ROC 0.8468 | PR 0.5340 | P 0.4291 | R 0.8701 | F1 0.5748 | Train 4881 | Val 2440\n","\n","[NNConv] å¹³å‡Â±SD\n","ROC-AUC: 0.8389 Â± 0.0115\n","PR-AUC: 0.5272 Â± 0.0176\n","Precision: 0.4214 Â± 0.0219\n","Recall: 0.8563 Â± 0.0149\n","F1-Score: 0.5645 Â± 0.0190\n","\n","================ Transformer (d.x + d.g + d.r + edge_attr) ================\n","[Fold 0] moved priority from valâ†’train: 9  | swapped (trainâ†’val): 9\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold0: ROC 0.8737 | PR 0.5722 | P 0.4472 | R 0.8917 | F1 0.5957 | Train 4880 | Val 2441\n","[Fold 1] moved priority from valâ†’train: 14  | swapped (trainâ†’val): 14\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold1: ROC 0.9151 | PR 0.6821 | P 0.6349 | R 0.7736 | F1 0.6974 | Train 4881 | Val 2440\n","[Fold 2] moved priority from valâ†’train: 7  | swapped (trainâ†’val): 7\n","[train] mean(w)=1.00, mean(SampleWeight)=0.75\n","Fold2: ROC 0.9170 | PR 0.7183 | P 0.5167 | R 0.9134 | F1 0.6600 | Train 4881 | Val 2440\n","\n","[Transformer] å¹³å‡Â±SD\n","ROC-AUC: 0.9019 Â± 0.0245\n","PR-AUC: 0.6575 Â± 0.0761\n","Precision: 0.5329 Â± 0.0949\n","Recall: 0.8596 Â± 0.0752\n","F1-Score: 0.6510 Â± 0.0515\n","\n","âœ… å®Œäº†: ä¿å­˜å…ˆ /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_gnn_dx_dg_dr_cv_edgeall\n"]}]},{"cell_type":"code","source":["# =============================================================\n","# TransformerConv + NNConv ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆd.x + d.g + d.r, edge_attrï¼‰\n","# 5-fold CV / å­¦ç¿’æ›²ç·šãƒ»ROCãƒ»PRæ›²ç·š / ãƒ­ã‚¸ãƒƒãƒˆåŠ é‡å¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«\n","# â˜…å„ªå…ˆCIDï¼ˆ7åŒ–åˆç‰©ï¼‰ã¯å¸¸ã«å­¦ç¿’ã‚»ãƒƒãƒˆã¸å›ºå®šï¼ˆæ¤œè¨¼ã«ã¯å‡ºã•ãªã„ï¼‰\n","# å…¥åŠ›: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\n","# å‡ºåŠ›: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_5fold/\n","# + SampleWeightå¯¾å¿œï¼ˆå­¦ç¿’æå¤±ã¯å¿…ãšåŠ é‡ã€æ¤œè¨¼æŒ‡æ¨™ã¯ä»»æ„ã§åŠ é‡ï¼‰\n","# =============================================================\n","\n","import os, torch, random\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import numpy as np, pandas as pd\n","import matplotlib.pyplot as plt\n","from torch.serialization import add_safe_globals\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","from torch_geometric.loader import DataLoader\n","from sklearn.model_selection import StratifiedKFold\n","from sklearn.metrics import (\n","    roc_auc_score, average_precision_score,\n","    precision_score, recall_score, f1_score,\n","    roc_curve, precision_recall_curve, auc\n",")\n","\n","# ----- äº‹å‰æº–å‚™ & è¿½åŠ è¨­å®šï¼ˆâ˜…ï¼‰ -----\n","SEED = 42\n","torch.manual_seed(SEED); random.seed(SEED); np.random.seed(SEED)\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","DATA_PATH = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\"\n","SAVE_DIR  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_5fold\"\n","PLOT_DIR  = os.path.join(SAVE_DIR, \"plots\")\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","\n","# â˜… é‡ã¿å±æ€§ã®å€™è£œï¼ˆä¸Šã‹ã‚‰é †ã«æ¢ç´¢ï¼‰\n","WEIGHT_ATTR_CANDIDATES = [\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]\n","# â˜… æ¤œè¨¼ã§ã‚‚é‡ã¿ã‚’ä½¿ã†ã‹ï¼ˆTrueæ¨å¥¨ã€‚å¤–éƒ¨æ¯”è¼ƒã§éåŠ é‡ã«ã—ãŸã„å ´åˆã¯ Falseï¼‰\n","APPLY_WEIGHT_IN_VAL = True\n","\n","BATCH_TRAIN = 64\n","BATCH_VAL   = 128\n","HID = 256\n","LR  = 3e-4\n","WEIGHT_DECAY = 1e-4\n","PATIENCE = 10\n","TMAX = 10\n","CLIP = 5\n","MAX_EPOCHS = 200\n","\n","# ----- å„ªå…ˆCIDï¼ˆå¸¸ã«å­¦ç¿’ã¸å›ºå®šï¼‰-----\n","PRIORITY_CIDS = {3348, 3955, 2724385, 10315094, 68770, 13342, 441074}\n","\n","# ----- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆPyTorch 2.6 å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰ -----\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr])\n","    except Exception as e:\n","        print(f\"[WARN] add_safe_globals å¤±æ•—: {e}\")\n","    try:\n","        obj = torch.load(path)  # weights_only=True æ—¢å®š\n","    except Exception as e:\n","        print(f\"[WARN] å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆ{e}ï¼‰ã€‚weights_only=False ã§å†è©¦è¡Œã—ã¾ã™ï¼ˆä¿¡é ¼ãƒ•ã‚¡ã‚¤ãƒ«å‰æï¼‰ã€‚\")\n","        obj = torch.load(path, weights_only=False)\n","\n","    if isinstance(obj, list):\n","        return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj:\n","        return obj[\"data_list\"]\n","    try:\n","        return list(obj)\n","    except Exception as e:\n","        raise RuntimeError(f\"æœªçŸ¥ã®å½¢å¼: {type(obj)}; liståŒ–å¤±æ•—: {e}\")\n","\n","data = load_pyg_list(DATA_PATH)\n","if len(data) == 0:\n","    raise RuntimeError(\"data ãŒç©ºã§ã™ã€‚\")\n","\n","# ----- ãƒ©ãƒ™ãƒ« & CID ã‚’æŠ½å‡º -----\n","labels = [int(d.y.item()) for d in data]\n","cids   = [int(getattr(d, \"cid\", -1)) for d in data]  # è¿½åŠ æ¸ˆã¿cidã‚’å‚ç…§ï¼ˆæ¬ æã¯ -1ï¼‰\n","\n","# å„ªå…ˆCIDã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æŠ½å‡º\n","priority_idx = [i for i, cid in enumerate(cids) if cid in PRIORITY_CIDS]\n","non_priority_idx = [i for i in range(len(data)) if i not in priority_idx]\n","\n","print(f\"[INFO] å…¨ã‚µãƒ³ãƒ—ãƒ«: {len(data)} | å„ªå…ˆCIDãƒ’ãƒƒãƒˆä»¶æ•°: {len(priority_idx)}\")\n","if len(priority_idx) == 0:\n","    print(\"[WARN] å„ªå…ˆCIDã«è©²å½“ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ï¼ˆcid==-1å«ã‚€ï¼‰ã€‚\")\n","else:\n","    _, counts = np.unique([cids[i] for i in priority_idx], return_counts=True)\n","    unique_cids = sorted(set([cids[i] for i in priority_idx]))\n","    print(\"[INFO] å„ªå…ˆCIDä¸€è¦§:\", unique_cids)\n","    print(\"[INFO] å„ªå…ˆCIDã®åˆè¨ˆã‚°ãƒ©ãƒ•æ•°ï¼ˆæ‹¡å¼µå«ã‚€ï¼‰:\", int(sum(counts)))\n","\n","# ----- æ¬¡å…ƒã‚’è‡ªå‹•å–å¾— -----\n","sample = data[0]\n","def infer_feat_dim(t):\n","    if t is None: return 0\n","    if t.dim() == 1: return t.numel()\n","    if t.dim() in (2,3): return t.size(-1)\n","    raise RuntimeError(f\"æœªçŸ¥ã®ãƒ†ãƒ³ã‚½ãƒ«æ¬¡å…ƒ: dim={t.dim()}\")\n","\n","X_DIM   = sample.x.size(-1)\n","E_DIM   = sample.edge_attr.size(-1)\n","G_DIM   = infer_feat_dim(sample.g)\n","R_DIM   = infer_feat_dim(sample.r)\n","print(f\"[INFO] Dims: x={X_DIM}, edge={E_DIM}, g={G_DIM}, r={R_DIM}\")\n","\n","# ----- ãƒ¢ãƒ‡ãƒ«å®šç¾© -----\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.c1 = TransformerConv(X_DIM, HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.c2 = TransformerConv(HID,  HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x, g, r], dim=1)).view(-1)  # logits\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hidden = max(64, min(256, in_attr_dim * 8))\n","    return nn.Sequential(nn.Linear(in_attr_dim, hidden), nn.ReLU(),\n","                         nn.Linear(hidden, in_channels * out_channels))\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        edge_nn1 = make_edge_mlp(E_DIM, HID, X_DIM)\n","        edge_nn2 = make_edge_mlp(E_DIM, HID, HID)\n","        self.c1 = NNConv(X_DIM, HID, edge_nn1, aggr='mean')\n","        self.c2 = NNConv(HID,  HID, edge_nn2, aggr='mean')\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x, g, r], dim=1)).view(-1)  # logits\n","\n","# ----- é‡ã¿ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆâ˜…ï¼‰ -----\n","def _find_weight_attr(d):\n","    for name in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(d, name):\n","            return name\n","    return None\n","\n","def _to_1d_weight(t):\n","    \"\"\"\n","    DataLoaderå¾Œã® batch.<attr> ã¯ [N] or [N,1] ã®å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ 1DåŒ–\n","    \"\"\"\n","    if t is None: return None\n","    if t.dim() == 2 and t.size(1) == 1:\n","        return t.view(-1)\n","    return t.view(-1)\n","\n","def get_batch_weights(batch, device=None):\n","    name = None\n","    for cand in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(batch, cand):\n","            name = cand; break\n","    if name is None:\n","        # 1.0ã§åŸ‹ã‚ã‚‹\n","        n = batch.y.numel()\n","        return torch.ones(n, dtype=torch.float, device=device or batch.y.device), \"CONST1\"\n","    w = getattr(batch, name)\n","    w = _to_1d_weight(w).to(device or batch.y.device).float()\n","    return w, name\n","\n","# ----- è£œåŠ©: ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜ -----\n","def _ensure_dir(path): os.makedirs(path, exist_ok=True)\n","\n","def plot_curve(xs, ys, title, xlabel, ylabel, save_path):\n","    plt.figure(); plt.plot(xs, ys)\n","    plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)\n","    plt.tight_layout(); plt.savefig(save_path); plt.close()\n","\n","def save_roc_pr_curves(y_true, y_prob, title_prefix, out_dir, sample_weight=None):\n","    _ensure_dir(out_dir)\n","    fpr, tpr, _ = roc_curve(y_true, y_prob, sample_weight=sample_weight)\n","    roc_auc = auc(fpr, tpr)\n","    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n","    plt.plot([0,1],[0,1],'--', linewidth=1)\n","    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"{title_prefix} ROC\")\n","    plt.legend(); plt.tight_layout()\n","    plt.savefig(os.path.join(out_dir, f\"{title_prefix}_ROC.png\")); plt.close()\n","    prec, rec, _ = precision_recall_curve(y_true, y_prob, sample_weight=sample_weight)\n","    ap = average_precision_score(y_true, y_prob, sample_weight=sample_weight)\n","    plt.figure(); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n","    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"{title_prefix} PR\")\n","    plt.legend(); plt.tight_layout()\n","    plt.savefig(os.path.join(out_dir, f\"{title_prefix}_PR.png\")); plt.close()\n","\n","def best_f1_threshold(y_true, y_prob, sample_weight=None):\n","    prec, rec, thr = precision_recall_curve(y_true, y_prob, sample_weight=sample_weight)\n","    thr = np.append(thr, 1.0)\n","    f1s = 2 * prec * rec / np.clip(prec + rec, 1e-9, None)\n","    i = np.nanargmax(f1s)\n","    return float(thr[i]), float(f1s[i])\n","\n","# ----- å­¦ç¿’é–¢æ•°ï¼ˆâ˜… é‡ã¿å¯¾å¿œï¼‰ -----\n","def train_fold(model, tr_loader, va_loader, fold, save_path, model_name, apply_weight_in_val=True):\n","    # ---- pos_weight ã‚’ã€Œé‡ã¿ä»˜ãå®ŸåŠ¹æ¯”ã€ã‹ã‚‰è¨ˆç®—ï¼ˆæœ€å¤§10ã«ã‚¯ãƒªãƒƒãƒ—ï¼‰ ----\n","    # tr_loader.dataset ã¯ list[Data] ã‚’æƒ³å®š\n","    y_list, w_list = [], []\n","    for d in tr_loader.dataset:\n","        y_list.append(int(d.y.item()))\n","        # ã‚µãƒ³ãƒ—ãƒ«æ¯ã®é‡ã¿ã‚’å–å¾—ï¼ˆç„¡ã‘ã‚Œã°1ï¼‰\n","        w = None\n","        for cand in WEIGHT_ATTR_CANDIDATES:\n","            if hasattr(d, cand):\n","                a = getattr(d, cand)\n","                # a ã¯ tensor([w]) ã¾ãŸã¯ float ã‚’æƒ³å®š\n","                w = float(a.item()) if torch.is_tensor(a) else float(a)\n","                break\n","        if w is None: w = 1.0\n","        w_list.append(w)\n","    ytr = torch.tensor(y_list, dtype=torch.float)\n","    wtr = torch.tensor(w_list, dtype=torch.float)\n","    pos_w = (wtr[ytr==0].sum() / torch.clamp(wtr[ytr==1].sum(), min=1e-8)).item()\n","    pos_w = float(min(max(pos_w, 1.0), 10.0))\n","\n","    criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([pos_w], device=DEVICE),\n","                                     reduction='none')  # â† per-sample\n","    opt = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n","    sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=TMAX)\n","\n","    history = {\"epoch\": [], \"train_loss\": [], \"val_auc\": [], \"val_prauc\": []}\n","    best_auc, best_state, wait = 0.0, None, 0\n","\n","    print(f\"[INFO] fold{fold} pos_weight(eff)={pos_w:.3f}\")\n","\n","    for ep in range(1, MAX_EPOCHS + 1):\n","        model.train(); epoch_losses = []\n","        for batch in tr_loader:\n","            batch = batch.to(DEVICE)\n","            logits = model(batch)\n","            # per-sample loss\n","            loss_vec = criterion(logits, batch.y.float())\n","            sw, used_attr = get_batch_weights(batch, DEVICE)\n","            # åŠ é‡å¹³å‡ï¼ˆåˆ†æ¯=é‡ã¿åˆè¨ˆï¼‰\n","            loss = (loss_vec * sw).sum() / (sw.sum() + 1e-8)\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n","            opt.step()\n","            epoch_losses.append(loss.item())\n","        sch.step()\n","\n","        # æ¤œè¨¼\n","        model.eval(); ys, ps, ws = [], [], []\n","        with torch.no_grad():\n","            for batch in va_loader:\n","                batch = batch.to(DEVICE)\n","                ys += batch.y.cpu().tolist()\n","                ps += torch.sigmoid(model(batch)).cpu().tolist()\n","                sw, _ = get_batch_weights(batch, DEVICE)\n","                ws += sw.detach().cpu().tolist()\n","\n","        if apply_weight_in_val:\n","            auc_val = roc_auc_score(ys, ps, sample_weight=ws)\n","            pr_val  = average_precision_score(ys, ps, sample_weight=ws)\n","        else:\n","            auc_val = roc_auc_score(ys, ps)\n","            pr_val  = average_precision_score(ys, ps)\n","\n","        history[\"epoch\"].append(ep)\n","        history[\"train_loss\"].append(float(np.mean(epoch_losses)))\n","        history[\"val_auc\"].append(float(auc_val))\n","        history[\"val_prauc\"].append(float(pr_val))\n","\n","        if auc_val > best_auc:\n","            best_auc, wait = auc_val, 0\n","            best_state = model.state_dict()\n","            torch.save(best_state, save_path)\n","        else:\n","            wait += 1\n","            if wait >= PATIENCE:\n","                print(f\"âœ… EarlyStopped [{model_name}] (fold{fold}) at epoch {ep}\")\n","                break\n","\n","    model.load_state_dict(best_state)\n","    return model, history\n","\n","# ----- Cross Validationï¼ˆ5-foldï¼‰ï¼šå„ªå…ˆCIDã‚’å¸¸ã«å­¦ç¿’ã¸å›ºå®š -----\n","kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=SEED)\n","metrics_tr_list, metrics_nn_list, metrics_ens_list = [], [], []\n","\n","# åˆ†å‰²å¯¾è±¡ã¯ã€Œéå„ªå…ˆã€ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ã§è¡Œã„ã€å„foldã®å­¦ç¿’å´ã«å„ªå…ˆã‚µãƒ³ãƒ—ãƒ«ã‚’è¿½åŠ \n","non_priority_labels = np.array([labels[i] for i in non_priority_idx])\n","non_priority_idx    = np.array(non_priority_idx, dtype=int)\n","priority_idx        = np.array(priority_idx, dtype=int)\n","\n","fold_counter = 0\n","for tr_np, va_np in kf.split(np.zeros(len(non_priority_idx)), non_priority_labels):\n","    # éå„ªå…ˆã®foldåˆ†å‰²çµæœ â†’ å®Ÿã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¸å¤‰æ›\n","    tr_base = non_priority_idx[tr_np]\n","    va_base = non_priority_idx[va_np]\n","\n","    # å­¦ç¿’ = éå„ªå…ˆã®å­¦ç¿’ + å…¨å„ªå…ˆ\n","    tr_idx = np.concatenate([tr_base, priority_idx]).astype(int)\n","    # æ¤œè¨¼ = éå„ªå…ˆã®æ¤œè¨¼ï¼ˆå„ªå…ˆã¯ä¸€åˆ‡å«ã‚ãªã„ï¼‰\n","    va_idx = va_base.astype(int)\n","\n","    # å¿µã®ãŸã‚ãƒ¦ãƒ‹ãƒ¼ã‚¯åŒ–ï¼†è¡çªé™¤å»\n","    tr_idx = np.unique(tr_idx)\n","    va_idx = np.setdiff1d(np.unique(va_idx), priority_idx, assume_unique=False)\n","\n","    # foldã”ã¨ã®æƒ…å ±è¡¨ç¤ºï¼ˆé‡ã¿çµ±è¨ˆã‚‚è¡¨ç¤ºï¼‰ï¼ˆâ˜…ï¼‰\n","    def _stats(indices):\n","        ys = np.array([int(data[i].y.item()) for i in indices])\n","        # é‡ã¿å–ã‚Šå‡ºã—\n","        ws = []\n","        for i in indices:\n","            w = None\n","            for cand in WEIGHT_ATTR_CANDIDATES:\n","                if hasattr(data[i], cand):\n","                    a = getattr(data[i], cand)\n","                    w = float(a.item()) if torch.is_tensor(a) else float(a)\n","                    break\n","            if w is None: w = 1.0\n","            ws.append(w)\n","        ws = np.array(ws, dtype=float)\n","        return ys.mean(), ws.mean(), ws.min(), ws.max()\n","    y_bar_tr, w_bar_tr, w_min_tr, w_max_tr = _stats(tr_idx)\n","    y_bar_va, w_bar_va, w_min_va, w_max_va = _stats(va_idx)\n","\n","    print(f\"\\nğŸ“‚ Fold {fold_counter} | train={len(tr_idx)} val={len(va_idx)} | \"\n","          f\"train_w(mean/min/max)={w_bar_tr:.2f}/{w_min_tr:.2f}/{w_max_tr:.2f} | \"\n","          f\"val_w(mean/min/max)={w_bar_va:.2f}/{w_min_va:.2f}/{w_max_va:.2f}\")\n","\n","    tr_data = [data[i] for i in tr_idx]\n","    va_data = [data[i] for i in va_idx]\n","\n","    tr_loader = DataLoader(tr_data, batch_size=BATCH_TRAIN, shuffle=True, pin_memory=True)\n","    va_loader = DataLoader(va_data, batch_size=BATCH_VAL,   shuffle=False, pin_memory=True)\n","\n","    fold_plot_dir = os.path.join(PLOT_DIR, f\"fold{fold_counter}\")\n","    _ensure_dir(fold_plot_dir)\n","\n","    # ---- Transformer ----\n","    model_tr = Transformer_DX_DG_DR().to(DEVICE)\n","    path_tr  = f\"{SAVE_DIR}/transformer_fold{fold_counter}.pt\"\n","    model_tr, hist_tr = train_fold(model_tr, tr_loader, va_loader, fold_counter, path_tr, \"Transformer\",\n","                                   apply_weight_in_val=APPLY_WEIGHT_IN_VAL)\n","\n","    pd.DataFrame(hist_tr).to_csv(f\"{SAVE_DIR}/history_transformer_fold{fold_counter}.csv\", index=False)\n","    plot_curve(hist_tr[\"epoch\"], hist_tr[\"train_loss\"], f\"Transformer Fold{fold_counter} Train Loss\", \"Epoch\", \"Loss\",\n","               os.path.join(fold_plot_dir, \"Transformer_Loss.png\"))\n","    plot_curve(hist_tr[\"epoch\"], hist_tr[\"val_auc\"], f\"Transformer Fold{fold_counter} Val ROC-AUC\", \"Epoch\", \"ROC-AUC\",\n","               os.path.join(fold_plot_dir, \"Transformer_ValAUC.png\"))\n","    plot_curve(hist_tr[\"epoch\"], hist_tr[\"val_prauc\"], f\"Transformer Fold{fold_counter} Val PR-AUC\", \"Epoch\", \"PR-AUC\",\n","               os.path.join(fold_plot_dir, \"Transformer_ValPRAUC.png\"))\n","\n","    # ---- NNConv ----\n","    model_nn = NNConv_DX_DG_DR().to(DEVICE)\n","    path_nn  = f\"{SAVE_DIR}/nnconv_fold{fold_counter}.pt\"\n","    model_nn, hist_nn = train_fold(model_nn, tr_loader, va_loader, fold_counter, path_nn, \"NNConv\",\n","                                   apply_weight_in_val=APPLY_WEIGHT_IN_VAL)\n","\n","    pd.DataFrame(hist_nn).to_csv(f\"{SAVE_DIR}/history_nnconv_fold{fold_counter}.csv\", index=False)\n","    plot_curve(hist_nn[\"epoch\"], hist_nn[\"train_loss\"], f\"NNConv Fold{fold_counter} Train Loss\", \"Epoch\", \"Loss\",\n","               os.path.join(fold_plot_dir, \"NNConv_Loss.png\"))\n","    plot_curve(hist_nn[\"epoch\"], hist_nn[\"val_auc\"], f\"NNConv Fold{fold_counter} Val ROC-AUC\", \"Epoch\", \"ROC-AUC\",\n","               os.path.join(fold_plot_dir, \"NNConv_ValAUC.png\"))\n","    plot_curve(hist_nn[\"epoch\"], hist_nn[\"val_prauc\"], f\"NNConv Fold{fold_counter} Val PR-AUC\", \"Epoch\", \"PR-AUC\",\n","               os.path.join(fold_plot_dir, \"NNConv_ValPRAUC.png\"))\n","\n","    # ---- è©•ä¾¡ï¼ˆå„ãƒ¢ãƒ‡ãƒ«&ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«; ãƒ­ã‚¸ãƒƒãƒˆåŠ é‡å¹³å‡ï¼‰----\n","    def eval_logits_and_weights(m):\n","        m.eval(); ys, logits, ws = [], [], []\n","        with torch.no_grad():\n","            for batch in va_loader:\n","                batch = batch.to(DEVICE)\n","                ys += batch.y.cpu().tolist()\n","                logits += m(batch).cpu().tolist()  # ãƒ­ã‚¸ãƒƒãƒˆ\n","                sw, _ = get_batch_weights(batch, DEVICE)\n","                ws += sw.detach().cpu().tolist()\n","        return np.array(ys), np.array(logits), np.array(ws, dtype=float)\n","\n","    ys_tr, lg_tr, w_va = eval_logits_and_weights(model_tr)\n","    ys_nn, lg_nn, w_va2 = eval_logits_and_weights(model_nn)\n","    assert np.allclose(ys_tr, ys_nn)\n","    ys = ys_tr.tolist()\n","\n","    # ã¾ãšå„ãƒ¢ãƒ‡ãƒ«ã®ç¢ºç‡ã§PR-AUCã‚’ç®—å‡º â†’ ãã®é‡ã¿ã§ãƒ­ã‚¸ãƒƒãƒˆåŠ é‡å¹³å‡\n","    ps_tr = torch.sigmoid(torch.tensor(lg_tr)).numpy()\n","    ps_nn = torch.sigmoid(torch.tensor(lg_nn)).numpy()\n","    if APPLY_WEIGHT_IN_VAL:\n","        pr_tr = average_precision_score(ys, ps_tr, sample_weight=w_va)\n","        pr_nn = average_precision_score(ys, ps_nn, sample_weight=w_va)\n","    else:\n","        pr_tr = average_precision_score(ys, ps_tr)\n","        pr_nn = average_precision_score(ys, ps_nn)\n","\n","    a_tr = pr_tr / (pr_tr + pr_nn + 1e-12)\n","    a_nn = pr_nn / (pr_tr + pr_nn + 1e-12)\n","\n","    lg_ens = a_tr * lg_tr + a_nn * lg_nn\n","    ps_ens = torch.sigmoid(torch.tensor(lg_ens)).numpy()\n","\n","    def pack_metrics(y, p, name, sw=None):\n","        thr_opt, f1_opt = best_f1_threshold(y, p, sample_weight=sw if APPLY_WEIGHT_IN_VAL else None)\n","        y_pred05 = (p >= 0.5).astype(int)\n","        y_predF  = (p >= thr_opt).astype(int)\n","        if APPLY_WEIGHT_IN_VAL:\n","            roc = roc_auc_score(y, p, sample_weight=sw)\n","            pr  = average_precision_score(y, p, sample_weight=sw)\n","            # â€» precision/recall/f1 ã¯è¡¨ç¤ºç”¨ã«éåŠ é‡ï¼ˆâ€»å¿…è¦ãªã‚‰ sklearn ã«é‡ã¿ç‰ˆã¯ç„¡ã„ã®ã§æ‰‹è¨ˆç®—ã«å¤‰æ›´å¯ï¼‰\n","            prec05 = precision_score(y, y_pred05, zero_division=0)\n","            rec05  = recall_score(y, y_pred05, zero_division=0)\n","            f105   = f1_score(y, y_pred05, zero_division=0)\n","        else:\n","            roc = roc_auc_score(y, p)\n","            pr  = average_precision_score(y, p)\n","            prec05 = precision_score(y, y_pred05, zero_division=0)\n","            rec05  = recall_score(y, y_pred05, zero_division=0)\n","            f105   = f1_score(y, y_pred05, zero_division=0)\n","        return {\n","            \"Fold\": fold_counter, \"Model\": name,\n","            \"ROC-AUC\": roc, \"PR-AUC\": pr,\n","            \"Precision@0.5\": prec05, \"Recall@0.5\": rec05, \"F1@0.5\": f105,\n","            \"BestThr(F1)\": thr_opt, \"F1@BestThr\": f1_opt\n","        }\n","\n","    mt = pack_metrics(ys, ps_tr,  \"Transformer\", w_va)\n","    mn = pack_metrics(ys, ps_nn,  \"NNConv\",      w_va)\n","    me = pack_metrics(ys, ps_ens, \"Ensemble\",    w_va)\n","    print(f\"[Transformer] {mt}\")\n","    print(f\"[NNConv]      {mn}\")\n","    print(f\"[Ensemble]    {me} (alpha={a_tr:.3f}/{a_nn:.3f})\")\n","\n","    # ROC/PR ã‚«ãƒ¼ãƒ–ä¿å­˜ï¼ˆâ˜…é‡ã¿é©ç”¨ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n","    fold_dir = os.path.join(fold_plot_dir)\n","    save_roc_pr_curves(ys, ps_tr,  \"Transformer\", fold_dir, sample_weight=w_va if APPLY_WEIGHT_IN_VAL else None)\n","    save_roc_pr_curves(ys, ps_nn,  \"NNConv\",      fold_dir, sample_weight=w_va if APPLY_WEIGHT_IN_VAL else None)\n","    save_roc_pr_curves(ys, ps_ens, \"Ensemble\",    fold_dir, sample_weight=w_va if APPLY_WEIGHT_IN_VAL else None)\n","\n","    metrics_tr_list.append(mt)\n","    metrics_nn_list.append(mn)\n","    metrics_ens_list.append(me)\n","\n","    fold_counter += 1\n","\n","# ----- çµæœä¿å­˜ -----\n","def save_metrics(rows, csv_name):\n","    df = pd.DataFrame(rows)\n","    mean = df.select_dtypes(include=[np.number]).mean()\n","    std  = df.select_dtypes(include=[np.number]).std()\n","    df.loc[\"Mean\"] = mean\n","    df.loc[\"Std\"]  = std\n","    path = f\"{SAVE_DIR}/{csv_name}\"\n","    df.to_csv(path, index=False)\n","    print(f\"ğŸ“ Saved: {path}\")\n","    print(\"ğŸ¯ å¹³å‡çµæœ:\"); print(mean)\n","\n","save_metrics(metrics_tr_list,  \"transformer_cv_results.csv\")\n","save_metrics(metrics_nn_list,  \"nnconv_cv_results.csv\")\n","save_metrics(metrics_ens_list, \"ensemble_cv_results.csv\")\n","\n","print(\"\\nâœ… å®Œäº†:\", SAVE_DIR)\n","print(f\"â„¹ï¸ æ¤œè¨¼ã§é‡ã¿é©ç”¨: {APPLY_WEIGHT_IN_VAL}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pCHJJlIMW6s8","executionInfo":{"status":"ok","timestamp":1760682417285,"user_tz":-540,"elapsed":1782627,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"8b9c9514-5030-4bbc-b868-9b825670cd2f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] å…¨ã‚µãƒ³ãƒ—ãƒ«: 7321 | å„ªå…ˆCIDãƒ’ãƒƒãƒˆä»¶æ•°: 30\n","[INFO] å„ªå…ˆCIDä¸€è¦§: [3348, 3955, 13342, 68770, 10315094]\n","[INFO] å„ªå…ˆCIDã®åˆè¨ˆã‚°ãƒ©ãƒ•æ•°ï¼ˆæ‹¡å¼µå«ã‚€ï¼‰: 30\n","[INFO] Dims: x=5, edge=6, g=7, r=10\n","\n","ğŸ“‚ Fold 0 | train=5862 val=1459 | train_w(mean/min/max)=0.74/0.70/5.00 | val_w(mean/min/max)=0.73/0.70/5.00\n","[INFO] fold0 pos_weight(eff)=3.001\n","âœ… EarlyStopped [Transformer] (fold0) at epoch 123\n","[INFO] fold0 pos_weight(eff)=3.001\n","âœ… EarlyStopped [NNConv] (fold0) at epoch 122\n","[Transformer] {'Fold': 0, 'Model': 'Transformer', 'ROC-AUC': 0.9290930207799629, 'PR-AUC': 0.7607180366092011, 'Precision@0.5': 0.6155913978494624, 'Recall@0.5': 0.7658862876254181, 'F1@0.5': 0.6825633383010432, 'BestThr(F1)': 0.3620673165428875, 'F1@BestThr': 0.7299046330523874}\n","[NNConv]      {'Fold': 0, 'Model': 'NNConv', 'ROC-AUC': 0.9007353953179269, 'PR-AUC': 0.6945218779560177, 'Precision@0.5': 0.5343347639484979, 'Recall@0.5': 0.8327759197324415, 'F1@0.5': 0.6509803921568628, 'BestThr(F1)': 0.5473303160253076, 'F1@BestThr': 0.6893572919018572}\n","[Ensemble]    {'Fold': 0, 'Model': 'Ensemble', 'ROC-AUC': 0.9359282927032763, 'PR-AUC': 0.7837372507212821, 'Precision@0.5': 0.6206030150753769, 'Recall@0.5': 0.8260869565217391, 'F1@0.5': 0.7087517934002869, 'BestThr(F1)': 0.49294780700001983, 'F1@BestThr': 0.7426744813914088} (alpha=0.523/0.477)\n","\n","ğŸ“‚ Fold 1 | train=5863 val=1458 | train_w(mean/min/max)=0.74/0.70/5.00 | val_w(mean/min/max)=0.72/0.70/5.00\n","[INFO] fold1 pos_weight(eff)=2.969\n","âœ… EarlyStopped [Transformer] (fold1) at epoch 155\n","[INFO] fold1 pos_weight(eff)=2.969\n","âœ… EarlyStopped [NNConv] (fold1) at epoch 86\n","[Transformer] {'Fold': 1, 'Model': 'Transformer', 'ROC-AUC': 0.9434856824593641, 'PR-AUC': 0.7869554366931588, 'Precision@0.5': 0.6701030927835051, 'Recall@0.5': 0.87248322147651, 'F1@0.5': 0.7580174927113703, 'BestThr(F1)': 0.49526713116771887, 'F1@BestThr': 0.7779456200028062}\n","[NNConv]      {'Fold': 1, 'Model': 'NNConv', 'ROC-AUC': 0.887058973367999, 'PR-AUC': 0.6494403117644864, 'Precision@0.5': 0.5202558635394456, 'Recall@0.5': 0.8187919463087249, 'F1@0.5': 0.636245110821382, 'BestThr(F1)': 0.554570124277058, 'F1@BestThr': 0.6587850132757347}\n","[Ensemble]    {'Fold': 1, 'Model': 'Ensemble', 'ROC-AUC': 0.9436690480786781, 'PR-AUC': 0.7777029321981974, 'Precision@0.5': 0.670076726342711, 'Recall@0.5': 0.8791946308724832, 'F1@0.5': 0.760522496371553, 'BestThr(F1)': 0.5482322401563636, 'F1@BestThr': 0.7767680762333874} (alpha=0.548/0.452)\n","\n","ğŸ“‚ Fold 2 | train=5863 val=1458 | train_w(mean/min/max)=0.74/0.70/5.00 | val_w(mean/min/max)=0.71/0.70/5.00\n","[INFO] fold2 pos_weight(eff)=2.955\n","âœ… EarlyStopped [Transformer] (fold2) at epoch 164\n","[INFO] fold2 pos_weight(eff)=2.955\n","âœ… EarlyStopped [NNConv] (fold2) at epoch 103\n","[Transformer] {'Fold': 2, 'Model': 'Transformer', 'ROC-AUC': 0.9492664554374848, 'PR-AUC': 0.8222951755967522, 'Precision@0.5': 0.6725, 'Recall@0.5': 0.8996655518394648, 'F1@0.5': 0.7696709585121603, 'BestThr(F1)': 0.6234632685907612, 'F1@BestThr': 0.7927524434522805}\n","[NNConv]      {'Fold': 2, 'Model': 'NNConv', 'ROC-AUC': 0.9159345768788932, 'PR-AUC': 0.7315139662171198, 'Precision@0.5': 0.6172506738544474, 'Recall@0.5': 0.7658862876254181, 'F1@0.5': 0.6835820895522388, 'BestThr(F1)': 0.45627154646716905, 'F1@BestThr': 0.700520833819552}\n","[Ensemble]    {'Fold': 2, 'Model': 'Ensemble', 'ROC-AUC': 0.9541882731865216, 'PR-AUC': 0.8299868308270021, 'Precision@0.5': 0.7050938337801609, 'Recall@0.5': 0.8795986622073578, 'F1@0.5': 0.7827380952380952, 'BestThr(F1)': 0.45572935755449134, 'F1@BestThr': 0.8020088858690839} (alpha=0.529/0.471)\n","\n","ğŸ“‚ Fold 3 | train=5863 val=1458 | train_w(mean/min/max)=0.74/0.70/5.00 | val_w(mean/min/max)=0.72/0.70/5.00\n","[INFO] fold3 pos_weight(eff)=2.999\n","âœ… EarlyStopped [Transformer] (fold3) at epoch 103\n","[INFO] fold3 pos_weight(eff)=2.999\n","âœ… EarlyStopped [NNConv] (fold3) at epoch 63\n","[Transformer] {'Fold': 3, 'Model': 'Transformer', 'ROC-AUC': 0.9292674602490061, 'PR-AUC': 0.7191594363659605, 'Precision@0.5': 0.6027397260273972, 'Recall@0.5': 0.882943143812709, 'F1@0.5': 0.7164179104477612, 'BestThr(F1)': 0.5356063309160425, 'F1@BestThr': 0.7565477245083003}\n","[NNConv]      {'Fold': 3, 'Model': 'NNConv', 'ROC-AUC': 0.8281062221355079, 'PR-AUC': 0.5038975613789067, 'Precision@0.5': 0.44014732965009207, 'Recall@0.5': 0.7993311036789298, 'F1@0.5': 0.5676959619952494, 'BestThr(F1)': 0.46536154628723647, 'F1@BestThr': 0.598255213172371}\n","[Ensemble]    {'Fold': 3, 'Model': 'Ensemble', 'ROC-AUC': 0.9284097847013604, 'PR-AUC': 0.705656511015744, 'Precision@0.5': 0.604494382022472, 'Recall@0.5': 0.8996655518394648, 'F1@0.5': 0.7231182795698925, 'BestThr(F1)': 0.5524543951496556, 'F1@BestThr': 0.7651958186026974} (alpha=0.588/0.412)\n","\n","ğŸ“‚ Fold 4 | train=5863 val=1458 | train_w(mean/min/max)=0.74/0.70/5.00 | val_w(mean/min/max)=0.72/0.70/5.00\n","[INFO] fold4 pos_weight(eff)=2.960\n","âœ… EarlyStopped [Transformer] (fold4) at epoch 82\n","[INFO] fold4 pos_weight(eff)=2.960\n","âœ… EarlyStopped [NNConv] (fold4) at epoch 82\n","[Transformer] {'Fold': 4, 'Model': 'Transformer', 'ROC-AUC': 0.9130781514308249, 'PR-AUC': 0.6827862611957745, 'Precision@0.5': 0.5133079847908745, 'Recall@0.5': 0.903010033444816, 'F1@0.5': 0.6545454545454545, 'BestThr(F1)': 0.7045521585555372, 'F1@BestThr': 0.7001607721519267}\n","[NNConv]      {'Fold': 4, 'Model': 'NNConv', 'ROC-AUC': 0.8779516319853526, 'PR-AUC': 0.6252861274189102, 'Precision@0.5': 0.5820433436532507, 'Recall@0.5': 0.6287625418060201, 'F1@0.5': 0.6045016077170418, 'BestThr(F1)': 0.43994711308956835, 'F1@BestThr': 0.6270691340212335}\n","[Ensemble]    {'Fold': 4, 'Model': 'Ensemble', 'ROC-AUC': 0.9263220520783029, 'PR-AUC': 0.710869230107875, 'Precision@0.5': 0.5908045977011495, 'Recall@0.5': 0.8595317725752508, 'F1@0.5': 0.7002724795640327, 'BestThr(F1)': 0.5903883216147937, 'F1@BestThr': 0.732337505533715} (alpha=0.522/0.478)\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_5fold/transformer_cv_results.csv\n","ğŸ¯ å¹³å‡çµæœ:\n","Fold             2.000000\n","ROC-AUC          0.932838\n","PR-AUC           0.754383\n","Precision@0.5    0.614848\n","Recall@0.5       0.864798\n","F1@0.5           0.716243\n","BestThr(F1)      0.544191\n","F1@BestThr       0.751462\n","dtype: float64\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_5fold/nnconv_cv_results.csv\n","ğŸ¯ å¹³å‡çµæœ:\n","Fold             2.000000\n","ROC-AUC          0.881957\n","PR-AUC           0.640932\n","Precision@0.5    0.538806\n","Recall@0.5       0.769110\n","F1@0.5           0.628601\n","BestThr(F1)      0.492696\n","F1@BestThr       0.654797\n","dtype: float64\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_5fold/ensemble_cv_results.csv\n","ğŸ¯ å¹³å‡çµæœ:\n","Fold             2.000000\n","ROC-AUC          0.937703\n","PR-AUC           0.761591\n","Precision@0.5    0.638215\n","Recall@0.5       0.868816\n","F1@0.5           0.735081\n","BestThr(F1)      0.527950\n","F1@BestThr       0.763797\n","dtype: float64\n","\n","âœ… å®Œäº†: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_5fold\n","â„¹ï¸ æ¤œè¨¼ã§é‡ã¿é©ç”¨: True\n"]}]},{"cell_type":"code","source":["# ================================================\n","# TransformerConv + NNConv (d.x + d.g + d.r, edge_attr)\n","# Scaffold 5-Fold CV + Ensemble (logit-weighted by Val PR-AUC)\n","# å­¦ç¿’æ›²ç·šï¼ˆLoss/Val AUC/Val PR-AUCï¼‰ï¼†ROC/PRå›³ ä¿å­˜ä»˜ã\n","# â˜… å„ªå…ˆCIDã®å±ã™ã‚‹ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã¯æ¯foldã§å¿…ãšå­¦ç¿’ã¸å›ºå®šï¼ˆæ¤œè¨¼/ãƒ†ã‚¹ãƒˆã‹ã‚‰é™¤å¤–ï¼‰\n","# --- ä»¥ä¸‹ã€åŠ ç­† ---\n","# â˜… SampleWeightå¯¾å¿œï¼š\n","#    ãƒ»å­¦ç¿’æå¤±ã¯å¿…ãšã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã§åŠ é‡ï¼ˆBCEWithLogitsLoss(reduction='none') â†’ é‡ã¿ä»˜ãå¹³å‡ï¼‰\n","#    ãƒ»pos_weight ã¯é‡ã¿ä»˜ãå®ŸåŠ¹æ¯”ï¼ˆneg_sum/pos_sumã€ä¸Šé™10ï¼‰ã§è¨ˆç®—\n","#    ãƒ»æ¤œè¨¼ã® ROC/PRãƒ»å›³ãƒ»ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ï¼ˆVal PR-AUCï¼‰ã‚‚ã€ãƒ•ãƒ©ã‚°ã§é‡ã¿é©ç”¨å¯èƒ½\n","# â˜… é‡ã¿å±æ€§å€™è£œï¼ˆä¸Šã‹ã‚‰é †ã«æ¢ç´¢ï¼‰ï¼š[\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]ï¼ˆç„¡ã‘ã‚Œã°å…¨ã¦1.0ï¼‰\n","# â˜… ãƒ•ãƒ©ã‚°ï¼šAPPLY_WEIGHT_IN_VALï¼ˆæ¤œè¨¼ã«é‡ã¿é©ç”¨ï¼‰ã€APPLY_WEIGHT_IN_TESTï¼ˆãƒ†ã‚¹ãƒˆã«é‡ã¿é©ç”¨ï¼‰\n","# ================================================\n","import os, random\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import matplotlib.pyplot as plt\n","\n","from torch.serialization import add_safe_globals\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","\n","from rdkit import Chem\n","from rdkit.Chem.Scaffolds import MurckoScaffold\n","\n","from sklearn.metrics import (\n","    roc_auc_score, precision_recall_curve, f1_score, auc, roc_curve, average_precision_score\n",")\n","from collections import defaultdict\n","\n","# ----- è¨­å®š -----\n","PT_PATH   = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\"\n","SAVE_DIR  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_scaffold5fold\"\n","PLOT_DIR  = os.path.join(SAVE_DIR, \"plots\")\n","NUM_FOLDS = 5\n","BATCH_TR  = 64\n","BATCH_TE  = 128\n","LR        = 3e-4\n","WD        = 1e-4\n","TMAX      = 20\n","PATIENCE  = 15\n","MAX_EPOCH = 200\n","CLIP      = 5\n","SEED      = 42\n","\n","# â˜… å­¦ç¿’ã¸å¸¸æ™‚å«ã‚ã‚‹ CIDï¼ˆè©²å½“ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã”ã¨å­¦ç¿’ã¸å›ºå®šï¼‰\n","PRIORITY_CIDS = {3348, 3955, 2724385, 10315094, 68770, 13342, 441074}\n","\n","# â˜… SampleWeight è¨­å®šï¼ˆåŠ ç­†ï¼‰\n","WEIGHT_ATTR_CANDIDATES = [\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]\n","APPLY_WEIGHT_IN_VAL  = True   # æ¤œè¨¼ã® AUC/AP/å›³/ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ã«é‡ã¿ã‚’ä½¿ã†\n","APPLY_WEIGHT_IN_TEST = False  # ãƒ†ã‚¹ãƒˆã®æŒ‡æ¨™ãƒ»å›³ã«é‡ã¿ã‚’ä½¿ã†ï¼ˆå¿…è¦ãªã‚‰ True ã«ï¼‰\n","\n","random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","os.makedirs(SAVE_DIR, exist_ok=True); os.makedirs(PLOT_DIR, exist_ok=True)\n","\n","# ----- ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ -----\n","def _ensure_dir(p): os.makedirs(p, exist_ok=True)\n","\n","def plot_curve(xs, ys, title, xlabel, ylabel, save_path):\n","    plt.figure(); plt.plot(xs, ys)\n","    plt.title(title); plt.xlabel(xlabel); plt.ylabel(ylabel)\n","    plt.tight_layout(); plt.savefig(save_path); plt.close()\n","\n","def save_roc_pr_curves(y_true, y_prob, title_prefix, out_dir, sample_weight=None):\n","    _ensure_dir(out_dir)\n","    # ROC\n","    fpr, tpr, _ = roc_curve(y_true, y_prob, sample_weight=sample_weight)\n","    roc_auc = auc(fpr, tpr)\n","    plt.figure(); plt.plot(fpr, tpr, label=f\"AUC={roc_auc:.3f}\")\n","    plt.plot([0,1],[0,1],'--', linewidth=1)\n","    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.title(f\"{title_prefix} ROC\")\n","    plt.legend(); plt.tight_layout()\n","    plt.savefig(os.path.join(out_dir, f\"{title_prefix}_ROC.png\")); plt.close()\n","    # PR\n","    prec, rec, _ = precision_recall_curve(y_true, y_prob, sample_weight=sample_weight)\n","    ap = average_precision_score(y_true, y_prob, sample_weight=sample_weight)\n","    plt.figure(); plt.plot(rec, prec, label=f\"AP={ap:.3f}\")\n","    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\"); plt.title(f\"{title_prefix} PR\")\n","    plt.legend(); plt.tight_layout()\n","    plt.savefig(os.path.join(out_dir, f\"{title_prefix}_PR.png\")); plt.close()\n","\n","# â˜… é‡ã¿å–ã‚Šå‡ºã—ï¼ˆData / batch å…±é€šï¼‰\n","def _get_weight_from_data(d):\n","    for nm in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(d, nm):\n","            v = getattr(d, nm)\n","            return float(v.item()) if torch.is_tensor(v) else float(v)\n","    return 1.0\n","\n","def _to_1d(w):\n","    if w is None: return None\n","    if torch.is_tensor(w):\n","        if w.dim() == 2 and w.size(1) == 1: return w.view(-1)\n","        return w.view(-1)\n","    return torch.tensor(w, dtype=torch.float32)\n","\n","def get_batch_weights(batch, device=None):\n","    for nm in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(batch, nm):\n","            w = getattr(batch, nm)\n","            w = _to_1d(w).to(device or batch.y.device).float()\n","            return w, nm\n","    # ç„¡ã‘ã‚Œã°1\n","    return torch.ones(batch.y.numel(), device=device or batch.y.device, dtype=torch.float32), \"CONST1\"\n","\n","# ----- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆPyTorch 2.6 å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰ -----\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception as e:\n","        print(f\"[WARN] add_safe_globals å¤±æ•—: {e}\")\n","    try:\n","        obj = torch.load(path)  # PyTorch 2.6 default: weights_only=True\n","    except Exception as e:\n","        print(f\"[WARN] å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆ{e}ï¼‰ã€‚weights_only=False ã§å†è©¦è¡Œã—ã¾ã™ï¼ˆä¿¡é ¼ãƒ•ã‚¡ã‚¤ãƒ«å‰æï¼‰ã€‚\")\n","        obj = torch.load(path, weights_only=False)\n","\n","    if isinstance(obj, list):\n","        return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj:\n","        return obj[\"data_list\"]\n","    try:\n","        return list(obj)\n","    except Exception as e:\n","        raise RuntimeError(f\"æœªçŸ¥ã®å½¢å¼: {type(obj)}; liståŒ–å¤±æ•—: {e}\")\n","\n","data = load_pyg_list(PT_PATH)\n","print(f\"âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(data)}ä»¶\")\n","print(\"ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ:\", pd.Series([int(d.y) for d in data]).value_counts().to_dict())\n","\n","# ----- ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ç®—å‡º & ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å¯¾å¿œ -----\n","def smiles_to_scaffold(smi, fallback):\n","    m = Chem.MolFromSmiles(smi)\n","    if m:\n","        try:\n","            return MurckoScaffold.MurckoScaffoldSmiles(mol=m)\n","        except Exception:\n","            pass\n","    return fallback  # å¤±æ•—æ™‚ã¯ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯\n","\n","scaf_of = []\n","for i, d in enumerate(data):\n","    smi = getattr(d, \"smiles\", \"\")\n","    scaf = smiles_to_scaffold(smi, f\"_NOSCAF_{i}\")\n","    scaf_of.append(scaf)\n","\n","# ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰â†’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹\n","scaf_to_indices = defaultdict(list)\n","for i, scaf in enumerate(scaf_of):\n","    scaf_to_indices[scaf].append(i)\n","\n","# å„ªå…ˆCIDã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã€ãã‚ŒãŒå±ã™ã‚‹ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰é›†åˆ\n","cids = [int(getattr(d, \"cid\", -1)) for d in data]\n","priority_idx = [i for i, c in enumerate(cids) if c in PRIORITY_CIDS]\n","priority_scaffolds = set(scaf_of[i] for i in priority_idx)\n","print(f\"[INFO] å„ªå…ˆCIDãƒ’ãƒƒãƒˆ: {len(priority_idx)} ã‚µãƒ³ãƒ—ãƒ« / å„ªå…ˆã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰: {len(priority_scaffolds)} ç¨®\")\n","\n","# ----- ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰åˆ†å‰² -----\n","def scaffold_split_kfold(k=5, seed=42):\n","    scafs = list(scaf_to_indices.keys())\n","    random.seed(seed); random.shuffle(scafs)\n","    folds = [[] for _ in range(k)]\n","    for i, sc in enumerate(scafs):\n","        folds[i % k].extend(scaf_to_indices[sc])\n","    return folds\n","\n","folds = scaffold_split_kfold(k=NUM_FOLDS, seed=SEED)\n","\n","# ----- æ¬¡å…ƒå–å¾— -----\n","sample = data[0]\n","def infer_dim(t):\n","    if t.dim() == 1: return t.numel()\n","    if t.dim() in (2,3): return t.size(-1)\n","    raise RuntimeError(f\"æœªçŸ¥ã®ãƒ†ãƒ³ã‚½ãƒ«æ¬¡å…ƒ: {t.size()}\")\n","\n","X_DIM = sample.x.size(-1)\n","E_DIM = sample.edge_attr.size(-1)\n","G_DIM = infer_dim(sample.g)\n","R_DIM = infer_dim(sample.r)\n","HID   = 256\n","print(f\"[INFO] Dims: x={X_DIM}, edge={E_DIM}, g={G_DIM}, r={R_DIM}\")\n","\n","# ----- ãƒ¢ãƒ‡ãƒ« -----\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.c1 = TransformerConv(X_DIM, HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.c2 = TransformerConv(HID,  HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x, g, r], dim=1)).view(-1)  # ãƒ­ã‚¸ãƒƒãƒˆ\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hidden = max(64, min(256, in_attr_dim * 8))\n","    return nn.Sequential(nn.Linear(in_attr_dim, hidden), nn.ReLU(),\n","                         nn.Linear(hidden, in_channels * out_channels))\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        edge_nn1 = make_edge_mlp(E_DIM, HID, X_DIM)\n","        edge_nn2 = make_edge_mlp(E_DIM, HID, HID)\n","        self.c1 = NNConv(X_DIM, HID, edge_nn1, aggr='mean')\n","        self.c2 = NNConv(HID,  HID, edge_nn2, aggr='mean')\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x, g, r], dim=1)).view(-1)  # ãƒ­ã‚¸ãƒƒãƒˆ\n","\n","# ----- å­¦ç¿’/è©•ä¾¡ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆSampleWeightå¯¾å¿œã«æ”¹ä¿®ï¼‰ -----\n","def pos_weight_from(dataset):\n","    # é‡ã¿ä»˜ãå®ŸåŠ¹æ¯”ï¼ˆneg_sum / pos_sumï¼‰ã€ä¸Šé™10\n","    ys = torch.tensor([float(d.y.item()) for d in dataset])\n","    ws = torch.tensor([_get_weight_from_data(d) for d in dataset], dtype=torch.float32)\n","    pos_sum = ws[ys == 1].sum()\n","    neg_sum = ws[ys == 0].sum()\n","    pw = (neg_sum / torch.clamp(pos_sum, min=1e-8)).item()\n","    return torch.tensor([min(max(pw, 1.0), 10.0)], dtype=torch.float32)\n","\n","@torch.no_grad()\n","def eval_logits(model, ds, batch_size=BATCH_TE):\n","    model.eval(); ys, lg, ws = [], [], []\n","    for bt in DataLoader(ds, batch_size=batch_size, shuffle=False):\n","        bt = bt.to(DEVICE)\n","        ys.append(bt.y.detach().cpu())\n","        lg.append(model(bt).detach().cpu())  # ãƒ­ã‚¸ãƒƒãƒˆ\n","        w, _ = get_batch_weights(bt, DEVICE)\n","        ws.append(w.detach().cpu())\n","    y  = torch.cat(ys).numpy()\n","    l  = torch.cat(lg).numpy()\n","    sw = torch.cat(ws).numpy()\n","    return y, l, sw\n","\n","def metrics_from(y, p, thr=0.5, sample_weight=None):\n","    precision, recall, _ = precision_recall_curve(y, p, sample_weight=sample_weight)\n","    pr_auc = auc(recall, precision)\n","    roc    = roc_auc_score(y, p, sample_weight=sample_weight)\n","    f1     = f1_score(y, (p >= thr).astype(int))  # â€»F1ã¯è¡¨ç¤ºç”¨ã«éåŠ é‡ï¼ˆå¿…è¦ãªã‚‰æ‰‹è¨ˆç®—ã«å¤‰æ›´ï¼‰\n","    return roc, pr_auc, f1\n","\n","def train_one(model, train_set, val_set, save_path, tag, plot_dir):\n","    model.to(DEVICE)\n","    pw = pos_weight_from(train_set).to(DEVICE)\n","    crit = nn.BCEWithLogitsLoss(pos_weight=pw, reduction='none')  # â† per-sample\n","    opt  = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n","    sch  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=TMAX)\n","\n","    history = {\"epoch\": [], \"train_loss\": [], \"val_auc\": [], \"val_prauc\": []}\n","    best_auc, wait = 0.0, 0\n","\n","    print(f\"[{tag}] pos_weight(eff)={float(pw.item()):.3f}\")\n","\n","    for ep in range(1, MAX_EPOCH + 1):\n","        model.train(); epoch_losses = []\n","        for bt in DataLoader(train_set, batch_size=BATCH_TR, shuffle=True):\n","            bt = bt.to(DEVICE)\n","            logits = model(bt)\n","            loss_vec = crit(logits, bt.y.float())\n","            sw, _nm = get_batch_weights(bt, DEVICE)\n","            loss = (loss_vec * sw).sum() / (sw.sum() + 1e-8)\n","\n","            opt.zero_grad(); loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n","            opt.step()\n","            epoch_losses.append(loss.item())\n","        sch.step()\n","\n","        yv, lv, wv = eval_logits(model, val_set)\n","        pv = torch.sigmoid(torch.tensor(lv)).numpy()\n","        if APPLY_WEIGHT_IN_VAL:\n","            roc_v, pr_v, f1_v = metrics_from(yv, pv, sample_weight=wv)\n","        else:\n","            roc_v, pr_v, f1_v = metrics_from(yv, pv)\n","\n","        history[\"epoch\"].append(ep)\n","        history[\"train_loss\"].append(float(np.mean(epoch_losses)))\n","        history[\"val_auc\"].append(float(roc_v))\n","        history[\"val_prauc\"].append(float(pr_v))\n","\n","        print(f\"[{tag}] Epoch {ep:03d} | ROC-AUC {roc_v:.4f} | PR-AUC {pr_v:.4f} | F1 {f1_v:.4f}\")\n","\n","        if roc_v > best_auc:\n","            best_auc, wait = roc_v, 0\n","            torch.save(model.state_dict(), save_path)\n","        else:\n","            wait += 1\n","            if wait >= PATIENCE:\n","                print(f\"âœ… EarlyStopping [{tag}]\")\n","                break\n","\n","    # ãƒ™ã‚¹ãƒˆå¾©å…ƒ\n","    model.load_state_dict(torch.load(save_path, map_location=DEVICE))\n","\n","    # å­¦ç¿’æ›²ç·šä¿å­˜\n","    df_hist = pd.DataFrame(history)\n","    df_hist.to_csv(save_path.replace(\".pt\", f\"_history.csv\"), index=False)\n","    _ensure_dir(plot_dir)\n","    plot_curve(df_hist[\"epoch\"], df_hist[\"train_loss\"], f\"{tag} Train Loss\", \"Epoch\", \"Loss\",\n","               os.path.join(plot_dir, f\"{tag.replace('/','_')}_Loss.png\"))\n","    plot_curve(df_hist[\"epoch\"], df_hist[\"val_auc\"], f\"{tag} Val ROC-AUC\", \"Epoch\", \"ROC-AUC\",\n","               os.path.join(plot_dir, f\"{tag.replace('/','_')}_ValAUC.png\"))\n","    plot_curve(df_hist[\"epoch\"], df_hist[\"val_prauc\"], f\"{tag} Val PR-AUC\", \"Epoch\", \"PR-AUC\",\n","               os.path.join(plot_dir, f\"{tag.replace('/','_')}_ValPRAUC.png\"))\n","\n","    # ãƒ™ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«ã§ã®æ¤œè¨¼PR-AUCï¼ˆã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ç”¨ï¼‰\n","    yv, lv, wv = eval_logits(model, val_set)\n","    pv = torch.sigmoid(torch.tensor(lv)).numpy()\n","    pr_v = average_precision_score(yv, pv, sample_weight=wv) if APPLY_WEIGHT_IN_VAL else average_precision_score(yv, pv)\n","    return model, float(pr_v)\n","\n","# ----- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆå„ªå…ˆã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã¯å¸¸ã«å­¦ç¿’ã¸ï¼‰ -----\n","res_tr, res_nn, res_en = [], [], []\n","\n","for k in range(NUM_FOLDS):\n","    test_idx = folds[k]\n","    val_idx  = folds[(k + 1) % NUM_FOLDS]\n","    train_idx = [i for j in range(NUM_FOLDS) if j not in [k, (k + 1) % NUM_FOLDS] for i in folds[j]]\n","\n","    # ã“ã“ãŒè‚ï¼šå„ªå…ˆCIDãŒå±ã™ã‚‹ã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰ã¯æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆã‹ã‚‰é™¤å¤–ã—ã€å­¦ç¿’ã¸ç§»å‹•\n","    def move_priority_scaffolds_to_train(idx_list):\n","        moved = []\n","        for i in list(idx_list):\n","            sc = scaf_of[i]\n","            if sc in priority_scaffolds:  # å„ªå…ˆã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰\n","                moved.extend(scaf_to_indices[sc])\n","        idx_set = set(idx_list) - set(moved)\n","        return list(sorted(idx_set)), list(sorted(set(moved)))\n","\n","    val_idx,  moved_from_val  = move_priority_scaffolds_to_train(val_idx)\n","    test_idx, moved_from_test = move_priority_scaffolds_to_train(test_idx)\n","\n","    # å­¦ç¿’ã¸è¿½åŠ ï¼ˆé‡è¤‡æ’é™¤ï¼‰\n","    train_idx = list(sorted(set(train_idx).union(moved_from_val).union(moved_from_test)))\n","\n","    # ã‚µãƒ‹ãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ï¼šå„ªå…ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒval/testã«æ®‹ã£ã¦ã„ãªã„ã“ã¨\n","    pr_in_val  = len(set(priority_idx).intersection(val_idx))\n","    pr_in_test = len(set(priority_idx).intersection(test_idx))\n","    print(f\"\\nğŸ“‚ Fold {k} | train={len(train_idx)} val={len(val_idx)} test={len(test_idx)} \"\n","          f\"| moved_from_val={len(moved_from_val)} moved_from_test={len(moved_from_test)} \"\n","          f\"| priority_in_val={pr_in_val} priority_in_test={pr_in_test}\")\n","\n","    train_set = [data[i] for i in train_idx]\n","    val_set   = [data[i] for i in val_idx]\n","    test_set  = [data[i] for i in test_idx]\n","\n","    fold_plot_dir = os.path.join(PLOT_DIR, f\"fold{k}\"); _ensure_dir(fold_plot_dir)\n","\n","    # --- å­¦ç¿’ï¼ˆæ¤œè¨¼PR-AUCã‚’é‡ã¿ã¨ã—ã¦è¿”å´ï¼‰ ---\n","    m_tr = Transformer_DX_DG_DR().to(DEVICE)\n","    m_nn = NNConv_DX_DG_DR().to(DEVICE)\n","    path_tr = f\"{SAVE_DIR}/transformer_fold{k}.pt\"\n","    path_nn = f\"{SAVE_DIR}/nnconv_fold{k}.pt\"\n","\n","    m_tr, pr_tr_val = train_one(m_tr, train_set, val_set, path_tr, f\"Transformer/F{k}\", fold_plot_dir)\n","    m_nn, pr_nn_val = train_one(m_nn, train_set, val_set, path_nn, f\"NNConv/F{k}\",      fold_plot_dir)\n","\n","    # foldã”ã¨ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿ï¼ˆæ¤œè¨¼PR-AUCã§æ­£è¦åŒ–ï¼‰ â€»æ¤œè¨¼PR-AUCã¯ãƒ•ãƒ©ã‚°ã«å¿œã˜ã¦é‡ã¿ä»˜ã‘æ¸ˆã¿\n","    w_tr, w_nn = pr_tr_val, pr_nn_val\n","    s = w_tr + w_nn + 1e-12\n","    a_tr, a_nn = w_tr/s, w_nn/s\n","\n","    # --- ãƒ†ã‚¹ãƒˆï¼ˆãƒ­ã‚¸ãƒƒãƒˆåŠ é‡å¹³å‡ï¼‰ ---\n","    yt, lg_tr, wt = eval_logits(m_tr, test_set)\n","    _,  lg_nn, wt2 = eval_logits(m_nn, test_set)\n","    assert np.allclose(wt, wt2)  # åŒä¸€åˆ†å‰²ã®ã¯ãš\n","\n","    ps_tr = torch.sigmoid(torch.tensor(lg_tr)).numpy()\n","    ps_nn = torch.sigmoid(torch.tensor(lg_nn)).numpy()\n","    lg_en = a_tr * lg_tr + a_nn * lg_nn\n","    ps_en = torch.sigmoid(torch.tensor(lg_en)).numpy()\n","\n","    def metrics_from_pack(y, p, sw=None):\n","        return metrics_from(y, p, sample_weight=sw)\n","\n","    if APPLY_WEIGHT_IN_TEST:\n","        sw_use = wt\n","    else:\n","        sw_use = None\n","\n","    roc_tr, pr_tr, f1_tr = metrics_from_pack(yt, ps_tr, sw_use)\n","    roc_nn, pr_nn, f1_nn = metrics_from_pack(yt, ps_nn, sw_use)\n","    roc_en, pr_en, f1_en = metrics_from_pack(yt, ps_en, sw_use)\n","\n","    print(f\"âœ… Fold{k} [Transformer] ROC {roc_tr:.4f} | PR {pr_tr:.4f} | F1 {f1_tr:.4f}\")\n","    print(f\"âœ… Fold{k} [NNConv]      ROC {roc_nn:.4f} | PR {pr_nn:.4f} | F1 {f1_nn:.4f}\")\n","    print(f\"âœ… Fold{k} [Ensemble]    ROC {roc_en:.4f} | PR {pr_en:.4f} | F1 {f1_en:.4f} (alpha={a_tr:.3f}/{a_nn:.3f})\")\n","\n","    # ãƒ†ã‚¹ãƒˆROC/PRå›³ä¿å­˜ï¼ˆé‡ã¿ã¯å›³ã«ã‚‚åæ˜ å¯èƒ½ï¼‰\n","    save_roc_pr_curves(yt, ps_tr,  f\"Transformer_F{k}\", fold_plot_dir, sample_weight=sw_use)\n","    save_roc_pr_curves(yt, ps_nn,  f\"NNConv_F{k}\",      fold_plot_dir, sample_weight=sw_use)\n","    save_roc_pr_curves(yt, ps_en,  f\"Ensemble_F{k}\",    fold_plot_dir, sample_weight=sw_use)\n","\n","    res_tr.append([roc_tr, pr_tr, f1_tr])\n","    res_nn.append([roc_nn, pr_nn, f1_nn])\n","    res_en.append([roc_en, pr_en, f1_en])\n","\n","# ----- çµæœã¾ã¨ã‚ -----\n","def to_df(rows, name):\n","    arr = np.array(rows)\n","    df = pd.DataFrame({\n","        \"Fold\": [f\"Fold{i}\" for i in range(NUM_FOLDS)],\n","        \"ROC-AUC\": arr[:, 0],\n","        \"PR-AUC\":  arr[:, 1],\n","        \"F1\":      arr[:, 2]\n","    })\n","    df.index = df[\"Fold\"]; df = df.drop(columns=[\"Fold\"])\n","    df.loc[\"Mean\"] = df.mean(numeric_only=True)\n","    df.loc[\"Std\"]  = df.std(numeric_only=True)\n","    out = f\"{SAVE_DIR}/cv_results_{name}.csv\"\n","    df.to_csv(out, index=True)\n","    print(f\"ğŸ“ Saved: {out}\")\n","    print(\"ğŸ¯ å¹³å‡çµæœ:\"); print(df.loc[\"Mean\"])\n","    return df\n","\n","df_tr = to_df(res_tr, \"transformer\")\n","df_nn = to_df(res_nn, \"nnconv\")\n","df_en = to_df(res_en, \"ensemble\")\n","\n","rows_order = [f\"Fold{i}\" for i in range(NUM_FOLDS)] + [\"Mean\", \"Std\"]\n","def pick(df, col): return df.reindex(rows_order)[col].tolist()\n","\n","df_comb = pd.DataFrame({\n","    \"Fold\": rows_order,\n","    \"Transformer_ROC\": pick(df_tr, \"ROC-AUC\"),\n","    \"Transformer_PR\":  pick(df_tr, \"PR-AUC\"),\n","    \"Transformer_F1\":  pick(df_tr, \"F1\"),\n","    \"NNConv_ROC\":      pick(df_nn, \"ROC-AUC\"),\n","    \"NNConv_PR\":       pick(df_nn, \"PR-AUC\"),\n","    \"NNConv_F1\":       pick(df_nn, \"F1\"),\n","    \"Ensemble_ROC\":    pick(df_en, \"ROC-AUC\"),\n","    \"Ensemble_PR\":     pick(df_en, \"PR-AUC\"),\n","    \"Ensemble_F1\":     pick(df_en, \"F1\"),\n","})\n","df_comb.to_csv(f\"{SAVE_DIR}/cv_results_combined.csv\", index=False)\n","print(\"\\nâœ… å®Œäº†:\", SAVE_DIR)\n","print(f\"â„¹ï¸ æ¤œè¨¼ã§é‡ã¿é©ç”¨: {APPLY_WEIGHT_IN_VAL} / ãƒ†ã‚¹ãƒˆã§é‡ã¿é©ç”¨: {APPLY_WEIGHT_IN_TEST}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FeSV6XcXfASr","executionInfo":{"status":"ok","timestamp":1760682910895,"user_tz":-540,"elapsed":440072,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"aae6d737-b089-4f26-bc7e-95a82dfea978"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: 7321ä»¶\n","ãƒ©ãƒ™ãƒ«åˆ†å¸ƒ: {0: 5797, 1: 1524}\n","[INFO] å„ªå…ˆCIDãƒ’ãƒƒãƒˆ: 30 ã‚µãƒ³ãƒ—ãƒ« / å„ªå…ˆã‚¹ã‚­ãƒ£ãƒ•ã‚©ãƒ¼ãƒ«ãƒ‰: 5 ç¨®\n","[INFO] Dims: x=5, edge=6, g=7, r=10\n","\n","ğŸ“‚ Fold 0 | train=4682 val=1327 test=1312 | moved_from_val=8 moved_from_test=7 | priority_in_val=0 priority_in_test=0\n","[Transformer/F0] pos_weight(eff)=2.674\n","[Transformer/F0] Epoch 001 | ROC-AUC 0.7379 | PR-AUC 0.3870 | F1 0.4255\n","[Transformer/F0] Epoch 002 | ROC-AUC 0.7217 | PR-AUC 0.3677 | F1 0.4484\n","[Transformer/F0] Epoch 003 | ROC-AUC 0.7409 | PR-AUC 0.3875 | F1 0.4620\n","[Transformer/F0] Epoch 004 | ROC-AUC 0.7603 | PR-AUC 0.4226 | F1 0.4387\n","[Transformer/F0] Epoch 005 | ROC-AUC 0.7478 | PR-AUC 0.3965 | F1 0.4620\n","[Transformer/F0] Epoch 006 | ROC-AUC 0.7640 | PR-AUC 0.4284 | F1 0.4728\n","[Transformer/F0] Epoch 007 | ROC-AUC 0.7665 | PR-AUC 0.4174 | F1 0.4983\n","[Transformer/F0] Epoch 008 | ROC-AUC 0.7642 | PR-AUC 0.4134 | F1 0.4718\n","[Transformer/F0] Epoch 009 | ROC-AUC 0.7528 | PR-AUC 0.3907 | F1 0.4533\n","[Transformer/F0] Epoch 010 | ROC-AUC 0.7595 | PR-AUC 0.4028 | F1 0.4724\n","[Transformer/F0] Epoch 011 | ROC-AUC 0.7634 | PR-AUC 0.4147 | F1 0.4834\n","[Transformer/F0] Epoch 012 | ROC-AUC 0.7581 | PR-AUC 0.4078 | F1 0.4629\n","[Transformer/F0] Epoch 013 | ROC-AUC 0.7558 | PR-AUC 0.4065 | F1 0.4866\n","[Transformer/F0] Epoch 014 | ROC-AUC 0.7585 | PR-AUC 0.4138 | F1 0.4615\n","[Transformer/F0] Epoch 015 | ROC-AUC 0.7561 | PR-AUC 0.4139 | F1 0.4707\n","[Transformer/F0] Epoch 016 | ROC-AUC 0.7572 | PR-AUC 0.4142 | F1 0.4452\n","[Transformer/F0] Epoch 017 | ROC-AUC 0.7572 | PR-AUC 0.4155 | F1 0.4496\n","[Transformer/F0] Epoch 018 | ROC-AUC 0.7582 | PR-AUC 0.4178 | F1 0.4663\n","[Transformer/F0] Epoch 019 | ROC-AUC 0.7578 | PR-AUC 0.4166 | F1 0.4763\n","[Transformer/F0] Epoch 020 | ROC-AUC 0.7578 | PR-AUC 0.4165 | F1 0.4776\n","[Transformer/F0] Epoch 021 | ROC-AUC 0.7578 | PR-AUC 0.4165 | F1 0.4776\n","[Transformer/F0] Epoch 022 | ROC-AUC 0.7579 | PR-AUC 0.4167 | F1 0.4776\n","âœ… EarlyStopping [Transformer/F0]\n","[NNConv/F0] pos_weight(eff)=2.674\n","[NNConv/F0] Epoch 001 | ROC-AUC 0.5750 | PR-AUC 0.2241 | F1 0.3504\n","[NNConv/F0] Epoch 002 | ROC-AUC 0.7290 | PR-AUC 0.3507 | F1 0.4259\n","[NNConv/F0] Epoch 003 | ROC-AUC 0.7868 | PR-AUC 0.4417 | F1 0.0353\n","[NNConv/F0] Epoch 004 | ROC-AUC 0.7577 | PR-AUC 0.4603 | F1 0.4296\n","[NNConv/F0] Epoch 005 | ROC-AUC 0.7678 | PR-AUC 0.4417 | F1 0.4315\n","[NNConv/F0] Epoch 006 | ROC-AUC 0.7685 | PR-AUC 0.4487 | F1 0.4369\n","[NNConv/F0] Epoch 007 | ROC-AUC 0.7495 | PR-AUC 0.4131 | F1 0.4632\n","[NNConv/F0] Epoch 008 | ROC-AUC 0.7548 | PR-AUC 0.4159 | F1 0.4658\n","[NNConv/F0] Epoch 009 | ROC-AUC 0.7791 | PR-AUC 0.4575 | F1 0.4828\n","[NNConv/F0] Epoch 010 | ROC-AUC 0.7529 | PR-AUC 0.4381 | F1 0.4690\n","[NNConv/F0] Epoch 011 | ROC-AUC 0.7584 | PR-AUC 0.4363 | F1 0.4652\n","[NNConv/F0] Epoch 012 | ROC-AUC 0.7339 | PR-AUC 0.4208 | F1 0.4650\n","[NNConv/F0] Epoch 013 | ROC-AUC 0.7640 | PR-AUC 0.4342 | F1 0.4685\n","[NNConv/F0] Epoch 014 | ROC-AUC 0.7544 | PR-AUC 0.4456 | F1 0.4696\n","[NNConv/F0] Epoch 015 | ROC-AUC 0.7707 | PR-AUC 0.4537 | F1 0.4706\n","[NNConv/F0] Epoch 016 | ROC-AUC 0.7669 | PR-AUC 0.4625 | F1 0.4736\n","[NNConv/F0] Epoch 017 | ROC-AUC 0.7608 | PR-AUC 0.4530 | F1 0.4824\n","[NNConv/F0] Epoch 018 | ROC-AUC 0.7618 | PR-AUC 0.4575 | F1 0.4772\n","âœ… EarlyStopping [NNConv/F0]\n","âœ… Fold0 [Transformer] ROC 0.7631 | PR 0.3753 | F1 0.4469\n","âœ… Fold0 [NNConv]      ROC 0.7363 | PR 0.3405 | F1 0.0492\n","âœ… Fold0 [Ensemble]    ROC 0.7916 | PR 0.4043 | F1 0.2941 (alpha=0.486/0.514)\n","\n","ğŸ“‚ Fold 1 | train=4202 val=1792 test=1327 | moved_from_val=0 moved_from_test=8 | priority_in_val=0 priority_in_test=0\n","[Transformer/F1] pos_weight(eff)=2.880\n","[Transformer/F1] Epoch 001 | ROC-AUC 0.7102 | PR-AUC 0.4031 | F1 0.3636\n","[Transformer/F1] Epoch 002 | ROC-AUC 0.7483 | PR-AUC 0.4275 | F1 0.3381\n","[Transformer/F1] Epoch 003 | ROC-AUC 0.7698 | PR-AUC 0.4426 | F1 0.5527\n","[Transformer/F1] Epoch 004 | ROC-AUC 0.7733 | PR-AUC 0.4517 | F1 0.4561\n","[Transformer/F1] Epoch 005 | ROC-AUC 0.7818 | PR-AUC 0.4633 | F1 0.5317\n","[Transformer/F1] Epoch 006 | ROC-AUC 0.7951 | PR-AUC 0.4824 | F1 0.5708\n","[Transformer/F1] Epoch 007 | ROC-AUC 0.8007 | PR-AUC 0.4942 | F1 0.5330\n","[Transformer/F1] Epoch 008 | ROC-AUC 0.8061 | PR-AUC 0.5041 | F1 0.5111\n","[Transformer/F1] Epoch 009 | ROC-AUC 0.8091 | PR-AUC 0.5054 | F1 0.5549\n","[Transformer/F1] Epoch 010 | ROC-AUC 0.8160 | PR-AUC 0.5137 | F1 0.5717\n","[Transformer/F1] Epoch 011 | ROC-AUC 0.8248 | PR-AUC 0.5224 | F1 0.5422\n","[Transformer/F1] Epoch 012 | ROC-AUC 0.8302 | PR-AUC 0.5426 | F1 0.5620\n","[Transformer/F1] Epoch 013 | ROC-AUC 0.8298 | PR-AUC 0.5450 | F1 0.5563\n","[Transformer/F1] Epoch 014 | ROC-AUC 0.8290 | PR-AUC 0.5447 | F1 0.5489\n","[Transformer/F1] Epoch 015 | ROC-AUC 0.8265 | PR-AUC 0.5434 | F1 0.5607\n","[Transformer/F1] Epoch 016 | ROC-AUC 0.8283 | PR-AUC 0.5488 | F1 0.5605\n","[Transformer/F1] Epoch 017 | ROC-AUC 0.8291 | PR-AUC 0.5487 | F1 0.5684\n","[Transformer/F1] Epoch 018 | ROC-AUC 0.8273 | PR-AUC 0.5493 | F1 0.5609\n","[Transformer/F1] Epoch 019 | ROC-AUC 0.8279 | PR-AUC 0.5516 | F1 0.5612\n","[Transformer/F1] Epoch 020 | ROC-AUC 0.8279 | PR-AUC 0.5518 | F1 0.5609\n","[Transformer/F1] Epoch 021 | ROC-AUC 0.8279 | PR-AUC 0.5518 | F1 0.5609\n","[Transformer/F1] Epoch 022 | ROC-AUC 0.8279 | PR-AUC 0.5516 | F1 0.5596\n","[Transformer/F1] Epoch 023 | ROC-AUC 0.8276 | PR-AUC 0.5517 | F1 0.5550\n","[Transformer/F1] Epoch 024 | ROC-AUC 0.8285 | PR-AUC 0.5524 | F1 0.5543\n","[Transformer/F1] Epoch 025 | ROC-AUC 0.8289 | PR-AUC 0.5555 | F1 0.5596\n","[Transformer/F1] Epoch 026 | ROC-AUC 0.8282 | PR-AUC 0.5545 | F1 0.5592\n","[Transformer/F1] Epoch 027 | ROC-AUC 0.8308 | PR-AUC 0.5615 | F1 0.5579\n","[Transformer/F1] Epoch 028 | ROC-AUC 0.8280 | PR-AUC 0.5610 | F1 0.5535\n","[Transformer/F1] Epoch 029 | ROC-AUC 0.8284 | PR-AUC 0.5623 | F1 0.5771\n","[Transformer/F1] Epoch 030 | ROC-AUC 0.8248 | PR-AUC 0.5605 | F1 0.5631\n","[Transformer/F1] Epoch 031 | ROC-AUC 0.8291 | PR-AUC 0.5670 | F1 0.5779\n","[Transformer/F1] Epoch 032 | ROC-AUC 0.8260 | PR-AUC 0.5723 | F1 0.5585\n","[Transformer/F1] Epoch 033 | ROC-AUC 0.8268 | PR-AUC 0.5662 | F1 0.5643\n","[Transformer/F1] Epoch 034 | ROC-AUC 0.8281 | PR-AUC 0.5734 | F1 0.5650\n","[Transformer/F1] Epoch 035 | ROC-AUC 0.8272 | PR-AUC 0.5684 | F1 0.5521\n","[Transformer/F1] Epoch 036 | ROC-AUC 0.8113 | PR-AUC 0.5548 | F1 0.4700\n","[Transformer/F1] Epoch 037 | ROC-AUC 0.8206 | PR-AUC 0.5762 | F1 0.5506\n","[Transformer/F1] Epoch 038 | ROC-AUC 0.8079 | PR-AUC 0.5550 | F1 0.5618\n","[Transformer/F1] Epoch 039 | ROC-AUC 0.8162 | PR-AUC 0.5712 | F1 0.5545\n","[Transformer/F1] Epoch 040 | ROC-AUC 0.8126 | PR-AUC 0.5634 | F1 0.5283\n","[Transformer/F1] Epoch 041 | ROC-AUC 0.8072 | PR-AUC 0.5572 | F1 0.5481\n","[Transformer/F1] Epoch 042 | ROC-AUC 0.8055 | PR-AUC 0.5591 | F1 0.5615\n","âœ… EarlyStopping [Transformer/F1]\n","[NNConv/F1] pos_weight(eff)=2.880\n","[NNConv/F1] Epoch 001 | ROC-AUC 0.6450 | PR-AUC 0.3238 | F1 0.2291\n","[NNConv/F1] Epoch 002 | ROC-AUC 0.7385 | PR-AUC 0.4667 | F1 0.4283\n","[NNConv/F1] Epoch 003 | ROC-AUC 0.7293 | PR-AUC 0.4276 | F1 0.1674\n","[NNConv/F1] Epoch 004 | ROC-AUC 0.7639 | PR-AUC 0.4648 | F1 0.3636\n","[NNConv/F1] Epoch 005 | ROC-AUC 0.7586 | PR-AUC 0.4372 | F1 0.2927\n","[NNConv/F1] Epoch 006 | ROC-AUC 0.7661 | PR-AUC 0.4623 | F1 0.5095\n","[NNConv/F1] Epoch 007 | ROC-AUC 0.7836 | PR-AUC 0.4846 | F1 0.5774\n","[NNConv/F1] Epoch 008 | ROC-AUC 0.8013 | PR-AUC 0.4921 | F1 0.5576\n","[NNConv/F1] Epoch 009 | ROC-AUC 0.8229 | PR-AUC 0.5089 | F1 0.5739\n","[NNConv/F1] Epoch 010 | ROC-AUC 0.8093 | PR-AUC 0.5121 | F1 0.5827\n","[NNConv/F1] Epoch 011 | ROC-AUC 0.8080 | PR-AUC 0.5114 | F1 0.5535\n","[NNConv/F1] Epoch 012 | ROC-AUC 0.7999 | PR-AUC 0.5194 | F1 0.5430\n","[NNConv/F1] Epoch 013 | ROC-AUC 0.8112 | PR-AUC 0.5255 | F1 0.5676\n","[NNConv/F1] Epoch 014 | ROC-AUC 0.8301 | PR-AUC 0.5386 | F1 0.5779\n","[NNConv/F1] Epoch 015 | ROC-AUC 0.8142 | PR-AUC 0.5316 | F1 0.5661\n","[NNConv/F1] Epoch 016 | ROC-AUC 0.8103 | PR-AUC 0.5293 | F1 0.5756\n","[NNConv/F1] Epoch 017 | ROC-AUC 0.8030 | PR-AUC 0.5270 | F1 0.5821\n","[NNConv/F1] Epoch 018 | ROC-AUC 0.8035 | PR-AUC 0.5293 | F1 0.5781\n","[NNConv/F1] Epoch 019 | ROC-AUC 0.8038 | PR-AUC 0.5314 | F1 0.5500\n","[NNConv/F1] Epoch 020 | ROC-AUC 0.8052 | PR-AUC 0.5317 | F1 0.5648\n","[NNConv/F1] Epoch 021 | ROC-AUC 0.8052 | PR-AUC 0.5317 | F1 0.5648\n","[NNConv/F1] Epoch 022 | ROC-AUC 0.8065 | PR-AUC 0.5323 | F1 0.5630\n","[NNConv/F1] Epoch 023 | ROC-AUC 0.8066 | PR-AUC 0.5332 | F1 0.5500\n","[NNConv/F1] Epoch 024 | ROC-AUC 0.8097 | PR-AUC 0.5334 | F1 0.5557\n","[NNConv/F1] Epoch 025 | ROC-AUC 0.8094 | PR-AUC 0.5311 | F1 0.5632\n","[NNConv/F1] Epoch 026 | ROC-AUC 0.8139 | PR-AUC 0.5345 | F1 0.5763\n","[NNConv/F1] Epoch 027 | ROC-AUC 0.8147 | PR-AUC 0.5295 | F1 0.5611\n","[NNConv/F1] Epoch 028 | ROC-AUC 0.8069 | PR-AUC 0.5308 | F1 0.5515\n","[NNConv/F1] Epoch 029 | ROC-AUC 0.8119 | PR-AUC 0.5505 | F1 0.5630\n","âœ… EarlyStopping [NNConv/F1]\n","âœ… Fold1 [Transformer] ROC 0.7564 | PR 0.4154 | F1 0.4370\n","âœ… Fold1 [NNConv]      ROC 0.7825 | PR 0.4675 | F1 0.5012\n","âœ… Fold1 [Ensemble]    ROC 0.7760 | PR 0.4560 | F1 0.4967 (alpha=0.511/0.489)\n","\n","ğŸ“‚ Fold 2 | train=4054 val=1475 test=1792 | moved_from_val=6 moved_from_test=0 | priority_in_val=0 priority_in_test=0\n","[Transformer/F2] pos_weight(eff)=3.034\n","[Transformer/F2] Epoch 001 | ROC-AUC 0.7582 | PR-AUC 0.4168 | F1 0.4836\n","[Transformer/F2] Epoch 002 | ROC-AUC 0.7642 | PR-AUC 0.4330 | F1 0.0333\n","[Transformer/F2] Epoch 003 | ROC-AUC 0.7635 | PR-AUC 0.4489 | F1 0.5569\n","[Transformer/F2] Epoch 004 | ROC-AUC 0.7560 | PR-AUC 0.5012 | F1 0.4056\n","[Transformer/F2] Epoch 005 | ROC-AUC 0.7753 | PR-AUC 0.5481 | F1 0.5645\n","[Transformer/F2] Epoch 006 | ROC-AUC 0.7885 | PR-AUC 0.5704 | F1 0.5589\n","[Transformer/F2] Epoch 007 | ROC-AUC 0.7968 | PR-AUC 0.5697 | F1 0.5817\n","[Transformer/F2] Epoch 008 | ROC-AUC 0.7936 | PR-AUC 0.5749 | F1 0.5672\n","[Transformer/F2] Epoch 009 | ROC-AUC 0.7914 | PR-AUC 0.5714 | F1 0.5237\n","[Transformer/F2] Epoch 010 | ROC-AUC 0.7899 | PR-AUC 0.5753 | F1 0.5801\n","[Transformer/F2] Epoch 011 | ROC-AUC 0.7936 | PR-AUC 0.5760 | F1 0.5962\n","[Transformer/F2] Epoch 012 | ROC-AUC 0.7934 | PR-AUC 0.5776 | F1 0.5558\n","[Transformer/F2] Epoch 013 | ROC-AUC 0.7950 | PR-AUC 0.5766 | F1 0.5718\n","[Transformer/F2] Epoch 014 | ROC-AUC 0.7958 | PR-AUC 0.5856 | F1 0.5688\n","[Transformer/F2] Epoch 015 | ROC-AUC 0.7964 | PR-AUC 0.5789 | F1 0.5571\n","[Transformer/F2] Epoch 016 | ROC-AUC 0.7953 | PR-AUC 0.5766 | F1 0.5874\n","[Transformer/F2] Epoch 017 | ROC-AUC 0.7973 | PR-AUC 0.5852 | F1 0.5761\n","[Transformer/F2] Epoch 018 | ROC-AUC 0.7963 | PR-AUC 0.5799 | F1 0.5806\n","[Transformer/F2] Epoch 019 | ROC-AUC 0.7971 | PR-AUC 0.5869 | F1 0.5646\n","[Transformer/F2] Epoch 020 | ROC-AUC 0.7969 | PR-AUC 0.5865 | F1 0.5698\n","[Transformer/F2] Epoch 021 | ROC-AUC 0.7969 | PR-AUC 0.5865 | F1 0.5698\n","[Transformer/F2] Epoch 022 | ROC-AUC 0.7969 | PR-AUC 0.5865 | F1 0.5678\n","[Transformer/F2] Epoch 023 | ROC-AUC 0.7969 | PR-AUC 0.5859 | F1 0.5738\n","[Transformer/F2] Epoch 024 | ROC-AUC 0.7976 | PR-AUC 0.5874 | F1 0.5738\n","[Transformer/F2] Epoch 025 | ROC-AUC 0.7977 | PR-AUC 0.5879 | F1 0.5606\n","[Transformer/F2] Epoch 026 | ROC-AUC 0.7989 | PR-AUC 0.5863 | F1 0.5764\n","[Transformer/F2] Epoch 027 | ROC-AUC 0.7957 | PR-AUC 0.5857 | F1 0.6126\n","[Transformer/F2] Epoch 028 | ROC-AUC 0.7974 | PR-AUC 0.5831 | F1 0.5784\n","[Transformer/F2] Epoch 029 | ROC-AUC 0.7944 | PR-AUC 0.5822 | F1 0.5653\n","[Transformer/F2] Epoch 030 | ROC-AUC 0.8025 | PR-AUC 0.5885 | F1 0.5568\n","[Transformer/F2] Epoch 031 | ROC-AUC 0.7966 | PR-AUC 0.5692 | F1 0.5708\n","[Transformer/F2] Epoch 032 | ROC-AUC 0.7998 | PR-AUC 0.5699 | F1 0.5780\n","[Transformer/F2] Epoch 033 | ROC-AUC 0.7931 | PR-AUC 0.5675 | F1 0.5487\n","[Transformer/F2] Epoch 034 | ROC-AUC 0.8032 | PR-AUC 0.5784 | F1 0.5218\n","[Transformer/F2] Epoch 035 | ROC-AUC 0.8030 | PR-AUC 0.5911 | F1 0.5704\n","[Transformer/F2] Epoch 036 | ROC-AUC 0.7937 | PR-AUC 0.5739 | F1 0.5926\n","[Transformer/F2] Epoch 037 | ROC-AUC 0.8131 | PR-AUC 0.6010 | F1 0.6015\n","[Transformer/F2] Epoch 038 | ROC-AUC 0.7925 | PR-AUC 0.5701 | F1 0.5859\n","[Transformer/F2] Epoch 039 | ROC-AUC 0.8100 | PR-AUC 0.5953 | F1 0.6193\n","[Transformer/F2] Epoch 040 | ROC-AUC 0.7913 | PR-AUC 0.5875 | F1 0.5761\n","[Transformer/F2] Epoch 041 | ROC-AUC 0.8145 | PR-AUC 0.6199 | F1 0.5819\n","[Transformer/F2] Epoch 042 | ROC-AUC 0.8046 | PR-AUC 0.5888 | F1 0.5822\n","[Transformer/F2] Epoch 043 | ROC-AUC 0.8090 | PR-AUC 0.5998 | F1 0.6040\n","[Transformer/F2] Epoch 044 | ROC-AUC 0.7978 | PR-AUC 0.5995 | F1 0.5744\n","[Transformer/F2] Epoch 045 | ROC-AUC 0.8062 | PR-AUC 0.5923 | F1 0.6039\n","[Transformer/F2] Epoch 046 | ROC-AUC 0.7992 | PR-AUC 0.5861 | F1 0.5760\n","[Transformer/F2] Epoch 047 | ROC-AUC 0.7990 | PR-AUC 0.5994 | F1 0.5997\n","[Transformer/F2] Epoch 048 | ROC-AUC 0.8041 | PR-AUC 0.6040 | F1 0.5969\n","[Transformer/F2] Epoch 049 | ROC-AUC 0.8008 | PR-AUC 0.5992 | F1 0.6116\n","[Transformer/F2] Epoch 050 | ROC-AUC 0.8051 | PR-AUC 0.6002 | F1 0.5657\n","[Transformer/F2] Epoch 051 | ROC-AUC 0.8050 | PR-AUC 0.6106 | F1 0.6113\n","[Transformer/F2] Epoch 052 | ROC-AUC 0.8024 | PR-AUC 0.6016 | F1 0.5994\n","[Transformer/F2] Epoch 053 | ROC-AUC 0.8002 | PR-AUC 0.5986 | F1 0.5818\n","[Transformer/F2] Epoch 054 | ROC-AUC 0.8038 | PR-AUC 0.6031 | F1 0.6052\n","[Transformer/F2] Epoch 055 | ROC-AUC 0.8020 | PR-AUC 0.6020 | F1 0.6045\n","[Transformer/F2] Epoch 056 | ROC-AUC 0.8035 | PR-AUC 0.6016 | F1 0.5952\n","âœ… EarlyStopping [Transformer/F2]\n","[NNConv/F2] pos_weight(eff)=3.034\n","[NNConv/F2] Epoch 001 | ROC-AUC 0.6931 | PR-AUC 0.3954 | F1 0.4841\n","[NNConv/F2] Epoch 002 | ROC-AUC 0.7690 | PR-AUC 0.4496 | F1 0.5164\n","[NNConv/F2] Epoch 003 | ROC-AUC 0.7637 | PR-AUC 0.4551 | F1 0.5253\n","[NNConv/F2] Epoch 004 | ROC-AUC 0.7652 | PR-AUC 0.4539 | F1 0.4263\n","[NNConv/F2] Epoch 005 | ROC-AUC 0.7601 | PR-AUC 0.4535 | F1 0.5303\n","[NNConv/F2] Epoch 006 | ROC-AUC 0.7625 | PR-AUC 0.4582 | F1 0.5363\n","[NNConv/F2] Epoch 007 | ROC-AUC 0.7702 | PR-AUC 0.4512 | F1 0.5415\n","[NNConv/F2] Epoch 008 | ROC-AUC 0.7842 | PR-AUC 0.4626 | F1 0.5217\n","[NNConv/F2] Epoch 009 | ROC-AUC 0.7824 | PR-AUC 0.4707 | F1 0.5554\n","[NNConv/F2] Epoch 010 | ROC-AUC 0.7668 | PR-AUC 0.4616 | F1 0.5402\n","[NNConv/F2] Epoch 011 | ROC-AUC 0.7789 | PR-AUC 0.4702 | F1 0.5259\n","[NNConv/F2] Epoch 012 | ROC-AUC 0.7932 | PR-AUC 0.4809 | F1 0.5469\n","[NNConv/F2] Epoch 013 | ROC-AUC 0.7908 | PR-AUC 0.4829 | F1 0.5323\n","[NNConv/F2] Epoch 014 | ROC-AUC 0.7913 | PR-AUC 0.4903 | F1 0.5489\n","[NNConv/F2] Epoch 015 | ROC-AUC 0.7974 | PR-AUC 0.4916 | F1 0.5478\n","[NNConv/F2] Epoch 016 | ROC-AUC 0.7960 | PR-AUC 0.4861 | F1 0.5602\n","[NNConv/F2] Epoch 017 | ROC-AUC 0.7989 | PR-AUC 0.4948 | F1 0.5614\n","[NNConv/F2] Epoch 018 | ROC-AUC 0.7970 | PR-AUC 0.4876 | F1 0.5639\n","[NNConv/F2] Epoch 019 | ROC-AUC 0.7976 | PR-AUC 0.4892 | F1 0.5639\n","[NNConv/F2] Epoch 020 | ROC-AUC 0.7979 | PR-AUC 0.4898 | F1 0.5639\n","[NNConv/F2] Epoch 021 | ROC-AUC 0.7979 | PR-AUC 0.4898 | F1 0.5639\n","[NNConv/F2] Epoch 022 | ROC-AUC 0.7977 | PR-AUC 0.4892 | F1 0.5639\n","[NNConv/F2] Epoch 023 | ROC-AUC 0.7971 | PR-AUC 0.4878 | F1 0.5620\n","[NNConv/F2] Epoch 024 | ROC-AUC 0.7974 | PR-AUC 0.4878 | F1 0.5639\n","[NNConv/F2] Epoch 025 | ROC-AUC 0.7980 | PR-AUC 0.4892 | F1 0.5583\n","[NNConv/F2] Epoch 026 | ROC-AUC 0.7995 | PR-AUC 0.4932 | F1 0.5676\n","[NNConv/F2] Epoch 027 | ROC-AUC 0.8000 | PR-AUC 0.4927 | F1 0.5655\n","[NNConv/F2] Epoch 028 | ROC-AUC 0.8002 | PR-AUC 0.4929 | F1 0.5626\n","[NNConv/F2] Epoch 029 | ROC-AUC 0.7966 | PR-AUC 0.4841 | F1 0.5541\n","[NNConv/F2] Epoch 030 | ROC-AUC 0.8020 | PR-AUC 0.4968 | F1 0.5248\n","[NNConv/F2] Epoch 031 | ROC-AUC 0.7969 | PR-AUC 0.4848 | F1 0.5651\n","[NNConv/F2] Epoch 032 | ROC-AUC 0.7979 | PR-AUC 0.4958 | F1 0.5434\n","[NNConv/F2] Epoch 033 | ROC-AUC 0.7993 | PR-AUC 0.4890 | F1 0.5569\n","[NNConv/F2] Epoch 034 | ROC-AUC 0.7931 | PR-AUC 0.4817 | F1 0.5388\n","[NNConv/F2] Epoch 035 | ROC-AUC 0.8039 | PR-AUC 0.5061 | F1 0.5403\n","[NNConv/F2] Epoch 036 | ROC-AUC 0.7900 | PR-AUC 0.4764 | F1 0.5416\n","[NNConv/F2] Epoch 037 | ROC-AUC 0.7974 | PR-AUC 0.4963 | F1 0.0635\n","[NNConv/F2] Epoch 038 | ROC-AUC 0.8007 | PR-AUC 0.5042 | F1 0.5536\n","[NNConv/F2] Epoch 039 | ROC-AUC 0.7897 | PR-AUC 0.4904 | F1 0.5351\n","[NNConv/F2] Epoch 040 | ROC-AUC 0.8001 | PR-AUC 0.5054 | F1 0.5614\n","[NNConv/F2] Epoch 041 | ROC-AUC 0.8008 | PR-AUC 0.4957 | F1 0.5503\n","[NNConv/F2] Epoch 042 | ROC-AUC 0.8009 | PR-AUC 0.5002 | F1 0.5699\n","[NNConv/F2] Epoch 043 | ROC-AUC 0.7964 | PR-AUC 0.4797 | F1 0.5390\n","[NNConv/F2] Epoch 044 | ROC-AUC 0.7996 | PR-AUC 0.4895 | F1 0.5532\n","[NNConv/F2] Epoch 045 | ROC-AUC 0.7938 | PR-AUC 0.4841 | F1 0.5774\n","[NNConv/F2] Epoch 046 | ROC-AUC 0.8053 | PR-AUC 0.5030 | F1 0.5521\n","[NNConv/F2] Epoch 047 | ROC-AUC 0.8028 | PR-AUC 0.5128 | F1 0.5253\n","[NNConv/F2] Epoch 048 | ROC-AUC 0.8007 | PR-AUC 0.5063 | F1 0.5639\n","[NNConv/F2] Epoch 049 | ROC-AUC 0.7797 | PR-AUC 0.4930 | F1 0.5101\n","[NNConv/F2] Epoch 050 | ROC-AUC 0.8048 | PR-AUC 0.5160 | F1 0.5497\n","[NNConv/F2] Epoch 051 | ROC-AUC 0.7812 | PR-AUC 0.4989 | F1 0.5483\n","[NNConv/F2] Epoch 052 | ROC-AUC 0.7806 | PR-AUC 0.4888 | F1 0.5391\n","[NNConv/F2] Epoch 053 | ROC-AUC 0.7940 | PR-AUC 0.5265 | F1 0.5381\n","[NNConv/F2] Epoch 054 | ROC-AUC 0.7809 | PR-AUC 0.4980 | F1 0.5537\n","[NNConv/F2] Epoch 055 | ROC-AUC 0.7768 | PR-AUC 0.4955 | F1 0.5369\n","[NNConv/F2] Epoch 056 | ROC-AUC 0.7787 | PR-AUC 0.5028 | F1 0.5303\n","[NNConv/F2] Epoch 057 | ROC-AUC 0.7745 | PR-AUC 0.4993 | F1 0.5274\n","[NNConv/F2] Epoch 058 | ROC-AUC 0.7764 | PR-AUC 0.4931 | F1 0.5344\n","[NNConv/F2] Epoch 059 | ROC-AUC 0.7786 | PR-AUC 0.4995 | F1 0.5469\n","[NNConv/F2] Epoch 060 | ROC-AUC 0.7779 | PR-AUC 0.4991 | F1 0.5488\n","[NNConv/F2] Epoch 061 | ROC-AUC 0.7779 | PR-AUC 0.4991 | F1 0.5488\n","âœ… EarlyStopping [NNConv/F2]\n","âœ… Fold2 [Transformer] ROC 0.8169 | PR 0.5298 | F1 0.5246\n","âœ… Fold2 [NNConv]      ROC 0.8129 | PR 0.4516 | F1 0.5387\n","âœ… Fold2 [Ensemble]    ROC 0.8436 | PR 0.5371 | F1 0.5782 (alpha=0.551/0.449)\n","\n","ğŸ“‚ Fold 3 | train=4466 val=1380 test=1475 | moved_from_val=14 moved_from_test=6 | priority_in_val=0 priority_in_test=0\n","[Transformer/F3] pos_weight(eff)=2.972\n","[Transformer/F3] Epoch 001 | ROC-AUC 0.7300 | PR-AUC 0.3947 | F1 0.4098\n","[Transformer/F3] Epoch 002 | ROC-AUC 0.7366 | PR-AUC 0.4121 | F1 0.4845\n","[Transformer/F3] Epoch 003 | ROC-AUC 0.7417 | PR-AUC 0.4362 | F1 0.4537\n","[Transformer/F3] Epoch 004 | ROC-AUC 0.7436 | PR-AUC 0.4552 | F1 0.4532\n","[Transformer/F3] Epoch 005 | ROC-AUC 0.7360 | PR-AUC 0.4536 | F1 0.4689\n","[Transformer/F3] Epoch 006 | ROC-AUC 0.7299 | PR-AUC 0.4490 | F1 0.4666\n","[Transformer/F3] Epoch 007 | ROC-AUC 0.7507 | PR-AUC 0.4625 | F1 0.4960\n","[Transformer/F3] Epoch 008 | ROC-AUC 0.7510 | PR-AUC 0.4688 | F1 0.4806\n","[Transformer/F3] Epoch 009 | ROC-AUC 0.7534 | PR-AUC 0.4720 | F1 0.4789\n","[Transformer/F3] Epoch 010 | ROC-AUC 0.7481 | PR-AUC 0.4640 | F1 0.5032\n","[Transformer/F3] Epoch 011 | ROC-AUC 0.7585 | PR-AUC 0.4816 | F1 0.4826\n","[Transformer/F3] Epoch 012 | ROC-AUC 0.7579 | PR-AUC 0.4768 | F1 0.5075\n","[Transformer/F3] Epoch 013 | ROC-AUC 0.7601 | PR-AUC 0.4775 | F1 0.4822\n","[Transformer/F3] Epoch 014 | ROC-AUC 0.7589 | PR-AUC 0.4797 | F1 0.5102\n","[Transformer/F3] Epoch 015 | ROC-AUC 0.7585 | PR-AUC 0.4819 | F1 0.4924\n","[Transformer/F3] Epoch 016 | ROC-AUC 0.7623 | PR-AUC 0.4858 | F1 0.5079\n","[Transformer/F3] Epoch 017 | ROC-AUC 0.7603 | PR-AUC 0.4824 | F1 0.5037\n","[Transformer/F3] Epoch 018 | ROC-AUC 0.7608 | PR-AUC 0.4830 | F1 0.4982\n","[Transformer/F3] Epoch 019 | ROC-AUC 0.7612 | PR-AUC 0.4839 | F1 0.5006\n","[Transformer/F3] Epoch 020 | ROC-AUC 0.7613 | PR-AUC 0.4840 | F1 0.4982\n","[Transformer/F3] Epoch 021 | ROC-AUC 0.7613 | PR-AUC 0.4840 | F1 0.4982\n","[Transformer/F3] Epoch 022 | ROC-AUC 0.7612 | PR-AUC 0.4832 | F1 0.4935\n","[Transformer/F3] Epoch 023 | ROC-AUC 0.7613 | PR-AUC 0.4826 | F1 0.4918\n","[Transformer/F3] Epoch 024 | ROC-AUC 0.7614 | PR-AUC 0.4829 | F1 0.4935\n","[Transformer/F3] Epoch 025 | ROC-AUC 0.7622 | PR-AUC 0.4807 | F1 0.4830\n","[Transformer/F3] Epoch 026 | ROC-AUC 0.7609 | PR-AUC 0.4800 | F1 0.4941\n","[Transformer/F3] Epoch 027 | ROC-AUC 0.7593 | PR-AUC 0.4765 | F1 0.4759\n","[Transformer/F3] Epoch 028 | ROC-AUC 0.7598 | PR-AUC 0.4759 | F1 0.4982\n","[Transformer/F3] Epoch 029 | ROC-AUC 0.7579 | PR-AUC 0.4807 | F1 0.4923\n","[Transformer/F3] Epoch 030 | ROC-AUC 0.7581 | PR-AUC 0.4792 | F1 0.5222\n","[Transformer/F3] Epoch 031 | ROC-AUC 0.7583 | PR-AUC 0.4724 | F1 0.4917\n","âœ… EarlyStopping [Transformer/F3]\n","[NNConv/F3] pos_weight(eff)=2.972\n","[NNConv/F3] Epoch 001 | ROC-AUC 0.6290 | PR-AUC 0.3247 | F1 0.4072\n","[NNConv/F3] Epoch 002 | ROC-AUC 0.7063 | PR-AUC 0.3452 | F1 0.3887\n","[NNConv/F3] Epoch 003 | ROC-AUC 0.8130 | PR-AUC 0.4922 | F1 0.3854\n","[NNConv/F3] Epoch 004 | ROC-AUC 0.7976 | PR-AUC 0.4839 | F1 0.4969\n","[NNConv/F3] Epoch 005 | ROC-AUC 0.8035 | PR-AUC 0.4817 | F1 0.5372\n","[NNConv/F3] Epoch 006 | ROC-AUC 0.7979 | PR-AUC 0.4748 | F1 0.5184\n","[NNConv/F3] Epoch 007 | ROC-AUC 0.8071 | PR-AUC 0.5135 | F1 0.5296\n","[NNConv/F3] Epoch 008 | ROC-AUC 0.7899 | PR-AUC 0.4841 | F1 0.5082\n","[NNConv/F3] Epoch 009 | ROC-AUC 0.7956 | PR-AUC 0.4981 | F1 0.5235\n","[NNConv/F3] Epoch 010 | ROC-AUC 0.7768 | PR-AUC 0.4678 | F1 0.4979\n","[NNConv/F3] Epoch 011 | ROC-AUC 0.7764 | PR-AUC 0.4768 | F1 0.4976\n","[NNConv/F3] Epoch 012 | ROC-AUC 0.7997 | PR-AUC 0.5105 | F1 0.5424\n","[NNConv/F3] Epoch 013 | ROC-AUC 0.8034 | PR-AUC 0.5179 | F1 0.5411\n","[NNConv/F3] Epoch 014 | ROC-AUC 0.8003 | PR-AUC 0.5233 | F1 0.5539\n","[NNConv/F3] Epoch 015 | ROC-AUC 0.8013 | PR-AUC 0.5194 | F1 0.5246\n","[NNConv/F3] Epoch 016 | ROC-AUC 0.8012 | PR-AUC 0.5196 | F1 0.5459\n","[NNConv/F3] Epoch 017 | ROC-AUC 0.8002 | PR-AUC 0.5177 | F1 0.5348\n","[NNConv/F3] Epoch 018 | ROC-AUC 0.8007 | PR-AUC 0.5174 | F1 0.5551\n","âœ… EarlyStopping [NNConv/F3]\n","âœ… Fold3 [Transformer] ROC 0.7463 | PR 0.4923 | F1 0.4921\n","âœ… Fold3 [NNConv]      ROC 0.7614 | PR 0.4346 | F1 0.3802\n","âœ… Fold3 [Ensemble]    ROC 0.7711 | PR 0.5012 | F1 0.5031 (alpha=0.497/0.503)\n","\n","ğŸ“‚ Fold 4 | train=4629 val=1312 test=1380 | moved_from_val=7 moved_from_test=14 | priority_in_val=0 priority_in_test=0\n","[Transformer/F4] pos_weight(eff)=2.739\n","[Transformer/F4] Epoch 001 | ROC-AUC 0.7647 | PR-AUC 0.4212 | F1 0.4528\n","[Transformer/F4] Epoch 002 | ROC-AUC 0.7527 | PR-AUC 0.4092 | F1 0.3840\n","[Transformer/F4] Epoch 003 | ROC-AUC 0.7480 | PR-AUC 0.4017 | F1 0.4508\n","[Transformer/F4] Epoch 004 | ROC-AUC 0.7700 | PR-AUC 0.4244 | F1 0.4348\n","[Transformer/F4] Epoch 005 | ROC-AUC 0.7662 | PR-AUC 0.4059 | F1 0.4201\n","[Transformer/F4] Epoch 006 | ROC-AUC 0.7831 | PR-AUC 0.4427 | F1 0.4250\n","[Transformer/F4] Epoch 007 | ROC-AUC 0.7902 | PR-AUC 0.4364 | F1 0.4101\n","[Transformer/F4] Epoch 008 | ROC-AUC 0.7926 | PR-AUC 0.4412 | F1 0.4550\n","[Transformer/F4] Epoch 009 | ROC-AUC 0.7995 | PR-AUC 0.4456 | F1 0.4255\n","[Transformer/F4] Epoch 010 | ROC-AUC 0.7898 | PR-AUC 0.4323 | F1 0.4410\n","[Transformer/F4] Epoch 011 | ROC-AUC 0.7956 | PR-AUC 0.4409 | F1 0.4473\n","[Transformer/F4] Epoch 012 | ROC-AUC 0.8023 | PR-AUC 0.4422 | F1 0.4563\n","[Transformer/F4] Epoch 013 | ROC-AUC 0.8014 | PR-AUC 0.4469 | F1 0.4625\n","[Transformer/F4] Epoch 014 | ROC-AUC 0.7990 | PR-AUC 0.4396 | F1 0.4476\n","[Transformer/F4] Epoch 015 | ROC-AUC 0.7983 | PR-AUC 0.4391 | F1 0.4658\n","[Transformer/F4] Epoch 016 | ROC-AUC 0.8005 | PR-AUC 0.4402 | F1 0.4524\n","[Transformer/F4] Epoch 017 | ROC-AUC 0.8010 | PR-AUC 0.4409 | F1 0.4532\n","[Transformer/F4] Epoch 018 | ROC-AUC 0.8018 | PR-AUC 0.4418 | F1 0.4486\n","[Transformer/F4] Epoch 019 | ROC-AUC 0.8012 | PR-AUC 0.4413 | F1 0.4501\n","[Transformer/F4] Epoch 020 | ROC-AUC 0.8013 | PR-AUC 0.4414 | F1 0.4501\n","[Transformer/F4] Epoch 021 | ROC-AUC 0.8013 | PR-AUC 0.4414 | F1 0.4501\n","[Transformer/F4] Epoch 022 | ROC-AUC 0.8014 | PR-AUC 0.4414 | F1 0.4537\n","[Transformer/F4] Epoch 023 | ROC-AUC 0.8011 | PR-AUC 0.4413 | F1 0.4544\n","[Transformer/F4] Epoch 024 | ROC-AUC 0.8011 | PR-AUC 0.4411 | F1 0.4544\n","[Transformer/F4] Epoch 025 | ROC-AUC 0.8020 | PR-AUC 0.4416 | F1 0.4541\n","[Transformer/F4] Epoch 026 | ROC-AUC 0.8018 | PR-AUC 0.4424 | F1 0.4398\n","[Transformer/F4] Epoch 027 | ROC-AUC 0.8013 | PR-AUC 0.4429 | F1 0.4365\n","âœ… EarlyStopping [Transformer/F4]\n","[NNConv/F4] pos_weight(eff)=2.739\n","[NNConv/F4] Epoch 001 | ROC-AUC 0.5700 | PR-AUC 0.1995 | F1 0.0000\n","[NNConv/F4] Epoch 002 | ROC-AUC 0.7741 | PR-AUC 0.4072 | F1 0.0000\n","[NNConv/F4] Epoch 003 | ROC-AUC 0.7292 | PR-AUC 0.3409 | F1 0.3784\n","[NNConv/F4] Epoch 004 | ROC-AUC 0.7637 | PR-AUC 0.3991 | F1 0.5106\n","[NNConv/F4] Epoch 005 | ROC-AUC 0.7623 | PR-AUC 0.3938 | F1 0.3922\n","[NNConv/F4] Epoch 006 | ROC-AUC 0.7759 | PR-AUC 0.3896 | F1 0.5018\n","[NNConv/F4] Epoch 007 | ROC-AUC 0.7711 | PR-AUC 0.4198 | F1 0.4351\n","[NNConv/F4] Epoch 008 | ROC-AUC 0.7739 | PR-AUC 0.4008 | F1 0.4505\n","[NNConv/F4] Epoch 009 | ROC-AUC 0.7804 | PR-AUC 0.4180 | F1 0.3968\n","[NNConv/F4] Epoch 010 | ROC-AUC 0.7947 | PR-AUC 0.4238 | F1 0.4508\n","[NNConv/F4] Epoch 011 | ROC-AUC 0.8021 | PR-AUC 0.4351 | F1 0.3979\n","[NNConv/F4] Epoch 012 | ROC-AUC 0.7883 | PR-AUC 0.4351 | F1 0.4144\n","[NNConv/F4] Epoch 013 | ROC-AUC 0.7934 | PR-AUC 0.4263 | F1 0.5008\n","[NNConv/F4] Epoch 014 | ROC-AUC 0.7938 | PR-AUC 0.4255 | F1 0.4865\n","[NNConv/F4] Epoch 015 | ROC-AUC 0.7935 | PR-AUC 0.4205 | F1 0.4495\n","[NNConv/F4] Epoch 016 | ROC-AUC 0.7720 | PR-AUC 0.3844 | F1 0.4603\n","[NNConv/F4] Epoch 017 | ROC-AUC 0.7948 | PR-AUC 0.4183 | F1 0.4432\n","[NNConv/F4] Epoch 018 | ROC-AUC 0.7983 | PR-AUC 0.4220 | F1 0.4500\n","[NNConv/F4] Epoch 019 | ROC-AUC 0.7925 | PR-AUC 0.4097 | F1 0.4640\n","[NNConv/F4] Epoch 020 | ROC-AUC 0.7927 | PR-AUC 0.4098 | F1 0.4654\n","[NNConv/F4] Epoch 021 | ROC-AUC 0.7927 | PR-AUC 0.4098 | F1 0.4654\n","[NNConv/F4] Epoch 022 | ROC-AUC 0.7934 | PR-AUC 0.4109 | F1 0.4620\n","[NNConv/F4] Epoch 023 | ROC-AUC 0.7915 | PR-AUC 0.4097 | F1 0.4615\n","[NNConv/F4] Epoch 024 | ROC-AUC 0.7971 | PR-AUC 0.4175 | F1 0.4615\n","[NNConv/F4] Epoch 025 | ROC-AUC 0.7931 | PR-AUC 0.4152 | F1 0.4528\n","[NNConv/F4] Epoch 026 | ROC-AUC 0.7950 | PR-AUC 0.4238 | F1 0.4469\n","âœ… EarlyStopping [NNConv/F4]\n","âœ… Fold4 [Transformer] ROC 0.7635 | PR 0.4529 | F1 0.5307\n","âœ… Fold4 [NNConv]      ROC 0.7937 | PR 0.4727 | F1 0.4799\n","âœ… Fold4 [Ensemble]    ROC 0.7890 | PR 0.4809 | F1 0.5184 (alpha=0.504/0.496)\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_scaffold5fold/cv_results_transformer.csv\n","ğŸ¯ å¹³å‡çµæœ:\n","ROC-AUC    0.769237\n","PR-AUC     0.453141\n","F1         0.486278\n","Name: Mean, dtype: float64\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_scaffold5fold/cv_results_nnconv.csv\n","ğŸ¯ å¹³å‡çµæœ:\n","ROC-AUC    0.777360\n","PR-AUC     0.433381\n","F1         0.389825\n","Name: Mean, dtype: float64\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_scaffold5fold/cv_results_ensemble.csv\n","ğŸ¯ å¹³å‡çµæœ:\n","ROC-AUC    0.794258\n","PR-AUC     0.475905\n","F1         0.478105\n","Name: Mean, dtype: float64\n","\n","âœ… å®Œäº†: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_ens_trans_nn_scaffold5fold\n","â„¹ï¸ æ¤œè¨¼ã§é‡ã¿é©ç”¨: True / ãƒ†ã‚¹ãƒˆã§é‡ã¿é©ç”¨: False\n"]}]},{"cell_type":"code","source":["# ================================================\n","# LCO-CV (K=5) - TransformerConv & NNConv Ensemble (CIDå„ªå…ˆ=å…ƒä»•æ§˜)\n","#  - features: d.x + d.g + d.r (+ edge_attr)\n","#  - é™½æ€§ãŒå°‘ãªã„å ´åˆã®ã¿ SMILES ãƒ©ãƒ³ãƒ€ãƒ åŒ–ã§ä¸Šé™ä»˜ãã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒ«\n","#  - æ¤œè¨¼PR-AUCæœ€å¤§ã¨ãªã‚‹ Ensemble é‡ã¿ Î± ã‚’è‡ªå‹•é¸æŠ\n","#  - â˜… æŒ‡å®šCIDã®ã¿ã€Œå¿…ãšå­¦ç¿’ã«å«ã‚ã‚‹ã€(val/testã‹ã‚‰é™¤å¤–) ï¼ ã‚¯ãƒ©ã‚¹ã‚¿ã¯å›ºå®šã—ãªã„\n","# --- ä»¥ä¸‹ã€åŠ ç­† ---\n","#  - â˜… SampleWeightå¯¾å¿œï¼š\n","#      ãƒ»å­¦ç¿’æå¤±ã¯å¿…ãšã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã§åŠ é‡ï¼ˆBCEWithLogitsLoss(reduction='none') â†’ é‡ã¿ä»˜ãå¹³å‡ï¼‰\n","#      ãƒ»pos_weight ã¯é‡ã¿ä»˜ãå®ŸåŠ¹æ¯”ï¼ˆneg_sum/pos_sumã€ä¸Šé™10ï¼‰ã§ç®—å‡º\n","#      ãƒ»æ¤œè¨¼/ãƒ†ã‚¹ãƒˆã® ROCãƒ»PRãƒ»F1ï¼ˆå›³ãƒ»æ•°å€¤ï¼‰ãŠã‚ˆã³ Î±* æœ€é©åŒ–ï¼ˆVal PR-AUCï¼‰ã«ã‚‚é‡ã¿ã‚’é©ç”¨å¯\n","#      ãƒ»é‡ã¿å±æ€§å€™è£œï¼š[\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]ï¼ˆç„¡ã‘ã‚Œã° 1.0ï¼‰\n","#      ãƒ»ãƒ•ãƒ©ã‚°ï¼šAPPLY_WEIGHT_IN_VALï¼ˆæ¤œè¨¼ã«é‡ã¿ã‚’é©ç”¨ï¼‰ã€APPLY_WEIGHT_IN_TESTï¼ˆãƒ†ã‚¹ãƒˆã«é‡ã¿ã‚’é©ç”¨ï¼‰\n","# ================================================\n","import os, random, math, warnings as _warnings\n","import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from rdkit import DataStructs\n","from rdkit import RDLogger\n","\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, auc, average_precision_score, roc_curve\n","from torch.serialization import add_safe_globals\n","\n","# --- quiet ---\n","RDLogger.DisableLog('rdApp.*')\n","_warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# ----- å†ç¾æ€§ -----\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED)\n","torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n","\n","# ----- è¨­å®š -----\n","PT_PATH  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\"\n","SAVE_DIR = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_lco5_trans_nn_ens_posaug_CIDprior\"\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","DEVICE   = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","K          = 5\n","BATCH_TR   = 64\n","BATCH_TE   = 128\n","LR         = 3e-4\n","WD         = 1e-4\n","TMAX       = 20\n","PATIENCE   = 10\n","MAX_EPOCH  = 200\n","CLIP       = 5.0\n","ALPHAS     = np.linspace(0, 1, 11)   # 0,0.1,...,1.0\n","\n","# --- é™½æ€§ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒ«æ–¹é‡ ---\n","AUG_TARGET_POS_RATE = 0.30\n","AUG_MAX_PER_POS     = 3\n","\n","# â˜… å­¦ç¿’ã¸å¸¸æ™‚å«ã‚ã‚‹ CIDï¼ˆCIDå˜ä½ã§trainã¸ã€‚ã‚¯ãƒ©ã‚¹ã‚¿å›ºå®šã¯ã—ãªã„ï¼‰\n","PRIORITY_CIDS = {3348, 3955, 2724385, 10315094, 68770, 13342, 441074}\n","\n","# â˜… SampleWeight è¨­å®šï¼ˆåŠ ç­†ï¼‰\n","WEIGHT_ATTR_CANDIDATES = [\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]\n","APPLY_WEIGHT_IN_VAL  = True   # æ¤œè¨¼ã® PR-AUC/ROC ãªã©ã«é‡ã¿é©ç”¨ï¼ˆÎ±*æœ€é©åŒ–ã‚‚é‡ã¿ä»˜ãï¼‰\n","APPLY_WEIGHT_IN_TEST = False  # ãƒ†ã‚¹ãƒˆã®æŒ‡æ¨™ãƒ»å›³ã«é‡ã¿é©ç”¨ï¼ˆå¿…è¦ã«å¿œã˜ã¦ Trueï¼‰\n","\n","# ===== Utils =====\n","def pr_auc_score(y, p, sample_weight=None):\n","    prec, rec, _ = precision_recall_curve(y, p, sample_weight=sample_weight)\n","    return auc(rec, prec)\n","\n","def _get_weight_from_data(d):\n","    for nm in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(d, nm):\n","            v = getattr(d, nm)\n","            return float(v.item()) if torch.is_tensor(v) else float(v)\n","    return 1.0\n","\n","def _to_1d(w):\n","    if torch.is_tensor(w):\n","        if w.dim() == 2 and w.size(1) == 1: return w.view(-1)\n","        return w.view(-1)\n","    return torch.tensor(w, dtype=torch.float32)\n","\n","def get_batch_weights(batch, device=None):\n","    for nm in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(batch, nm):\n","            w = getattr(batch, nm)\n","            w = _to_1d(w).to(device or batch.y.device).float()\n","            return w, nm\n","    return torch.ones(batch.y.numel(), device=device or batch.y.device, dtype=torch.float32), \"CONST1\"\n","\n","def pos_weight_from(dataset):\n","    ys = torch.tensor([float(d.y.item()) for d in dataset])\n","    ws = torch.tensor([_get_weight_from_data(d) for d in dataset], dtype=torch.float32)\n","    pos_sum = ws[ys == 1].sum()\n","    neg_sum = ws[ys == 0].sum()\n","    w = (neg_sum / torch.clamp(pos_sum, min=1e-8)).item()\n","    return torch.tensor([min(max(w, 1.0), 10.0)], dtype=torch.float32)\n","\n","@torch.no_grad()\n","def eval_probs_model(m, ds, batch_size=BATCH_TE):\n","    if len(ds) == 0:\n","        return np.array([]), np.array([]), np.array([])\n","    m.eval(); ys, ps, ws = [], [], []\n","    for bt in DataLoader(ds, batch_size=batch_size, shuffle=False):\n","        bt = bt.to(DEVICE)\n","        ys.append(bt.y.detach().cpu())\n","        ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","        w, _ = get_batch_weights(bt, DEVICE)\n","        ws.append(w.detach().cpu())\n","    return torch.cat(ys).numpy(), torch.cat(ps).numpy(), torch.cat(ws).numpy()\n","\n","def best_alpha_for_prauc(y_val, p1, p2, alphas=ALPHAS, sample_weight=None):\n","    best_a, best_s = 0.5, -1.0\n","    for a in alphas:\n","        pv = a * p1 + (1 - a) * p2\n","        s = pr_auc_score(y_val, pv, sample_weight=sample_weight)\n","        if s > best_s:\n","            best_s, best_a = s, a\n","    return best_a, best_s\n","\n","def infer_dim(t):\n","    if t.dim() == 1: return t.numel()\n","    if t.dim() in (2,3): return t.size(-1)\n","    raise RuntimeError(f\"æœªçŸ¥ã®ãƒ†ãƒ³ã‚½ãƒ«æ¬¡å…ƒ: {t.size()}\")\n","\n","def ensure_priority_in_train(train_idx, val_idx, test_idx, data, priority_cids):\n","    \"\"\"CIDå˜ä½ã§å„ªå…ˆã‚µãƒ³ãƒ—ãƒ«ã‚’trainã¸å¼·åˆ¶ç§»å‹•ï¼ˆval/testã‹ã‚‰é™¤å¤–ï¼‰\"\"\"\n","    pr_set = set(priority_cids)\n","    def is_pr(i): return int(getattr(data[i], \"cid\", -1)) in pr_set\n","\n","    moved_from_val  = [i for i in val_idx  if is_pr(i)]\n","    moved_from_test = [i for i in test_idx if is_pr(i)]\n","\n","    if moved_from_val or moved_from_test:\n","        print(f\"[CID-PRIOR] move to train | from val: {len(moved_from_val)}, from test: {len(moved_from_test)}\")\n","\n","    train_idx = list(train_idx) + moved_from_val + moved_from_test\n","    val_idx   = [i for i in val_idx  if i not in moved_from_val]\n","    test_idx  = [i for i in test_idx if i not in moved_from_test]\n","\n","    train_idx = sorted(set(train_idx))\n","    val_idx   = sorted(set(val_idx)   - set(train_idx))\n","    test_idx  = sorted(set(test_idx)  - set(train_idx) - set(val_idx))\n","\n","    def contains_priority(indices):\n","        return any(int(getattr(data[i], \"cid\", -1)) in pr_set for i in indices)\n","    assert not contains_priority(val_idx),  \"priority CID in VAL (should be TRAIN)\"\n","    assert not contains_priority(test_idx), \"priority CID in TEST (should be TRAIN)\"\n","\n","    return train_idx, val_idx, test_idx\n","\n","# ----- ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆPyTorch 2.6 å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¯¾å¿œï¼‰ -----\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception as e:\n","        print(f\"[WARN] add_safe_globals å¤±æ•—: {e}\")\n","    try:\n","        obj = torch.load(path)  # default weights_only=True\n","    except Exception as e:\n","        print(f\"[WARN] å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆ{e}ï¼‰ã€‚weights_only=False ã§å†è©¦è¡Œï¼ˆä¿¡é ¼ãƒ•ã‚¡ã‚¤ãƒ«å‰æï¼‰ã€‚\")\n","        obj = torch.load(path, weights_only=False)\n","\n","    if isinstance(obj, list):\n","        return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj:\n","        return obj[\"data_list\"]\n","    try:\n","        return list(obj)\n","    except Exception as e:\n","        raise RuntimeError(f\"æœªçŸ¥å½¢å¼: {type(obj)}; liståŒ–å¤±æ•—: {e}\")\n","\n","# ===== ãƒ¢ãƒ‡ãƒ« =====\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self, X_DIM, G_DIM, R_DIM, E_DIM, HID=256):\n","        super().__init__()\n","        self.c1 = TransformerConv(X_DIM, HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.c2 = TransformerConv(HID,  HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x.float(), g.float(), r.float()], dim=1)).view(-1)\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hidden = max(64, min(256, in_attr_dim * 8))\n","    return nn.Sequential(nn.Linear(in_attr_dim, hidden), nn.ReLU(),\n","                         nn.Linear(hidden, in_channels * out_channels))\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self, X_DIM, G_DIM, R_DIM, E_DIM, HID=256):\n","        super().__init__()\n","        edge_nn1 = make_edge_mlp(E_DIM, HID, X_DIM)\n","        edge_nn2 = make_edge_mlp(E_DIM, HID, HID)\n","        self.c1 = NNConv(X_DIM, HID, edge_nn1, aggr='mean')\n","        self.c2 = NNConv(HID,  HID, edge_nn2, aggr='mean')\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x.float(), g.float(), r.float()], dim=1)).view(-1)\n","\n","# ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====\n","def main():\n","    # 1) ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰\n","    data = load_pyg_list(PT_PATH)\n","    if len(data) == 0:\n","        raise RuntimeError(\"data ãŒç©ºã§ã™ã€‚\")\n","    print(f\"âœ… ã‚°ãƒ©ãƒ•æ•°: {len(data)}\")\n","\n","    # 2) æ¬¡å…ƒç¢ºèª\n","    sample = data[0]\n","    X_DIM = sample.x.size(-1)\n","    if not hasattr(sample, \"edge_attr\") or sample.edge_attr is None:\n","        raise RuntimeError(\"edge_attr ãŒå¿…è¦ã§ã™ã€‚\")\n","    E_DIM = sample.edge_attr.size(-1)\n","    G_DIM = infer_dim(sample.g)\n","    R_DIM = infer_dim(sample.r)\n","    HID   = 256\n","    print(f\"[INFO] Dims: x={X_DIM}, edge={E_DIM}, g={G_DIM}, r={R_DIM}\")\n","\n","    # 3) KMeansã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆLCOãƒ™ãƒ¼ã‚¹ï¼‰\n","    fps = []\n","    for d in data:\n","        m = Chem.MolFromSmiles(d.smiles)\n","        arr = np.zeros((2048,), dtype=np.float32)\n","        fp = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048) if m is not None else None\n","        if fp is None:\n","            fps.append(arr)\n","        else:\n","            DataStructs.ConvertToNumpyArray(fp, arr)\n","            fps.append(arr)\n","\n","    km = KMeans(n_clusters=K, random_state=SEED, n_init=10).fit(fps)\n","    for d, c in zip(data, km.labels_):\n","        d.cluster = int(c)\n","\n","    # 4) ã‚¯ãƒ©ã‚¹ã‚¿ â†’ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¡¨\n","    cluster_to_indices = {cl: [] for cl in range(K)}\n","    for i, d in enumerate(data):\n","        cluster_to_indices[int(d.cluster)].append(i)\n","\n","    # 5) LCO-CVï¼ˆtest=foldã‚¯ãƒ©ã‚¹ã‚¿ã€val=(fold+1)%Kã€train=æ®‹ã‚Šï¼‰\n","    rows = []\n","    for fold in range(K):\n","        test_cls = fold\n","        val_cls  = (fold + 1) % K\n","        test_idx = list(cluster_to_indices[test_cls])\n","        val_idx  = list(cluster_to_indices[val_cls])\n","        train_idx = [i for cl, idxs in cluster_to_indices.items() if cl not in (test_cls, val_cls) for i in idxs]\n","\n","        # --- â˜… CIDå˜ä½ã§å„ªå…ˆã‚µãƒ³ãƒ—ãƒ«ã‚’trainã¸å¼·åˆ¶ç§»å‹•ï¼ˆval/testã‹ã‚‰å¤–ã™ï¼‰\n","        train_idx, val_idx, test_idx = ensure_priority_in_train(train_idx, val_idx, test_idx, data, PRIORITY_CIDS)\n","\n","        train_base = [data[i] for i in sorted(train_idx)]\n","        val_data   = [data[i] for i in sorted(val_idx)]\n","        test_data  = [data[i] for i in sorted(test_idx)]\n","\n","        # ---- é™½æ€§ãŒå°‘ãªã„ã¨ãã®ã¿ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆtrainã®ã¿ï¼‰----\n","        n_train = len(train_base)\n","        pos_cnt = sum(int(d.y) for d in train_base)\n","        neg_cnt = n_train - pos_cnt\n","        pos_rate = pos_cnt / max(1, n_train)\n","        target_pos = math.ceil(AUG_TARGET_POS_RATE * n_train)\n","        need_pos   = max(0, target_pos - pos_cnt)\n","\n","        if pos_cnt > 0 and need_pos > 0:\n","            per_pos_aug = max(1, min(AUG_MAX_PER_POS, math.ceil(need_pos / pos_cnt)))\n","            train_aug = []\n","            for d in train_base:\n","                if int(d.y) == 1:\n","                    m = Chem.MolFromSmiles(d.smiles)\n","                    if m is None:\n","                        continue\n","                    for _ in range(per_pos_aug):\n","                        dd = d.clone()\n","                        # é‡ã¿ã¯ clone ã§å¼•ãç¶™ãŒã‚Œã‚‹æƒ³å®šï¼ˆå®‰å…¨ã®ãŸã‚ãã®ã¾ã¾ï¼‰\n","                        dd.smiles = Chem.MolToSmiles(m, doRandom=True)\n","                        train_aug.append(dd)\n","            train_data = train_base + train_aug\n","            print(f\"ğŸ” Fold {fold}: pos-aug enabled | base_pos={pos_cnt}, neg={neg_cnt}, \"\n","                  f\"pos_rate={pos_rate:.3f} -> target={AUG_TARGET_POS_RATE:.2f}, \"\n","                  f\"per_pos_aug={per_pos_aug}, +aug={len(train_aug)}, new_train={len(train_data)}\")\n","        else:\n","            train_data = train_base\n","            print(f\"ğŸ” Fold {fold}: pos-aug skipped | base_pos={pos_cnt}, neg={neg_cnt}, pos_rate={pos_rate:.3f}\")\n","\n","        print(f\"\\nğŸ“‚ Fold {fold} | train={len(train_data)} val={len(val_data)} test={len(test_data)}\")\n","\n","        # ---- å­¦ç¿’ï¼ˆ1ãƒ¢ãƒ‡ãƒ«ï¼‰ ----\n","        def train_one(model, train_set, val_set, save_path, tag):\n","            model.to(DEVICE)\n","            pw = pos_weight_from(train_set).to(DEVICE)\n","            crit = nn.BCEWithLogitsLoss(pos_weight=pw, reduction='none')  # per-sample\n","            opt  = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n","            sch  = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=TMAX)\n","\n","            best_auc, wait = 0.0, 0\n","            for ep in range(1, MAX_EPOCH + 1):\n","                model.train()\n","                for bt in DataLoader(train_set, batch_size=BATCH_TR, shuffle=True):\n","                    bt = bt.to(DEVICE)\n","                    logits = model(bt)\n","                    loss_vec = crit(logits, bt.y.float())\n","                    sw, _nm = get_batch_weights(bt, DEVICE)\n","                    loss = (loss_vec * sw).sum() / (sw.sum() + 1e-8)\n","\n","                    opt.zero_grad()\n","                    loss.backward()\n","                    nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n","                    opt.step()\n","                sch.step()\n","\n","                yv, pv, wv = eval_probs_model(model, val_set)\n","                if yv.size > 0:\n","                    if APPLY_WEIGHT_IN_VAL:\n","                        roc = roc_auc_score(yv, pv, sample_weight=wv)\n","                        prc = pr_auc_score(yv, pv, sample_weight=wv)\n","                    else:\n","                        roc = roc_auc_score(yv, pv)\n","                        prc = pr_auc_score(yv, pv)\n","                    f1  = f1_score(yv, (pv >= 0.5).astype(int))\n","                else:\n","                    roc = prc = f1 = 0.0\n","                print(f\"[{tag}] Ep{ep:03d} | ROC={roc:.4f} PR={prc:.4f} F1={f1:.4f}\")\n","\n","                if roc > best_auc:\n","                    best_auc, wait = roc, 0\n","                    torch.save(model.state_dict(), save_path)\n","                else:\n","                    wait += 1\n","                    if wait >= PATIENCE:\n","                        print(f\"âœ… EarlyStopping [{tag}]\")\n","                        break\n","\n","            model.load_state_dict(torch.load(save_path, map_location=DEVICE))\n","            yv, pv, wv = eval_probs_model(model, val_set)\n","            return model, yv, pv, wv\n","\n","        # --- å­¦ç¿’ï¼ˆTransformer / NNConvï¼‰ ---\n","        m_tr = Transformer_DX_DG_DR(X_DIM, G_DIM, R_DIM, E_DIM, HID)\n","        m_nn = NNConv_DX_DG_DR(      X_DIM, G_DIM, R_DIM, E_DIM, HID)\n","        p_tr = os.path.join(SAVE_DIR, f\"trans_fold{fold}.pt\")\n","        p_nn = os.path.join(SAVE_DIR, f\"nnconv_fold{fold}.pt\")\n","\n","        m_tr, yv, pv_tr, wv = train_one(m_tr, train_data, val_data, p_tr, f\"Transformer/F{fold}\")\n","        m_nn, _,  pv_nn, _  = train_one(m_nn, train_data, val_data, p_nn, f\"NNConv/F{fold}\")\n","\n","        # --- æ¤œè¨¼ã§ Î±*: PR-AUC æœ€å¤§ï¼ˆé‡ã¿é©ç”¨å¯ï¼‰ ---\n","        if yv.size == 0:\n","            alpha_star, pr_val = 0.5, 0.0\n","        else:\n","            alpha_star, pr_val = best_alpha_for_prauc(yv, pv_tr, pv_nn,\n","                                                      alphas=ALPHAS,\n","                                                      sample_weight=wv if APPLY_WEIGHT_IN_VAL else None)\n","        print(f\"â­ Fold{fold} best Î±={alpha_star:.2f} (Val PR-AUC={pr_val:.4f}{' [weighted]' if APPLY_WEIGHT_IN_VAL else ''})\")\n","\n","        # --- ãƒ†ã‚¹ãƒˆ ---\n","        yt, pt_tr, wt = eval_probs_model(m_tr, test_data)\n","        _,  pt_nn, wt2 = eval_probs_model(m_nn, test_data)\n","        if yt.size == 0:\n","            print(f\"[WARN] Fold{fold}: test ãŒç©ºã®ãŸã‚è©•ä¾¡ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚\")\n","            continue\n","        assert np.allclose(wt, wt2)\n","\n","        pt_en = alpha_star * pt_tr + (1 - alpha_star) * pt_nn\n","\n","        def pack(prefix, y, p, sw=None):\n","            if sw is not None:\n","                return {\n","                    f\"{prefix}_ROC\": roc_auc_score(y, p, sample_weight=sw),\n","                    f\"{prefix}_PR\":  pr_auc_score(y, p, sample_weight=sw),\n","                    f\"{prefix}_F1\":  f1_score(y, (p >= 0.5).astype(int)),  # F1ã¯è¡¨ç¤ºç”¨ã«éåŠ é‡\n","                }\n","            else:\n","                return {\n","                    f\"{prefix}_ROC\": roc_auc_score(y, p),\n","                    f\"{prefix}_PR\":  pr_auc_score(y, p),\n","                    f\"{prefix}_F1\":  f1_score(y, (p >= 0.5).astype(int)),\n","                }\n","\n","        sw_use = wt if APPLY_WEIGHT_IN_TEST else None\n","        rec = {\"Fold\": fold, \"Alpha\": float(alpha_star)}\n","        rec.update(pack(\"Transformer\", yt, pt_tr, sw_use))\n","        rec.update(pack(\"NNConv\",      yt, pt_nn, sw_use))\n","        rec.update(pack(\"Ensemble\",    yt, pt_en, sw_use))\n","        rows.append(rec)\n","\n","        print(f\"âœ… Fold{fold} [Transformer] ROC={rec['Transformer_ROC']:.4f} PR={rec['Transformer_PR']:.4f} F1={rec['Transformer_F1']:.4f}\")\n","        print(f\"âœ… Fold{fold} [NNConv]      ROC={rec['NNConv_ROC']:.4f} PR={rec['NNConv_PR']:.4f} F1={rec['NNConv_F1']:.4f}\")\n","        print(f\"âœ… Fold{fold} [Ensemble]    ROC={rec['Ensemble_ROC']:.4f} PR={rec['Ensemble_PR']:.4f} F1={rec['Ensemble_F1']:.4f} (Î±={alpha_star:.2f})\")\n","\n","    # 6) ä¿å­˜ãƒ»æ¦‚è¦\n","    if len(rows) == 0:\n","        print(\"\\nâš ï¸ ã™ã¹ã¦ã®foldãŒè©•ä¾¡ã‚¹ã‚­ãƒƒãƒ—ã¨ãªã‚Šã¾ã—ãŸã€‚\")\n","        return\n","\n","    df = pd.DataFrame(rows)\n","    out_csv = os.path.join(SAVE_DIR, \"lco_cv_metrics_trans_nn_ensemble_CIDprior.csv\")\n","    df.to_csv(out_csv, index=False)\n","\n","    metrics_cols = [c for c in df.columns if c not in [\"Fold\", \"Alpha\"]]\n","    mean_row = df[metrics_cols].mean().to_dict()\n","    std_row  = df[metrics_cols].std().to_dict()\n","    print(\"\\nğŸ‰ LCO-CV å®Œäº†ï¼\")\n","    print(\"å¹³å‡å€¤:\", {k: float(v) for k, v in mean_row.items()})\n","    print(\"æ¨™æº–åå·®:\", {k: float(v) for k, v in std_row.items()})\n","    print(\"Î±*\", df[\"Alpha\"].round(2).tolist())\n","    print(f\"ğŸ“ Saved: {out_csv}\")\n","    print(f\"â„¹ï¸ æ¤œè¨¼ã§é‡ã¿é©ç”¨: {APPLY_WEIGHT_IN_VAL} / ãƒ†ã‚¹ãƒˆã§é‡ã¿é©ç”¨: {APPLY_WEIGHT_IN_TEST}\")\n","\n","if __name__ == \"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IeNnH2Q4l2M6","executionInfo":{"status":"ok","timestamp":1760683309322,"user_tz":-540,"elapsed":263284,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"e490f087-8356-40d1-a473-30aaca112ebb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ã‚°ãƒ©ãƒ•æ•°: 7321\n","[INFO] Dims: x=5, edge=6, g=7, r=10\n","ğŸ” Fold 0: pos-aug enabled | base_pos=1482, neg=4922, pos_rate=0.231 -> target=0.30, per_pos_aug=1, +aug=1482, new_train=7886\n","\n","ğŸ“‚ Fold 0 | train=7886 val=632 test=285\n","[Transformer/F0] Ep001 | ROC=0.5966 PR=0.0766 F1=0.1379\n","[Transformer/F0] Ep002 | ROC=0.6960 PR=0.1032 F1=0.1805\n","[Transformer/F0] Ep003 | ROC=0.7103 PR=0.1116 F1=0.1287\n","[Transformer/F0] Ep004 | ROC=0.7057 PR=0.1166 F1=0.1524\n","[Transformer/F0] Ep005 | ROC=0.7071 PR=0.1147 F1=0.1720\n","[Transformer/F0] Ep006 | ROC=0.7371 PR=0.1231 F1=0.1441\n","[Transformer/F0] Ep007 | ROC=0.7483 PR=0.1344 F1=0.1784\n","[Transformer/F0] Ep008 | ROC=0.7625 PR=0.1366 F1=0.1853\n","[Transformer/F0] Ep009 | ROC=0.8113 PR=0.1337 F1=0.2025\n","[Transformer/F0] Ep010 | ROC=0.8243 PR=0.1367 F1=0.1942\n","[Transformer/F0] Ep011 | ROC=0.8336 PR=0.1393 F1=0.2335\n","[Transformer/F0] Ep012 | ROC=0.8558 PR=0.1496 F1=0.2532\n","[Transformer/F0] Ep013 | ROC=0.8717 PR=0.1642 F1=0.2419\n","[Transformer/F0] Ep014 | ROC=0.8385 PR=0.1369 F1=0.1923\n","[Transformer/F0] Ep015 | ROC=0.8619 PR=0.1530 F1=0.2542\n","[Transformer/F0] Ep016 | ROC=0.8546 PR=0.1472 F1=0.2273\n","[Transformer/F0] Ep017 | ROC=0.8476 PR=0.1429 F1=0.2239\n","[Transformer/F0] Ep018 | ROC=0.8566 PR=0.1484 F1=0.2372\n","[Transformer/F0] Ep019 | ROC=0.8566 PR=0.1484 F1=0.2459\n","[Transformer/F0] Ep020 | ROC=0.8558 PR=0.1478 F1=0.2410\n","[Transformer/F0] Ep021 | ROC=0.8558 PR=0.1478 F1=0.2410\n","[Transformer/F0] Ep022 | ROC=0.8551 PR=0.1472 F1=0.2400\n","[Transformer/F0] Ep023 | ROC=0.8528 PR=0.1456 F1=0.2353\n","âœ… EarlyStopping [Transformer/F0]\n","[NNConv/F0] Ep001 | ROC=0.7067 PR=0.1505 F1=0.3014\n","[NNConv/F0] Ep002 | ROC=0.6448 PR=0.0860 F1=0.2200\n","[NNConv/F0] Ep003 | ROC=0.6709 PR=0.1152 F1=0.1179\n","[NNConv/F0] Ep004 | ROC=0.6521 PR=0.1140 F1=0.1401\n","[NNConv/F0] Ep005 | ROC=0.7116 PR=0.1193 F1=0.1925\n","[NNConv/F0] Ep006 | ROC=0.6861 PR=0.1170 F1=0.1091\n","[NNConv/F0] Ep007 | ROC=0.6838 PR=0.1150 F1=0.1616\n","[NNConv/F0] Ep008 | ROC=0.7102 PR=0.1158 F1=0.1263\n","[NNConv/F0] Ep009 | ROC=0.6860 PR=0.1181 F1=0.1704\n","[NNConv/F0] Ep010 | ROC=0.7648 PR=0.1384 F1=0.1704\n","[NNConv/F0] Ep011 | ROC=0.8085 PR=0.1536 F1=0.1714\n","[NNConv/F0] Ep012 | ROC=0.7219 PR=0.1403 F1=0.1862\n","[NNConv/F0] Ep013 | ROC=0.7134 PR=0.1385 F1=0.1771\n","[NNConv/F0] Ep014 | ROC=0.7319 PR=0.1413 F1=0.1736\n","[NNConv/F0] Ep015 | ROC=0.7584 PR=0.1515 F1=0.1928\n","[NNConv/F0] Ep016 | ROC=0.7419 PR=0.1498 F1=0.1860\n","[NNConv/F0] Ep017 | ROC=0.7514 PR=0.1508 F1=0.1928\n","[NNConv/F0] Ep018 | ROC=0.7540 PR=0.1529 F1=0.2060\n","[NNConv/F0] Ep019 | ROC=0.7522 PR=0.1535 F1=0.1951\n","[NNConv/F0] Ep020 | ROC=0.7529 PR=0.1540 F1=0.1951\n","[NNConv/F0] Ep021 | ROC=0.7529 PR=0.1540 F1=0.1951\n","âœ… EarlyStopping [NNConv/F0]\n","â­ Fold0 best Î±=1.00 (Val PR-AUC=0.1642 [weighted])\n","âœ… Fold0 [Transformer] ROC=0.7234 PR=0.0667 F1=0.0857\n","âœ… Fold0 [NNConv]      ROC=0.6508 PR=0.0546 F1=0.0886\n","âœ… Fold0 [Ensemble]    ROC=0.7234 PR=0.0667 F1=0.0857 (Î±=1.00)\n","ğŸ” Fold 1: pos-aug enabled | base_pos=1266, neg=4049, pos_rate=0.238 -> target=0.30, per_pos_aug=1, +aug=1266, new_train=6581\n","\n","ğŸ“‚ Fold 1 | train=6581 val=1374 test=632\n","[Transformer/F1] Ep001 | ROC=0.7883 PR=0.4433 F1=0.4448\n","[Transformer/F1] Ep002 | ROC=0.7062 PR=0.3161 F1=0.2767\n","[Transformer/F1] Ep003 | ROC=0.7347 PR=0.3511 F1=0.2708\n","[Transformer/F1] Ep004 | ROC=0.7444 PR=0.3687 F1=0.3361\n","[Transformer/F1] Ep005 | ROC=0.7462 PR=0.3698 F1=0.3459\n","[Transformer/F1] Ep006 | ROC=0.7458 PR=0.3836 F1=0.2989\n","[Transformer/F1] Ep007 | ROC=0.7478 PR=0.3880 F1=0.3750\n","[Transformer/F1] Ep008 | ROC=0.7453 PR=0.3849 F1=0.2557\n","[Transformer/F1] Ep009 | ROC=0.7467 PR=0.3856 F1=0.3488\n","[Transformer/F1] Ep010 | ROC=0.7467 PR=0.3881 F1=0.3514\n","[Transformer/F1] Ep011 | ROC=0.7402 PR=0.3794 F1=0.3425\n","âœ… EarlyStopping [Transformer/F1]\n","[NNConv/F1] Ep001 | ROC=0.6694 PR=0.3690 F1=0.3144\n","[NNConv/F1] Ep002 | ROC=0.7232 PR=0.4067 F1=0.4386\n","[NNConv/F1] Ep003 | ROC=0.6704 PR=0.3797 F1=0.3636\n","[NNConv/F1] Ep004 | ROC=0.6708 PR=0.3815 F1=0.3872\n","[NNConv/F1] Ep005 | ROC=0.6796 PR=0.3780 F1=0.3956\n","[NNConv/F1] Ep006 | ROC=0.7060 PR=0.3990 F1=0.4580\n","[NNConv/F1] Ep007 | ROC=0.7031 PR=0.4055 F1=0.4490\n","[NNConv/F1] Ep008 | ROC=0.6801 PR=0.3959 F1=0.3845\n","[NNConv/F1] Ep009 | ROC=0.6885 PR=0.4052 F1=0.4358\n","[NNConv/F1] Ep010 | ROC=0.6660 PR=0.3948 F1=0.4607\n","[NNConv/F1] Ep011 | ROC=0.6692 PR=0.4071 F1=0.4420\n","[NNConv/F1] Ep012 | ROC=0.6608 PR=0.3981 F1=0.4169\n","âœ… EarlyStopping [NNConv/F1]\n","â­ Fold1 best Î±=1.00 (Val PR-AUC=0.4433 [weighted])\n","âœ… Fold1 [Transformer] ROC=0.6669 PR=0.1061 F1=0.2162\n","âœ… Fold1 [NNConv]      ROC=0.6641 PR=0.0985 F1=0.1800\n","âœ… Fold1 [Ensemble]    ROC=0.6669 PR=0.1061 F1=0.2162 (Î±=1.00)\n","[CID-PRIOR] move to train | from val: 18, from test: 0\n","ğŸ” Fold 2: pos-aug skipped | base_pos=900, neg=2005, pos_rate=0.310\n","\n","ğŸ“‚ Fold 2 | train=2905 val=3042 test=1374\n","[Transformer/F2] Ep001 | ROC=0.5997 PR=0.1675 F1=0.0000\n","[Transformer/F2] Ep002 | ROC=0.6116 PR=0.1711 F1=0.0000\n","[Transformer/F2] Ep003 | ROC=0.6392 PR=0.1825 F1=0.2699\n","[Transformer/F2] Ep004 | ROC=0.6502 PR=0.1890 F1=0.2869\n","[Transformer/F2] Ep005 | ROC=0.6713 PR=0.2007 F1=0.2980\n","[Transformer/F2] Ep006 | ROC=0.6871 PR=0.2226 F1=0.2567\n","[Transformer/F2] Ep007 | ROC=0.7089 PR=0.2521 F1=0.3013\n","[Transformer/F2] Ep008 | ROC=0.7216 PR=0.2644 F1=0.3079\n","[Transformer/F2] Ep009 | ROC=0.7256 PR=0.2683 F1=0.3088\n","[Transformer/F2] Ep010 | ROC=0.7247 PR=0.2664 F1=0.3143\n","[Transformer/F2] Ep011 | ROC=0.7240 PR=0.2604 F1=0.3253\n","[Transformer/F2] Ep012 | ROC=0.7278 PR=0.2670 F1=0.3175\n","[Transformer/F2] Ep013 | ROC=0.7277 PR=0.2736 F1=0.3259\n","[Transformer/F2] Ep014 | ROC=0.7234 PR=0.2651 F1=0.3350\n","[Transformer/F2] Ep015 | ROC=0.7222 PR=0.2640 F1=0.3303\n","[Transformer/F2] Ep016 | ROC=0.7190 PR=0.2594 F1=0.3277\n","[Transformer/F2] Ep017 | ROC=0.7200 PR=0.2604 F1=0.3299\n","[Transformer/F2] Ep018 | ROC=0.7192 PR=0.2604 F1=0.3261\n","[Transformer/F2] Ep019 | ROC=0.7190 PR=0.2602 F1=0.3306\n","[Transformer/F2] Ep020 | ROC=0.7189 PR=0.2600 F1=0.3332\n","[Transformer/F2] Ep021 | ROC=0.7189 PR=0.2599 F1=0.3332\n","[Transformer/F2] Ep022 | ROC=0.7189 PR=0.2599 F1=0.3283\n","âœ… EarlyStopping [Transformer/F2]\n","[NNConv/F2] Ep001 | ROC=0.5594 PR=0.1435 F1=0.2314\n","[NNConv/F2] Ep002 | ROC=0.5359 PR=0.1393 F1=0.0524\n","[NNConv/F2] Ep003 | ROC=0.6321 PR=0.1781 F1=0.2841\n","[NNConv/F2] Ep004 | ROC=0.6961 PR=0.2348 F1=0.2968\n","[NNConv/F2] Ep005 | ROC=0.6995 PR=0.2484 F1=0.3001\n","[NNConv/F2] Ep006 | ROC=0.7281 PR=0.2716 F1=0.2857\n","[NNConv/F2] Ep007 | ROC=0.6751 PR=0.2037 F1=0.3169\n","[NNConv/F2] Ep008 | ROC=0.7191 PR=0.2654 F1=0.3176\n","[NNConv/F2] Ep009 | ROC=0.7257 PR=0.2728 F1=0.2942\n","[NNConv/F2] Ep010 | ROC=0.7436 PR=0.2947 F1=0.3046\n","[NNConv/F2] Ep011 | ROC=0.7472 PR=0.2972 F1=0.3223\n","[NNConv/F2] Ep012 | ROC=0.7530 PR=0.3043 F1=0.3028\n","[NNConv/F2] Ep013 | ROC=0.7485 PR=0.3011 F1=0.3149\n","[NNConv/F2] Ep014 | ROC=0.7505 PR=0.3021 F1=0.3362\n","[NNConv/F2] Ep015 | ROC=0.7566 PR=0.3096 F1=0.3867\n","[NNConv/F2] Ep016 | ROC=0.7569 PR=0.3133 F1=0.3748\n","[NNConv/F2] Ep017 | ROC=0.7582 PR=0.3147 F1=0.3629\n","[NNConv/F2] Ep018 | ROC=0.7585 PR=0.3169 F1=0.3986\n","[NNConv/F2] Ep019 | ROC=0.7589 PR=0.3165 F1=0.3914\n","[NNConv/F2] Ep020 | ROC=0.7593 PR=0.3166 F1=0.3916\n","[NNConv/F2] Ep021 | ROC=0.7593 PR=0.3166 F1=0.3916\n","[NNConv/F2] Ep022 | ROC=0.7598 PR=0.3169 F1=0.3979\n","[NNConv/F2] Ep023 | ROC=0.7596 PR=0.3175 F1=0.3966\n","[NNConv/F2] Ep024 | ROC=0.7603 PR=0.3186 F1=0.3766\n","[NNConv/F2] Ep025 | ROC=0.7612 PR=0.3218 F1=0.3915\n","[NNConv/F2] Ep026 | ROC=0.7573 PR=0.3265 F1=0.4024\n","[NNConv/F2] Ep027 | ROC=0.7686 PR=0.3227 F1=0.3853\n","[NNConv/F2] Ep028 | ROC=0.7645 PR=0.3289 F1=0.3150\n","[NNConv/F2] Ep029 | ROC=0.7589 PR=0.3233 F1=0.3456\n","[NNConv/F2] Ep030 | ROC=0.7613 PR=0.3216 F1=0.3416\n","[NNConv/F2] Ep031 | ROC=0.7223 PR=0.2947 F1=0.3274\n","[NNConv/F2] Ep032 | ROC=0.7327 PR=0.2998 F1=0.2470\n","[NNConv/F2] Ep033 | ROC=0.7041 PR=0.2762 F1=0.2850\n","[NNConv/F2] Ep034 | ROC=0.7069 PR=0.2848 F1=0.2871\n","[NNConv/F2] Ep035 | ROC=0.7123 PR=0.2873 F1=0.3588\n","[NNConv/F2] Ep036 | ROC=0.6577 PR=0.1885 F1=0.2833\n","[NNConv/F2] Ep037 | ROC=0.7070 PR=0.2887 F1=0.3333\n","âœ… EarlyStopping [NNConv/F2]\n","â­ Fold2 best Î±=0.40 (Val PR-AUC=0.3801 [weighted])\n","âœ… Fold2 [Transformer] ROC=0.6304 PR=0.2174 F1=0.1781\n","âœ… Fold2 [NNConv]      ROC=0.6593 PR=0.3073 F1=0.3179\n","âœ… Fold2 [Ensemble]    ROC=0.6745 PR=0.2623 F1=0.2184 (Î±=0.40)\n","[CID-PRIOR] move to train | from val: 12, from test: 18\n","ğŸ” Fold 3: pos-aug enabled | base_pos=300, neg=2021, pos_rate=0.129 -> target=0.30, per_pos_aug=2, +aug=600, new_train=2921\n","\n","ğŸ“‚ Fold 3 | train=2921 val=1958 test=3042\n","[Transformer/F3] Ep001 | ROC=0.5118 PR=0.4472 F1=0.5910\n","[Transformer/F3] Ep002 | ROC=0.5171 PR=0.4612 F1=0.5278\n","[Transformer/F3] Ep003 | ROC=0.4755 PR=0.4236 F1=0.5671\n","[Transformer/F3] Ep004 | ROC=0.5265 PR=0.4816 F1=0.5462\n","[Transformer/F3] Ep005 | ROC=0.4697 PR=0.4151 F1=0.5661\n","[Transformer/F3] Ep006 | ROC=0.5191 PR=0.4578 F1=0.5437\n","[Transformer/F3] Ep007 | ROC=0.4997 PR=0.4451 F1=0.5482\n","[Transformer/F3] Ep008 | ROC=0.4972 PR=0.4390 F1=0.5606\n","[Transformer/F3] Ep009 | ROC=0.4980 PR=0.4405 F1=0.5476\n","[Transformer/F3] Ep010 | ROC=0.5073 PR=0.4546 F1=0.5466\n","[Transformer/F3] Ep011 | ROC=0.4990 PR=0.4398 F1=0.5463\n","[Transformer/F3] Ep012 | ROC=0.4949 PR=0.4412 F1=0.5432\n","[Transformer/F3] Ep013 | ROC=0.4828 PR=0.4222 F1=0.5463\n","[Transformer/F3] Ep014 | ROC=0.5093 PR=0.4545 F1=0.5407\n","âœ… EarlyStopping [Transformer/F3]\n","[NNConv/F3] Ep001 | ROC=0.5154 PR=0.4411 F1=0.5941\n","[NNConv/F3] Ep002 | ROC=0.5501 PR=0.4666 F1=0.5944\n","[NNConv/F3] Ep003 | ROC=0.5895 PR=0.5188 F1=0.5941\n","[NNConv/F3] Ep004 | ROC=0.5604 PR=0.5066 F1=0.5941\n","[NNConv/F3] Ep005 | ROC=0.5223 PR=0.4827 F1=0.5943\n","[NNConv/F3] Ep006 | ROC=0.4927 PR=0.4152 F1=0.5915\n","[NNConv/F3] Ep007 | ROC=0.5456 PR=0.4737 F1=0.5811\n","[NNConv/F3] Ep008 | ROC=0.5309 PR=0.4559 F1=0.5615\n","[NNConv/F3] Ep009 | ROC=0.5445 PR=0.4702 F1=0.5916\n","[NNConv/F3] Ep010 | ROC=0.5219 PR=0.4587 F1=0.5871\n","[NNConv/F3] Ep011 | ROC=0.5285 PR=0.4587 F1=0.5690\n","[NNConv/F3] Ep012 | ROC=0.5411 PR=0.4806 F1=0.5778\n","[NNConv/F3] Ep013 | ROC=0.5554 PR=0.4969 F1=0.5868\n","âœ… EarlyStopping [NNConv/F3]\n","â­ Fold3 best Î±=0.00 (Val PR-AUC=0.5188 [weighted])\n","âœ… Fold3 [Transformer] ROC=0.6776 PR=0.2337 F1=0.2790\n","âœ… Fold3 [NNConv]      ROC=0.6907 PR=0.2072 F1=0.2474\n","âœ… Fold3 [Ensemble]    ROC=0.6907 PR=0.2072 F1=0.2474 (Î±=0.00)\n","[CID-PRIOR] move to train | from val: 0, from test: 12\n","ğŸ” Fold 4: pos-aug enabled | base_pos=684, neg=4394, pos_rate=0.135 -> target=0.30, per_pos_aug=2, +aug=1368, new_train=6446\n","\n","ğŸ“‚ Fold 4 | train=6446 val=285 test=1958\n","[Transformer/F4] Ep001 | ROC=0.7643 PR=0.0797 F1=0.0808\n","[Transformer/F4] Ep002 | ROC=0.7463 PR=0.0746 F1=0.0814\n","[Transformer/F4] Ep003 | ROC=0.7485 PR=0.0755 F1=0.0822\n","[Transformer/F4] Ep004 | ROC=0.7378 PR=0.0710 F1=0.0879\n","[Transformer/F4] Ep005 | ROC=0.7048 PR=0.0628 F1=0.0879\n","[Transformer/F4] Ep006 | ROC=0.6990 PR=0.0615 F1=0.0814\n","[Transformer/F4] Ep007 | ROC=0.6694 PR=0.0564 F1=0.0976\n","[Transformer/F4] Ep008 | ROC=0.6578 PR=0.0548 F1=0.1176\n","[Transformer/F4] Ep009 | ROC=0.6282 PR=0.0507 F1=0.1243\n","[Transformer/F4] Ep010 | ROC=0.6685 PR=0.0566 F1=0.1048\n","[Transformer/F4] Ep011 | ROC=0.6456 PR=0.0531 F1=0.1244\n","âœ… EarlyStopping [Transformer/F4]\n","[NNConv/F4] Ep001 | ROC=0.7827 PR=0.0846 F1=0.0000\n","[NNConv/F4] Ep002 | ROC=0.8022 PR=0.0928 F1=0.1017\n","[NNConv/F4] Ep003 | ROC=0.7741 PR=0.0823 F1=0.2051\n","[NNConv/F4] Ep004 | ROC=0.7283 PR=0.0698 F1=0.0941\n","[NNConv/F4] Ep005 | ROC=0.7439 PR=0.0732 F1=0.1231\n","[NNConv/F4] Ep006 | ROC=0.6557 PR=0.0564 F1=0.1600\n","[NNConv/F4] Ep007 | ROC=0.6566 PR=0.0545 F1=0.1297\n","[NNConv/F4] Ep008 | ROC=0.7799 PR=0.0854 F1=0.1283\n","[NNConv/F4] Ep009 | ROC=0.7408 PR=0.0701 F1=0.2017\n","[NNConv/F4] Ep010 | ROC=0.7622 PR=0.0763 F1=0.1951\n","[NNConv/F4] Ep011 | ROC=0.7430 PR=0.0710 F1=0.0370\n","[NNConv/F4] Ep012 | ROC=0.7433 PR=0.0717 F1=0.1852\n","âœ… EarlyStopping [NNConv/F4]\n","â­ Fold4 best Î±=0.20 (Val PR-AUC=0.0937 [weighted])\n","âœ… Fold4 [Transformer] ROC=0.6324 PR=0.5463 F1=0.5466\n","âœ… Fold4 [NNConv]      ROC=0.6210 PR=0.5369 F1=0.4407\n","âœ… Fold4 [Ensemble]    ROC=0.6291 PR=0.5408 F1=0.4832 (Î±=0.20)\n","\n","ğŸ‰ LCO-CV å®Œäº†ï¼\n","å¹³å‡å€¤: {'Transformer_ROC': 0.6661271710390023, 'Transformer_PR': 0.23404341694476552, 'Transformer_F1': 0.26113201975599576, 'NNConv_ROC': 0.6571696114865639, 'NNConv_PR': 0.24090824277611303, 'NNConv_F1': 0.2549170205922086, 'Ensemble_ROC': 0.6769294727534098, 'Ensemble_PR': 0.23662399408103535, 'Ensemble_F1': 0.2501796217608747}\n","æ¨™æº–åå·®: {'Transformer_ROC': 0.038188498244228354, 'Transformer_PR': 0.18853186272706007, 'Transformer_F1': 0.17427229792808124, 'NNConv_ROC': 0.025113063459784764, 'NNConv_PR': 0.19244660900235866, 'NNConv_F1': 0.13399055044504013, 'Ensemble_ROC': 0.03443835065434089, 'Ensemble_PR': 0.18705734685326916, 'Ensemble_F1': 0.14447976242154884}\n","Î±* [1.0, 1.0, 0.4, 0.0, 0.2]\n","ğŸ“ Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_lco5_trans_nn_ens_posaug_CIDprior/lco_cv_metrics_trans_nn_ensemble_CIDprior.csv\n","â„¹ï¸ æ¤œè¨¼ã§é‡ã¿é©ç”¨: True / ãƒ†ã‚¹ãƒˆã§é‡ã¿é©ç”¨: False\n"]}]},{"cell_type":"code","source":["# ================================================\n","# LCO-CV with Advanced Clustering & Fold Constraints\n","#  - clustering: Butina(Tanimoto) / K-Medoids(Tanimoto) / Murcko Scaffold(+subcluster)\n","#  - fold constraints: minimum positives/negatives per fold (with relaxation)\n","#  - models: TransformerConv & NNConv, PR-AUC-based early stopping\n","#  - ensemble alpha chosen to maximize validation PR-AUC\n","# --- ä»¥ä¸‹ã€åŠ ç­† ---\n","#  - â˜… SampleWeightå¯¾å¿œï¼š\n","#      ãƒ»å­¦ç¿’æå¤±ã¯ã‚µãƒ³ãƒ—ãƒ«é‡ã¿ã§åŠ é‡ï¼ˆBCEWithLogitsLoss(reduction='none') â†’ é‡ã¿ä»˜ãå¹³å‡ï¼‰\n","#      ãƒ»pos_weight ã¯é‡ã¿ä»˜ãå®ŸåŠ¹æ¯”ï¼ˆneg_sum/pos_sumã€ä¸Šé™10ï¼‰ã§ç®—å‡º\n","#      ãƒ»æ¤œè¨¼/ãƒ†ã‚¹ãƒˆã® PR-AUCãƒ»ROCï¼ˆæ•°å€¤ï¼‰ãŠã‚ˆã³ Î±* æœ€é©åŒ–ï¼ˆVal PR-AUCï¼‰ã«ã‚‚é‡ã¿é©ç”¨å¯\n","#      ãƒ»é‡ã¿å±æ€§å€™è£œï¼š[\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]ï¼ˆç„¡ã‘ã‚Œã° 1.0ï¼‰\n","#      ãƒ»ãƒ•ãƒ©ã‚°ï¼šAPPLY_WEIGHT_IN_VALï¼ˆæ¤œè¨¼ã«é‡ã¿ï¼‰ã€APPLY_WEIGHT_IN_TESTï¼ˆãƒ†ã‚¹ãƒˆã«é‡ã¿ï¼‰\n","# ================================================\n","import os, random, math, gc\n","import numpy as np\n","import pandas as pd\n","from collections import defaultdict\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","from torch.serialization import add_safe_globals\n","\n","from sklearn.metrics import roc_auc_score, precision_recall_curve, f1_score, auc\n","\n","# RDKit\n","from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from rdkit.Chem.Scaffolds import MurckoScaffold\n","from rdkit import DataStructs\n","from rdkit.ML.Cluster import Butina\n","\n","# ====== åŸºæœ¬è¨­å®š ======\n","SEED = 42\n","random.seed(SEED); np.random.seed(SEED)\n","torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n","\n","PT_PATH   = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/data_graph_with_smiles.pt\"\n","SAVE_DIR  = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_lco5_trans_nn_ens_posaug_advanced\"\n","os.makedirs(SAVE_DIR, exist_ok=True)\n","DEVICE    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# ---- CV / å­¦ç¿’è¨­å®š ----\n","K                  = 5\n","BATCH_TR           = 64\n","BATCH_TE           = 128\n","LR                 = 3e-4\n","WD                 = 1e-4\n","PATIENCE           = 10\n","MAX_EPOCH          = 200\n","CLIP               = 5.0\n","ALPHAS             = np.linspace(0,1,11)   # 0.0, 0.1, ..., 1.0\n","\n","# ---- ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆé™½æ€§ã®ã¿è¤‡è£½ï¼‰----\n","AUG_TARGET_POS_RATE = 0.30\n","AUG_MAX_PER_POS     = 3\n","\n","# ---- ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°æ–¹å¼ ----\n","# \"butina\" | \"kmedoids\" | \"scaffold\"\n","CLUSTER_METHOD   = \"butina\"\n","BUTINA_THRESH    = 0.7      # tanimoto >= 0.7 ã‚’åŒã‚¯ãƒ©ã‚¹ã‚¿\n","KMEDOIDS_ITERS   = 50\n","SUBCLUSTER_MIN   = 10\n","SUBCLUSTER_K_MAX = 5\n","\n","# ---- Fold å……è¶³åˆ¶ç´„ ----\n","MIN_POS_PER_FOLD = 10\n","MIN_NEG_PER_FOLD = 10\n","FOLD_ASSIGN_TRIALS = 200\n","\n","# â˜… SampleWeight è¨­å®šï¼ˆåŠ ç­†ï¼‰\n","WEIGHT_ATTR_CANDIDATES = [\"sample_weight\",\"weight\",\"w\",\"SampleWeight\",\"Weight\"]\n","APPLY_WEIGHT_IN_VAL  = True   # ValæŒ‡æ¨™ãƒ»Î±*æœ€é©åŒ–ã‚’é‡ã¿ä»˜ãã§\n","APPLY_WEIGHT_IN_TEST = False  # TestæŒ‡æ¨™ã‚’é‡ã¿ä»˜ãã§å‡ºã™å ´åˆã¯ True\n","\n","# ====== ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ï¼ˆé‡ã¿å¯¾å¿œï¼‰ ======\n","def pr_auc_score(y, p, sample_weight=None):\n","    prec, rec, _ = precision_recall_curve(y, p, sample_weight=sample_weight)\n","    return auc(rec, prec)\n","\n","def _get_weight_from_data(d):\n","    for nm in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(d, nm):\n","            v = getattr(d, nm)\n","            return float(v.item()) if torch.is_tensor(v) else float(v)\n","    return 1.0\n","\n","def _to_1d(w):\n","    if torch.is_tensor(w):\n","        if w.dim() == 2 and w.size(1) == 1: return w.view(-1)\n","        return w.view(-1)\n","    return torch.tensor(w, dtype=torch.float32)\n","\n","def get_batch_weights(batch, device=None):\n","    for nm in WEIGHT_ATTR_CANDIDATES:\n","        if hasattr(batch, nm):\n","            w = getattr(batch, nm)\n","            w = _to_1d(w).to(device or batch.y.device).float()\n","            return w, nm\n","    return torch.ones(batch.y.numel(), device=device or batch.y.device, dtype=torch.float32), \"CONST1\"\n","\n","def pos_weight_from(dataset):\n","    ys = torch.tensor([float(d.y.item()) for d in dataset])\n","    ws = torch.tensor([_get_weight_from_data(d) for d in dataset], dtype=torch.float32)\n","    pos_sum = ws[ys == 1].sum()\n","    neg_sum = ws[ys == 0].sum()\n","    w = (neg_sum / torch.clamp(pos_sum, min=1e-8)).item()\n","    return torch.tensor([min(max(w, 1.0), 10.0)], dtype=torch.float32)\n","\n","@torch.no_grad()\n","def eval_probs(model, ds, batch_size=BATCH_TE):\n","    model.eval(); ys, ps, ws = [], [], []\n","    for bt in DataLoader(ds, batch_size=batch_size, shuffle=False):\n","        bt = bt.to(DEVICE)\n","        ys.append(bt.y.detach().cpu())\n","        ps.append(torch.sigmoid(model(bt)).detach().cpu())\n","        w, _ = get_batch_weights(bt, DEVICE)\n","        ws.append(w.detach().cpu())\n","    return torch.cat(ys).numpy(), torch.cat(ps).numpy(), torch.cat(ws).numpy()\n","\n","def infer_dim(t):\n","    if t.dim() == 1: return t.numel()\n","    if t.dim() in (2,3): return t.size(-1)\n","    raise RuntimeError(f\"æœªçŸ¥ã®ãƒ†ãƒ³ã‚½ãƒ«æ¬¡å…ƒ: {t.size()}\")\n","\n","def best_alpha_for_prauc(y_val, p1, p2, alphas=ALPHAS, sample_weight=None):\n","    best_a, best_s = 0.5, -1.0\n","    for a in alphas:\n","        s = pr_auc_score(y_val, a*p1 + (1-a)*p2, sample_weight=sample_weight)\n","        if s > best_s:\n","            best_s, best_a = s, a\n","    return best_a, best_s\n","\n","# ====== ãƒ¢ãƒ‡ãƒ«å®šç¾© ======\n","def build_models_dims(sample):\n","    X_DIM = sample.x.size(-1)\n","    G_DIM = infer_dim(sample.g)\n","    R_DIM = infer_dim(sample.r)\n","    assert hasattr(sample, \"edge_attr\") and sample.edge_attr is not None, \"edge_attr ãŒå¿…è¦ã§ã™ã€‚\"\n","    E_DIM = sample.edge_attr.size(-1)\n","    HID   = 256\n","    return X_DIM, G_DIM, R_DIM, E_DIM, HID\n","\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self, X_DIM, G_DIM, R_DIM, E_DIM, HID=256):\n","        super().__init__()\n","        self.c1 = TransformerConv(X_DIM, HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.c2 = TransformerConv(HID,  HID, heads=4, concat=False, edge_dim=E_DIM, dropout=0.0, beta=False)\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x, g, r], dim=1)).view(-1)\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hidden = max(64, min(256, in_attr_dim * 8))\n","    return nn.Sequential(nn.Linear(in_attr_dim, hidden), nn.ReLU(),\n","                         nn.Linear(hidden, in_channels * out_channels))\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self, X_DIM, G_DIM, R_DIM, E_DIM, HID=256):\n","        super().__init__()\n","        edge_nn1 = make_edge_mlp(E_DIM, HID, X_DIM)\n","        edge_nn2 = make_edge_mlp(E_DIM, HID, HID)\n","        self.c1 = NNConv(X_DIM, HID, edge_nn1, aggr='mean')\n","        self.c2 = NNConv(HID,  HID, edge_nn2, aggr='mean')\n","        self.pool = AttentionalAggregation(gate_nn=nn.Linear(HID, 1))\n","        self.drop = nn.Dropout(0.2)\n","        self.fc = nn.Linear(HID + G_DIM + R_DIM, 1)\n","    def forward(self, d):\n","        x = F.relu(self.c1(d.x, d.edge_index, d.edge_attr))\n","        x = F.relu(self.c2(x, d.edge_index, d.edge_attr))\n","        x = self.pool(self.drop(x), d.batch)\n","        g = d.g.squeeze(1) if d.g.dim() == 3 else d.g\n","        r = d.r.squeeze(1) if d.r.dim() == 3 else d.r\n","        return self.fc(torch.cat([x, g, r], dim=1)).view(-1)\n","\n","def train_one(model, train_set, val_set, save_path, tag):\n","    model.to(DEVICE)\n","    crit = nn.BCEWithLogitsLoss(pos_weight=pos_weight_from(train_set).to(DEVICE),\n","                                reduction='none')  # per-sample\n","    opt  = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=WD)\n","\n","    best_pr, wait = -1.0, 0\n","    for ep in range(1, MAX_EPOCH+1):\n","        model.train()\n","        for bt in DataLoader(train_set, batch_size=BATCH_TR, shuffle=True):\n","            bt = bt.to(DEVICE)\n","            logits  = model(bt)\n","            lossvec = crit(logits, bt.y.float())\n","            sw, _nm = get_batch_weights(bt, DEVICE)\n","            loss = (lossvec * sw).sum() / (sw.sum() + 1e-8)\n","\n","            opt.zero_grad()\n","            loss.backward()\n","            nn.utils.clip_grad_norm_(model.parameters(), CLIP)\n","            opt.step()\n","\n","        yv, pv, wv = eval_probs(model, val_set)\n","        prc = pr_auc_score(yv, pv, sample_weight=wv if APPLY_WEIGHT_IN_VAL else None)\n","        roc = roc_auc_score(yv, pv, sample_weight=wv if APPLY_WEIGHT_IN_VAL else None)\n","        f1  = f1_score(yv, (pv>=0.5).astype(int))  # è¡¨ç¤ºç”¨ã«éåŠ é‡\n","        print(f\"[{tag}] Ep{ep:03d} | PR={prc:.4f} ROC={roc:.4f} F1@0.5={f1:.4f}\")\n","\n","        if prc > best_pr:\n","            best_pr, wait = prc, 0\n","            torch.save(model.state_dict(), save_path)\n","        else:\n","            wait += 1\n","            if wait >= PATIENCE:\n","                print(f\"âœ… EarlyStopping (best Val PR-AUC={best_pr:.4f}) [{tag}]\")\n","                break\n","\n","    model.load_state_dict(torch.load(save_path, map_location=DEVICE))\n","    return model, *eval_probs(model, val_set)\n","\n","# ====== ECFP4 & Tanimoto ======\n","def mol_from_smiles(s):\n","    try:\n","        return Chem.MolFromSmiles(s) if s is not None else None\n","    except:\n","        return None\n","\n","def fp_from_mol(m):\n","    if m is None:\n","        # é•·ã•2048ã®ã‚¼ãƒ­ãƒ™ã‚¯ãƒˆãƒ«ã‚’ä»£ç”¨ï¼ˆé¡ä¼¼åº¦=0ï¼‰\n","        return AllChem.GetMorganFingerprintAsBitVect(Chem.MolFromSmiles(\"\"), 2, nBits=2048)\n","    return AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048)\n","\n","def tanimoto(a, b):\n","    return DataStructs.TanimotoSimilarity(a, b)\n","\n","# ====== ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚° ======\n","def cluster_butina(fps, threshold=0.7):\n","    dists = []\n","    for i in range(1, len(fps)):\n","        sims = DataStructs.BulkTanimotoSimilarity(fps[i], fps[:i])\n","        dists.extend([1.0 - float(s) for s in sims])\n","    cs = Butina.ClusterData(dists, len(fps), 1.0 - float(threshold), isDistData=True)\n","    return [list(c) for c in cs]\n","\n","def kmedoids_tanimoto(fps, k, max_iters=50, seed=SEED):\n","    rng = np.random.RandomState(seed)\n","    n = len(fps)\n","    medoids = rng.choice(n, size=min(k, n), replace=False).tolist()\n","    if len(medoids) < k: k = len(medoids)\n","\n","    def assign(meds):\n","        assigns = np.empty(n, dtype=np.int64)\n","        for i in range(n):\n","            best_j, best_d = 0, 1e9\n","            for j, m in enumerate(meds):\n","                d = 1.0 - tanimoto(fps[i], fps[m])\n","                if d < best_d: best_d, best_j = d, j\n","            assigns[i] = best_j\n","        return assigns\n","\n","    def total_cost(assigns, meds):\n","        return sum(1.0 - tanimoto(fps[i], meds[assigns[i]]) for i in range(n))\n","\n","    assigns = assign(medoids)\n","    best_cost = total_cost(assigns, medoids)\n","    it, improved = 0, True\n","    while improved and it < max_iters:\n","        improved, it = False, it+1\n","        for mi in range(k):\n","            for cand in range(n):\n","                if cand in medoids: continue\n","                new_meds = medoids.copy(); new_meds[mi] = cand\n","                new_assigns = assign(new_meds)\n","                cost = total_cost(new_assigns, new_meds)\n","                if cost + 1e-9 < best_cost:\n","                    medoids, assigns, best_cost = new_meds, new_assigns, cost\n","                    improved = True\n","    clusters = [[] for _ in range(k)]\n","    for idx, a in enumerate(assigns): clusters[a].append(idx)\n","    return [c for c in clusters if len(c) > 0]\n","\n","def scaffold_key(mol):\n","    try:\n","        scaf = MurckoScaffold.GetScaffoldForMol(mol)\n","        return Chem.MolToSmiles(scaf, isomericSmiles=False) if scaf is not None else None\n","    except:\n","        return None\n","\n","def cluster_scaffold_then_subcluster(smiles_list, fps, sub_min=10, sub_kmax=5):\n","    sc_groups = defaultdict(list)\n","    for i, smi in enumerate(smiles_list):\n","        key = scaffold_key(mol_from_smiles(smi))\n","        if key is None: key = f\"_NOSCAF_{i}\"\n","        sc_groups[key].append(i)\n","\n","    clusters = []\n","    for _, idxs in sc_groups.items():\n","        if len(idxs) >= sub_min:\n","            k = max(1, min(sub_kmax, int(math.ceil(len(idxs)/sub_min))))\n","            sub_fps = [fps[i] for i in idxs]\n","            sub_clusters = kmedoids_tanimoto(sub_fps, k=k, max_iters=KMEDOIDS_ITERS, seed=SEED)\n","            for sc in sub_clusters:\n","                clusters.append([idxs[t] for t in sc])\n","        else:\n","            clusters.append(idxs)\n","    return clusters\n","\n","# ====== fold å‰²å½“ï¼ˆåˆ¶ç´„ä»˜ãï¼‰ ======\n","def summarize_cluster_labels(data, clusters):\n","    rows = []\n","    for cid, idxs in enumerate(clusters):\n","        ys = [int(data[i].y) for i in idxs]\n","        rows.append({\"cid\":cid, \"size\":len(idxs), \"pos\":sum(ys), \"neg\":len(ys)-sum(ys)})\n","    return pd.DataFrame(rows)\n","\n","def try_pack_clusters(clusters, labels_df, k=K, min_pos=MIN_POS_PER_FOLD, min_neg=MIN_NEG_PER_FOLD, trials=FOLD_ASSIGN_TRIALS):\n","    sizes = labels_df.set_index(\"cid\")[\"size\"].to_dict()\n","    pos_c = labels_df.set_index(\"cid\")[\"pos\"].to_dict()\n","    neg_c = labels_df.set_index(\"cid\")[\"neg\"].to_dict()\n","    cluster_ids = labels_df.sort_values(\"size\", ascending=False)[\"cid\"].tolist()\n","\n","    best_solution, best_score = None, (1e9, 1e9)  # (violations, size_var)\n","\n","    for _ in range(trials):\n","        folds = [{\"cids\":[], \"pos\":0, \"neg\":0, \"size\":0} for _ in range(k)]\n","        for cid in cluster_ids:\n","            best_fold, best_tuple = None, (1e9, 1e9)\n","            for f in range(k):\n","                p = folds[f][\"pos\"]  + pos_c[cid]\n","                n = folds[f][\"neg\"]  + neg_c[cid]\n","                s = folds[f][\"size\"] + sizes[cid]\n","                viol = int(p < min_pos) + int(n < min_neg)\n","                score = (viol, s)\n","                if score < best_tuple:\n","                    best_tuple, best_fold = score, f\n","            f = best_fold\n","            folds[f][\"cids\"].append(cid)\n","            folds[f][\"pos\"]  += pos_c[cid]\n","            folds[f][\"neg\"]  += neg_c[cid]\n","            folds[f][\"size\"] += sizes[cid]\n","\n","        viol = sum(int(fd[\"pos\"] < min_pos or fd[\"neg\"] < min_neg) for fd in folds)\n","        sz = np.array([fd[\"size\"] for fd in folds], dtype=float)\n","        size_var = float(np.var(sz))\n","        score = (viol, size_var)\n","        if score < best_score:\n","            best_score, best_solution = score, folds\n","            if viol == 0: break\n","    return best_solution, best_score\n","\n","def assign_folds_with_relaxation(data, clusters, k=K, min_pos=MIN_POS_PER_FOLD, min_neg=MIN_NEG_PER_FOLD):\n","    labels_df = summarize_cluster_labels(data, clusters)\n","    folds, score = try_pack_clusters(clusters, labels_df, k=k, min_pos=min_pos, min_neg=min_neg)\n","    viol, size_var = score\n","\n","    relax_steps = 0\n","    mpos, mneg = min_pos, min_neg\n","    while viol > 0 and (mpos > 0 or mneg > 0):\n","        relax_steps += 1\n","        if mpos > 0: mpos -= 1\n","        if mneg > 0: mneg -= 1\n","        folds2, score2 = try_pack_clusters(clusters, labels_df, k=k, min_pos=mpos, min_neg=mneg)\n","        if score2 < score:\n","            folds, score = folds2, score2\n","            viol, size_var = score\n","        if viol == 0: break\n","\n","    node2fold = {}\n","    for f, info in enumerate(folds):\n","        for cid in info[\"cids\"]:\n","            for idx in clusters[cid]:\n","                node2fold[idx] = f\n","\n","    recs = [{\"Fold\": f, \"size\": fd[\"size\"], \"pos\": fd[\"pos\"], \"neg\": fd[\"neg\"]} for f, fd in enumerate(folds)]\n","    fold_summary = pd.DataFrame(recs)\n","    labels_df[\"fold\"] = -1\n","    for f, info in enumerate(folds):\n","        for cid in info[\"cids\"]:\n","            labels_df.loc[labels_df[\"cid\"]==cid, \"fold\"] = f\n","\n","    return node2fold, fold_summary, labels_df, {\n","        \"violations\": int(viol),\n","        \"size_var\": float(size_var),\n","        \"relax_steps\": int(relax_steps),\n","        \"min_pos_final\": int(mpos),\n","        \"min_neg_final\": int(mneg)\n","    }\n","\n","# ====== å®‰å…¨ãƒ­ãƒ¼ãƒ‰ ======\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception as e:\n","        print(f\"[WARN] add_safe_globals å¤±æ•—: {e}\")\n","    try:\n","        obj = torch.load(path)  # PyTorch 2.6: weights_only=True æ—¢å®š\n","    except Exception as e:\n","        print(f\"[WARN] å®‰å…¨ãƒ­ãƒ¼ãƒ‰å¤±æ•—ï¼ˆ{e}ï¼‰ã€‚weights_only=Falseã§å†è©¦è¡Œï¼ˆä¿¡é ¼ãƒ•ã‚¡ã‚¤ãƒ«å‰æï¼‰ã€‚\")\n","        obj = torch.load(path, weights_only=False)\n","\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    try: return list(obj)\n","    except Exception as e:\n","        raise RuntimeError(f\"æœªçŸ¥å½¢å¼: {type(obj)}; liståŒ–å¤±æ•—: {e}\")\n","\n","# ====== ãƒ¡ã‚¤ãƒ³ ======\n","def main():\n","    # 1) ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰\n","    data = load_pyg_list(PT_PATH)\n","    print(f\"âœ… ã‚°ãƒ©ãƒ•æ•°: {len(data)}\")\n","    sample = data[0]\n","    X_DIM, G_DIM, R_DIM, E_DIM, HID = build_models_dims(sample)\n","\n","    # 2) SMILES / mol / fp\n","    smiles = [getattr(d, \"smiles\", None) for d in data]\n","    mols   = [mol_from_smiles(s) for s in smiles]\n","    fps    = [fp_from_mol(m) for m in mols]\n","\n","    # 3) ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°\n","    cm = CLUSTER_METHOD.lower()\n","    if cm == \"butina\":\n","        clusters = cluster_butina(fps, threshold=BUTINA_THRESH)\n","        method_tag = f\"butina_t{BUTINA_THRESH}\"\n","    elif cm == \"kmedoids\":\n","        clusters = kmedoids_tanimoto(fps, k=K, max_iters=KMEDOIDS_ITERS, seed=SEED)\n","        method_tag = f\"kmedoids_k{K}_it{KMEDOIDS_ITERS}\"\n","    elif cm == \"scaffold\":\n","        clusters = cluster_scaffold_then_subcluster(smiles, fps, sub_min=SUBCLUSTER_MIN, sub_kmax=SUBCLUSTER_K_MAX)\n","        method_tag = f\"scaffold_sub{SUBCLUSTER_K_MAX}\"\n","    else:\n","        raise ValueError(\"CLUSTER_METHOD ã¯ 'butina' | 'kmedoids' | 'scaffold'\")\n","\n","    # Kæœªæº€ãªã‚‰ãƒãƒ¼ã‚¸\n","    while len(clusters) < K:\n","        clusters = sorted(clusters, key=len)\n","        a, b = clusters.pop(0), clusters.pop(0)\n","        clusters.append(a + b)\n","    print(f\"ğŸ”§ Clusters={len(clusters)} (method={method_tag})\")\n","\n","    # 4) åˆ¶ç´„ä»˜ã fold å‰²å½“\n","    node2fold, fold_summary, cluster_labels, extra = assign_folds_with_relaxation(\n","        data, clusters, k=K, min_pos=MIN_POS_PER_FOLD, min_neg=MIN_NEG_PER_FOLD\n","    )\n","    print(\"ğŸ“Š Fold summary:\\n\", fold_summary)\n","    print(\"âš ï¸ Constraint:\", extra)\n","\n","    cluster_labels.to_csv(os.path.join(SAVE_DIR, f\"clusters_{method_tag}.csv\"), index=False)\n","    fold_summary.to_csv(os.path.join(SAVE_DIR, f\"fold_summary_{method_tag}.csv\"), index=False)\n","\n","    for i, d in enumerate(data):\n","        d.cluster = int(node2fold[i])\n","\n","    # 5) LCO-CV\n","    rows = []\n","    for fold in range(K):\n","        test_idx = [i for i,d in enumerate(data) if d.cluster==fold]\n","        rest_idx = [i for i,d in enumerate(data) if d.cluster!=fold]\n","\n","        rng = np.random.default_rng(SEED + fold)\n","        rng.shuffle(rest_idx)\n","\n","        n_val = max(1, int(0.1 * len(rest_idx)))\n","        val_idx   = rest_idx[:n_val]\n","        train_idx = rest_idx[n_val:]\n","\n","        test_data  = [data[i] for i in test_idx]\n","        val_data   = [data[i] for i in val_idx]\n","        train_base = [data[i] for i in train_idx]\n","\n","        # ---- é™½æ€§ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆå­¦ç¿’ã®ã¿ï¼‰----\n","        n_train = len(train_base)\n","        pos_cnt = sum(int(d.y) for d in train_base)\n","        neg_cnt = n_train - pos_cnt\n","        pos_rate = pos_cnt / max(1, n_train)\n","        target_pos = math.ceil(AUG_TARGET_POS_RATE * n_train)\n","        need_pos   = max(0, target_pos - pos_cnt)\n","\n","        if pos_cnt > 0 and need_pos > 0:\n","            per_pos_aug = max(1, min(AUG_MAX_PER_POS, math.ceil(need_pos / pos_cnt)))\n","            train_aug = []\n","            for d in train_base:\n","                if int(d.y)==1:\n","                    for _ in range(per_pos_aug):\n","                        dd = d.clone()  # é‡ã¿ã¯ clone ã§å¼•ãç¶™ãŒã‚Œã‚‹æƒ³å®š\n","                        train_aug.append(dd)\n","            train_data = train_base + train_aug\n","            print(f\"ğŸ” Fold {fold}: pos-oversample | base_pos={pos_cnt}, neg={neg_cnt}, \"\n","                  f\"pos_rate={pos_rate:.3f} -> target={AUG_TARGET_POS_RATE:.2f}, \"\n","                  f\"per_pos_aug={per_pos_aug}, +aug={len(train_aug)}, new_train={len(train_data)}\")\n","        else:\n","            train_data = train_base\n","            print(f\"ğŸ” Fold {fold}: oversample skipped | base_pos={pos_cnt}, neg={neg_cnt}, pos_rate={pos_rate:.3f}\")\n","\n","        print(f\"\\nğŸ“‚ Fold {fold} | train={len(train_data)} val={len(val_data)} test={len(test_data)}\")\n","\n","        # ---- ãƒ¢ãƒ‡ãƒ« ----\n","        m_tr = Transformer_DX_DG_DR(X_DIM, G_DIM, R_DIM, E_DIM, HID)\n","        m_nn = NNConv_DX_DG_DR(      X_DIM, G_DIM, R_DIM, E_DIM, HID)\n","        p_tr = os.path.join(SAVE_DIR, f\"{method_tag}_trans_fold{fold}.pt\")\n","        p_nn = os.path.join(SAVE_DIR, f\"{method_tag}_nnconv_fold{fold}.pt\")\n","\n","        # ---- å­¦ç¿’ï¼ˆPR-AUCã§ä¿å­˜ï¼›é‡ã¿å¯¾å¿œï¼‰----\n","        m_tr, yv, pv_tr, wv = train_one(m_tr, train_data, val_data, p_tr, f\"Transformer/F{fold}\")\n","        m_nn, _,  pv_nn, _  = train_one(m_nn, train_data, val_data, p_nn, f\"NNConv/F{fold}\")\n","\n","        # ---- Î±*: Val PR æœ€å¤§ï¼ˆé‡ã¿é©ç”¨å¯ï¼‰----\n","        alpha_star, pr_val = best_alpha_for_prauc(\n","            yv, pv_tr, pv_nn, alphas=ALPHAS, sample_weight=wv if APPLY_WEIGHT_IN_VAL else None\n","        )\n","        print(f\"â­ Fold{fold} best Î±={alpha_star:.2f} (Val PR-AUC={pr_val:.4f}{' [weighted]' if APPLY_WEIGHT_IN_VAL else ''})\")\n","\n","        # ---- ãƒ†ã‚¹ãƒˆï¼ˆé‡ã¿é©ç”¨ã¯ãƒ•ãƒ©ã‚°ã§ï¼‰----\n","        yt, pt_tr, wt = eval_probs(m_tr, test_data)\n","        _,  pt_nn, wt2 = eval_probs(m_nn, test_data)\n","        pt_en = alpha_star * pt_tr + (1 - alpha_star) * pt_nn\n","        sw_use = wt if APPLY_WEIGHT_IN_TEST else None\n","\n","        def pack(prefix, y, p, sw=None):\n","            return {\n","                f\"{prefix}_ROC\": roc_auc_score(y, p, sample_weight=sw) if sw is not None else roc_auc_score(y, p),\n","                f\"{prefix}_PR\":  pr_auc_score(y, p, sample_weight=sw),\n","                f\"{prefix}_F1\":  f1_score(y, (p>=0.5).astype(int)),  # è¡¨ç¤ºç”¨ã«éåŠ é‡\n","            }\n","\n","        rec = {\"Fold\": fold, \"Alpha\": float(alpha_star), \"Method\": CLUSTER_METHOD}\n","        rec.update(pack(\"Transformer\", yt, pt_tr, sw_use))\n","        rec.update(pack(\"NNConv\",      yt, pt_nn, sw_use))\n","        rec.update(pack(\"Ensemble\",    yt, pt_en, sw_use))\n","        rows.append(rec)\n","\n","        print(f\"âœ… Fold{fold} [Transformer] ROC={rec['Transformer_ROC']:.4f} PR={rec['Transformer_PR']:.4f} F1={rec['Transformer_F1']:.4f}\")\n","        print(f\"âœ… Fold{fold} [NNConv]      ROC={rec['NNConv_ROC']:.4f} PR={rec['NNConv_PR']:.4f} F1={rec['NNConv_F1']:.4f}\")\n","        print(f\"âœ… Fold{fold} [Ensemble]    ROC={rec['Ensemble_ROC']:.4f} PR={rec['Ensemble_PR']:.4f} F1={rec['Ensemble_F1']:.4f}\")\n","\n","        del m_tr, m_nn; gc.collect()\n","        if torch.cuda.is_available(): torch.cuda.empty_cache()\n","\n","    # 6) ä¿å­˜ãƒ»é›†è¨ˆ\n","    df = pd.DataFrame(rows)\n","    out_csv = os.path.join(SAVE_DIR, f\"lco_cv_metrics_{method_tag}.csv\")\n","    df.to_csv(out_csv, index=False)\n","\n","    metrics_cols = [c for c in df.columns if c not in [\"Fold\", \"Alpha\", \"Method\"]]\n","    mean_row = df[metrics_cols].mean().to_dict()\n","    std_row  = df[metrics_cols].std().to_dict()\n","    print(\"\\nğŸ‰ LCO-CV å®Œäº†ï¼\")\n","    print(\"å¹³å‡å€¤:\", {k: float(v) for k, v in mean_row.items()})\n","    print(\"æ¨™æº–åå·®:\", {k: float(v) for k, v in std_row.items()})\n","    print(\"Î±*\", df[\"Alpha\"].round(2).tolist())\n","    print(\"ä¿å­˜:\", out_csv)\n","\n","# ====== å®Ÿè¡Œ ======\n","if __name__ == \"__main__\":\n","    from rdkit import RDLogger, Chem as _Chem\n","    import warnings as _warnings\n","    RDLogger.DisableLog('rdApp.*')\n","    _warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4_z-h3_GRtdY","executionInfo":{"status":"ok","timestamp":1760685248902,"user_tz":-540,"elapsed":1563141,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"27b9be6d-ac32-4d83-f5ae-bc78d0566ff1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["âœ… ã‚°ãƒ©ãƒ•æ•°: 7321\n","ğŸ”§ Clusters=4906 (method=butina_t0.7)\n","ğŸ“Š Fold summary:\n","    Fold  size  pos   neg\n","0     0  1465  246  1219\n","1     1  1464  324  1140\n","2     2  1464  318  1146\n","3     3  1464  318  1146\n","4     4  1464  318  1146\n","âš ï¸ Constraint: {'violations': 0, 'size_var': 0.16000000000000006, 'relax_steps': 7, 'min_pos_final': 3, 'min_neg_final': 3}\n","ğŸ” Fold 0: pos-oversample | base_pos=1163, neg=4108, pos_rate=0.221 -> target=0.30, per_pos_aug=1, +aug=1163, new_train=6434\n","\n","ğŸ“‚ Fold 0 | train=6434 val=585 test=1465\n","[Transformer/F0] Ep001 | PR=0.4480 ROC=0.7865 F1@0.5=0.2727\n","[Transformer/F0] Ep002 | PR=0.4465 ROC=0.7883 F1@0.5=0.5232\n","[Transformer/F0] Ep003 | PR=0.4697 ROC=0.8044 F1@0.5=0.5000\n","[Transformer/F0] Ep004 | PR=0.5083 ROC=0.8238 F1@0.5=0.5000\n","[Transformer/F0] Ep005 | PR=0.5203 ROC=0.8230 F1@0.5=0.5263\n","[Transformer/F0] Ep006 | PR=0.5421 ROC=0.8347 F1@0.5=0.5040\n","[Transformer/F0] Ep007 | PR=0.5485 ROC=0.8434 F1@0.5=0.4952\n","[Transformer/F0] Ep008 | PR=0.5523 ROC=0.8497 F1@0.5=0.5225\n","[Transformer/F0] Ep009 | PR=0.5645 ROC=0.8592 F1@0.5=0.5743\n","[Transformer/F0] Ep010 | PR=0.5626 ROC=0.8608 F1@0.5=0.5903\n","[Transformer/F0] Ep011 | PR=0.5695 ROC=0.8672 F1@0.5=0.5470\n","[Transformer/F0] Ep012 | PR=0.6186 ROC=0.8769 F1@0.5=0.5780\n","[Transformer/F0] Ep013 | PR=0.5960 ROC=0.8751 F1@0.5=0.5766\n","[Transformer/F0] Ep014 | PR=0.6387 ROC=0.8894 F1@0.5=0.5778\n","[Transformer/F0] Ep015 | PR=0.6678 ROC=0.8952 F1@0.5=0.6309\n","[Transformer/F0] Ep016 | PR=0.6451 ROC=0.8924 F1@0.5=0.6125\n","[Transformer/F0] Ep017 | PR=0.6578 ROC=0.8854 F1@0.5=0.6168\n","[Transformer/F0] Ep018 | PR=0.6871 ROC=0.8993 F1@0.5=0.6168\n","[Transformer/F0] Ep019 | PR=0.7034 ROC=0.9029 F1@0.5=0.6438\n","[Transformer/F0] Ep020 | PR=0.7107 ROC=0.9098 F1@0.5=0.6667\n","[Transformer/F0] Ep021 | PR=0.6940 ROC=0.9100 F1@0.5=0.6720\n","[Transformer/F0] Ep022 | PR=0.7135 ROC=0.9113 F1@0.5=0.6688\n","[Transformer/F0] Ep023 | PR=0.7376 ROC=0.9157 F1@0.5=0.6777\n","[Transformer/F0] Ep024 | PR=0.7015 ROC=0.9056 F1@0.5=0.5739\n","[Transformer/F0] Ep025 | PR=0.7394 ROC=0.9097 F1@0.5=0.6452\n","[Transformer/F0] Ep026 | PR=0.7504 ROC=0.9175 F1@0.5=0.6645\n","[Transformer/F0] Ep027 | PR=0.7304 ROC=0.9193 F1@0.5=0.6689\n","[Transformer/F0] Ep028 | PR=0.7271 ROC=0.9243 F1@0.5=0.6846\n","[Transformer/F0] Ep029 | PR=0.7344 ROC=0.9182 F1@0.5=0.6779\n","[Transformer/F0] Ep030 | PR=0.7551 ROC=0.9259 F1@0.5=0.6624\n","[Transformer/F0] Ep031 | PR=0.7630 ROC=0.9280 F1@0.5=0.6957\n","[Transformer/F0] Ep032 | PR=0.7451 ROC=0.9272 F1@0.5=0.6752\n","[Transformer/F0] Ep033 | PR=0.7472 ROC=0.9296 F1@0.5=0.6899\n","[Transformer/F0] Ep034 | PR=0.7708 ROC=0.9343 F1@0.5=0.7051\n","[Transformer/F0] Ep035 | PR=0.7498 ROC=0.9331 F1@0.5=0.7279\n","[Transformer/F0] Ep036 | PR=0.7363 ROC=0.9257 F1@0.5=0.6904\n","[Transformer/F0] Ep037 | PR=0.7676 ROC=0.9357 F1@0.5=0.6890\n","[Transformer/F0] Ep038 | PR=0.7733 ROC=0.9370 F1@0.5=0.7192\n","[Transformer/F0] Ep039 | PR=0.7610 ROC=0.9388 F1@0.5=0.6814\n","[Transformer/F0] Ep040 | PR=0.7614 ROC=0.9335 F1@0.5=0.7222\n","[Transformer/F0] Ep041 | PR=0.7525 ROC=0.9318 F1@0.5=0.7226\n","[Transformer/F0] Ep042 | PR=0.7693 ROC=0.9365 F1@0.5=0.7153\n","[Transformer/F0] Ep043 | PR=0.7757 ROC=0.9411 F1@0.5=0.7426\n","[Transformer/F0] Ep044 | PR=0.7500 ROC=0.9258 F1@0.5=0.6386\n","[Transformer/F0] Ep045 | PR=0.7628 ROC=0.9371 F1@0.5=0.7020\n","[Transformer/F0] Ep046 | PR=0.7749 ROC=0.9412 F1@0.5=0.7010\n","[Transformer/F0] Ep047 | PR=0.7692 ROC=0.9401 F1@0.5=0.7239\n","[Transformer/F0] Ep048 | PR=0.7565 ROC=0.9370 F1@0.5=0.6730\n","[Transformer/F0] Ep049 | PR=0.7723 ROC=0.9454 F1@0.5=0.7171\n","[Transformer/F0] Ep050 | PR=0.7694 ROC=0.9425 F1@0.5=0.7039\n","[Transformer/F0] Ep051 | PR=0.7722 ROC=0.9417 F1@0.5=0.7240\n","[Transformer/F0] Ep052 | PR=0.7745 ROC=0.9434 F1@0.5=0.7216\n","[Transformer/F0] Ep053 | PR=0.7890 ROC=0.9452 F1@0.5=0.7429\n","[Transformer/F0] Ep054 | PR=0.7626 ROC=0.9377 F1@0.5=0.7137\n","[Transformer/F0] Ep055 | PR=0.7780 ROC=0.9438 F1@0.5=0.7191\n","[Transformer/F0] Ep056 | PR=0.7474 ROC=0.9363 F1@0.5=0.7254\n","[Transformer/F0] Ep057 | PR=0.7785 ROC=0.9460 F1@0.5=0.7260\n","[Transformer/F0] Ep058 | PR=0.7659 ROC=0.9419 F1@0.5=0.7287\n","[Transformer/F0] Ep059 | PR=0.7813 ROC=0.9449 F1@0.5=0.7361\n","[Transformer/F0] Ep060 | PR=0.7810 ROC=0.9465 F1@0.5=0.7368\n","[Transformer/F0] Ep061 | PR=0.7818 ROC=0.9487 F1@0.5=0.7381\n","[Transformer/F0] Ep062 | PR=0.7787 ROC=0.9461 F1@0.5=0.7519\n","[Transformer/F0] Ep063 | PR=0.7748 ROC=0.9475 F1@0.5=0.7273\n","âœ… EarlyStopping (best Val PR-AUC=0.7890) [Transformer/F0]\n","[NNConv/F0] Ep001 | PR=0.2659 ROC=0.6201 F1@0.5=0.3414\n","[NNConv/F0] Ep002 | PR=0.4490 ROC=0.7868 F1@0.5=0.4329\n","[NNConv/F0] Ep003 | PR=0.4472 ROC=0.7910 F1@0.5=0.4299\n","[NNConv/F0] Ep004 | PR=0.4670 ROC=0.8025 F1@0.5=0.5171\n","[NNConv/F0] Ep005 | PR=0.4704 ROC=0.8046 F1@0.5=0.5119\n","[NNConv/F0] Ep006 | PR=0.4657 ROC=0.8223 F1@0.5=0.4762\n","[NNConv/F0] Ep007 | PR=0.4846 ROC=0.8186 F1@0.5=0.5354\n","[NNConv/F0] Ep008 | PR=0.4801 ROC=0.8163 F1@0.5=0.5442\n","[NNConv/F0] Ep009 | PR=0.5188 ROC=0.8446 F1@0.5=0.5507\n","[NNConv/F0] Ep010 | PR=0.5000 ROC=0.8352 F1@0.5=0.5172\n","[NNConv/F0] Ep011 | PR=0.5018 ROC=0.8388 F1@0.5=0.5266\n","[NNConv/F0] Ep012 | PR=0.4950 ROC=0.8282 F1@0.5=0.5294\n","[NNConv/F0] Ep013 | PR=0.5041 ROC=0.8319 F1@0.5=0.5310\n","[NNConv/F0] Ep014 | PR=0.5173 ROC=0.8400 F1@0.5=0.5276\n","[NNConv/F0] Ep015 | PR=0.5014 ROC=0.8232 F1@0.5=0.5356\n","[NNConv/F0] Ep016 | PR=0.5444 ROC=0.8530 F1@0.5=0.5193\n","[NNConv/F0] Ep017 | PR=0.5482 ROC=0.8558 F1@0.5=0.5425\n","[NNConv/F0] Ep018 | PR=0.5504 ROC=0.8535 F1@0.5=0.5724\n","[NNConv/F0] Ep019 | PR=0.5405 ROC=0.8459 F1@0.5=0.5574\n","[NNConv/F0] Ep020 | PR=0.5642 ROC=0.8611 F1@0.5=0.5750\n","[NNConv/F0] Ep021 | PR=0.5589 ROC=0.8550 F1@0.5=0.5504\n","[NNConv/F0] Ep022 | PR=0.5550 ROC=0.8548 F1@0.5=0.5391\n","[NNConv/F0] Ep023 | PR=0.5713 ROC=0.8686 F1@0.5=0.5571\n","[NNConv/F0] Ep024 | PR=0.5849 ROC=0.8674 F1@0.5=0.5664\n","[NNConv/F0] Ep025 | PR=0.5588 ROC=0.8500 F1@0.5=0.5658\n","[NNConv/F0] Ep026 | PR=0.4900 ROC=0.8158 F1@0.5=0.4759\n","[NNConv/F0] Ep027 | PR=0.5856 ROC=0.8656 F1@0.5=0.6029\n","[NNConv/F0] Ep028 | PR=0.5914 ROC=0.8753 F1@0.5=0.5903\n","[NNConv/F0] Ep029 | PR=0.5643 ROC=0.8669 F1@0.5=0.5657\n","[NNConv/F0] Ep030 | PR=0.5896 ROC=0.8781 F1@0.5=0.6209\n","[NNConv/F0] Ep031 | PR=0.5909 ROC=0.8790 F1@0.5=0.6242\n","[NNConv/F0] Ep032 | PR=0.6068 ROC=0.8801 F1@0.5=0.6061\n","[NNConv/F0] Ep033 | PR=0.5982 ROC=0.8769 F1@0.5=0.5809\n","[NNConv/F0] Ep034 | PR=0.6124 ROC=0.8807 F1@0.5=0.6054\n","[NNConv/F0] Ep035 | PR=0.6023 ROC=0.8778 F1@0.5=0.6054\n","[NNConv/F0] Ep036 | PR=0.6186 ROC=0.8853 F1@0.5=0.6351\n","[NNConv/F0] Ep037 | PR=0.6328 ROC=0.8830 F1@0.5=0.6237\n","[NNConv/F0] Ep038 | PR=0.5946 ROC=0.8757 F1@0.5=0.6058\n","[NNConv/F0] Ep039 | PR=0.5850 ROC=0.8628 F1@0.5=0.5639\n","[NNConv/F0] Ep040 | PR=0.6148 ROC=0.8792 F1@0.5=0.6205\n","[NNConv/F0] Ep041 | PR=0.6159 ROC=0.8806 F1@0.5=0.6221\n","[NNConv/F0] Ep042 | PR=0.6099 ROC=0.8740 F1@0.5=0.5673\n","[NNConv/F0] Ep043 | PR=0.6091 ROC=0.8710 F1@0.5=0.6028\n","[NNConv/F0] Ep044 | PR=0.6435 ROC=0.8886 F1@0.5=0.6276\n","[NNConv/F0] Ep045 | PR=0.6397 ROC=0.8877 F1@0.5=0.6239\n","[NNConv/F0] Ep046 | PR=0.6008 ROC=0.8739 F1@0.5=0.6034\n","[NNConv/F0] Ep047 | PR=0.6456 ROC=0.8865 F1@0.5=0.6104\n","[NNConv/F0] Ep048 | PR=0.6338 ROC=0.8768 F1@0.5=0.6130\n","[NNConv/F0] Ep049 | PR=0.6463 ROC=0.8886 F1@0.5=0.6296\n","[NNConv/F0] Ep050 | PR=0.6507 ROC=0.8888 F1@0.5=0.5866\n","[NNConv/F0] Ep051 | PR=0.6502 ROC=0.8916 F1@0.5=0.6254\n","[NNConv/F0] Ep052 | PR=0.6349 ROC=0.8909 F1@0.5=0.6050\n","[NNConv/F0] Ep053 | PR=0.6375 ROC=0.8878 F1@0.5=0.6202\n","[NNConv/F0] Ep054 | PR=0.6492 ROC=0.8973 F1@0.5=0.6386\n","[NNConv/F0] Ep055 | PR=0.6638 ROC=0.8971 F1@0.5=0.6242\n","[NNConv/F0] Ep056 | PR=0.6719 ROC=0.9019 F1@0.5=0.6326\n","[NNConv/F0] Ep057 | PR=0.6796 ROC=0.9034 F1@0.5=0.6472\n","[NNConv/F0] Ep058 | PR=0.6850 ROC=0.9082 F1@0.5=0.6735\n","[NNConv/F0] Ep059 | PR=0.6592 ROC=0.9053 F1@0.5=0.6028\n","[NNConv/F0] Ep060 | PR=0.6916 ROC=0.9100 F1@0.5=0.6824\n","[NNConv/F0] Ep061 | PR=0.6619 ROC=0.9024 F1@0.5=0.6402\n","[NNConv/F0] Ep062 | PR=0.6628 ROC=0.9033 F1@0.5=0.5699\n","[NNConv/F0] Ep063 | PR=0.6941 ROC=0.9098 F1@0.5=0.6537\n","[NNConv/F0] Ep064 | PR=0.6948 ROC=0.9136 F1@0.5=0.6398\n","[NNConv/F0] Ep065 | PR=0.6955 ROC=0.9087 F1@0.5=0.6533\n","[NNConv/F0] Ep066 | PR=0.6641 ROC=0.9038 F1@0.5=0.6418\n","[NNConv/F0] Ep067 | PR=0.6788 ROC=0.9076 F1@0.5=0.6535\n","[NNConv/F0] Ep068 | PR=0.6863 ROC=0.9067 F1@0.5=0.6532\n","[NNConv/F0] Ep069 | PR=0.7051 ROC=0.9169 F1@0.5=0.6645\n","[NNConv/F0] Ep070 | PR=0.7098 ROC=0.9190 F1@0.5=0.6783\n","[NNConv/F0] Ep071 | PR=0.6688 ROC=0.9040 F1@0.5=0.6518\n","[NNConv/F0] Ep072 | PR=0.7159 ROC=0.9200 F1@0.5=0.6806\n","[NNConv/F0] Ep073 | PR=0.7174 ROC=0.9229 F1@0.5=0.6605\n","[NNConv/F0] Ep074 | PR=0.7100 ROC=0.9161 F1@0.5=0.6565\n","[NNConv/F0] Ep075 | PR=0.7142 ROC=0.9226 F1@0.5=0.6689\n","[NNConv/F0] Ep076 | PR=0.7144 ROC=0.9263 F1@0.5=0.6939\n","[NNConv/F0] Ep077 | PR=0.7321 ROC=0.9242 F1@0.5=0.7042\n","[NNConv/F0] Ep078 | PR=0.7270 ROC=0.9217 F1@0.5=0.6688\n","[NNConv/F0] Ep079 | PR=0.7264 ROC=0.9314 F1@0.5=0.6606\n","[NNConv/F0] Ep080 | PR=0.7119 ROC=0.9201 F1@0.5=0.6923\n","[NNConv/F0] Ep081 | PR=0.7240 ROC=0.9255 F1@0.5=0.6801\n","[NNConv/F0] Ep082 | PR=0.6917 ROC=0.9175 F1@0.5=0.6601\n","[NNConv/F0] Ep083 | PR=0.6918 ROC=0.9185 F1@0.5=0.6781\n","[NNConv/F0] Ep084 | PR=0.7279 ROC=0.9293 F1@0.5=0.6954\n","[NNConv/F0] Ep085 | PR=0.7312 ROC=0.9246 F1@0.5=0.6770\n","[NNConv/F0] Ep086 | PR=0.7318 ROC=0.9309 F1@0.5=0.7153\n","[NNConv/F0] Ep087 | PR=0.7339 ROC=0.9305 F1@0.5=0.7114\n","[NNConv/F0] Ep088 | PR=0.7585 ROC=0.9318 F1@0.5=0.7010\n","[NNConv/F0] Ep089 | PR=0.7668 ROC=0.9350 F1@0.5=0.7083\n","[NNConv/F0] Ep090 | PR=0.7330 ROC=0.9302 F1@0.5=0.7055\n","[NNConv/F0] Ep091 | PR=0.7626 ROC=0.9341 F1@0.5=0.7046\n","[NNConv/F0] Ep092 | PR=0.7386 ROC=0.9302 F1@0.5=0.6687\n","[NNConv/F0] Ep093 | PR=0.7414 ROC=0.9301 F1@0.5=0.6933\n","[NNConv/F0] Ep094 | PR=0.7399 ROC=0.9340 F1@0.5=0.7313\n","[NNConv/F0] Ep095 | PR=0.7870 ROC=0.9430 F1@0.5=0.7083\n","[NNConv/F0] Ep096 | PR=0.7462 ROC=0.9334 F1@0.5=0.7132\n","[NNConv/F0] Ep097 | PR=0.7724 ROC=0.9422 F1@0.5=0.7043\n","[NNConv/F0] Ep098 | PR=0.7848 ROC=0.9451 F1@0.5=0.7547\n","[NNConv/F0] Ep099 | PR=0.7609 ROC=0.9375 F1@0.5=0.7287\n","[NNConv/F0] Ep100 | PR=0.8062 ROC=0.9484 F1@0.5=0.7192\n","[NNConv/F0] Ep101 | PR=0.7981 ROC=0.9480 F1@0.5=0.7331\n","[NNConv/F0] Ep102 | PR=0.7965 ROC=0.9493 F1@0.5=0.6921\n","[NNConv/F0] Ep103 | PR=0.7963 ROC=0.9457 F1@0.5=0.7220\n","[NNConv/F0] Ep104 | PR=0.8022 ROC=0.9485 F1@0.5=0.7051\n","[NNConv/F0] Ep105 | PR=0.7992 ROC=0.9472 F1@0.5=0.7317\n","[NNConv/F0] Ep106 | PR=0.8031 ROC=0.9455 F1@0.5=0.7185\n","[NNConv/F0] Ep107 | PR=0.7767 ROC=0.9405 F1@0.5=0.7239\n","[NNConv/F0] Ep108 | PR=0.7963 ROC=0.9503 F1@0.5=0.7415\n","[NNConv/F0] Ep109 | PR=0.7868 ROC=0.9442 F1@0.5=0.7097\n","[NNConv/F0] Ep110 | PR=0.8114 ROC=0.9502 F1@0.5=0.7317\n","[NNConv/F0] Ep111 | PR=0.7979 ROC=0.9466 F1@0.5=0.7205\n","[NNConv/F0] Ep112 | PR=0.8117 ROC=0.9519 F1@0.5=0.7361\n","[NNConv/F0] Ep113 | PR=0.8210 ROC=0.9500 F1@0.5=0.7440\n","[NNConv/F0] Ep114 | PR=0.7942 ROC=0.9487 F1@0.5=0.7354\n","[NNConv/F0] Ep115 | PR=0.8101 ROC=0.9536 F1@0.5=0.7243\n","[NNConv/F0] Ep116 | PR=0.7903 ROC=0.9410 F1@0.5=0.7010\n","[NNConv/F0] Ep117 | PR=0.8355 ROC=0.9573 F1@0.5=0.7267\n","[NNConv/F0] Ep118 | PR=0.7925 ROC=0.9438 F1@0.5=0.7398\n","[NNConv/F0] Ep119 | PR=0.8199 ROC=0.9562 F1@0.5=0.7584\n","[NNConv/F0] Ep120 | PR=0.8341 ROC=0.9552 F1@0.5=0.7509\n","[NNConv/F0] Ep121 | PR=0.8275 ROC=0.9551 F1@0.5=0.7619\n","[NNConv/F0] Ep122 | PR=0.8134 ROC=0.9506 F1@0.5=0.7195\n","[NNConv/F0] Ep123 | PR=0.8298 ROC=0.9583 F1@0.5=0.7596\n","[NNConv/F0] Ep124 | PR=0.8103 ROC=0.9532 F1@0.5=0.7266\n","[NNConv/F0] Ep125 | PR=0.8243 ROC=0.9576 F1@0.5=0.7594\n","[NNConv/F0] Ep126 | PR=0.8408 ROC=0.9619 F1@0.5=0.7351\n","[NNConv/F0] Ep127 | PR=0.8315 ROC=0.9575 F1@0.5=0.7554\n","[NNConv/F0] Ep128 | PR=0.8147 ROC=0.9511 F1@0.5=0.7205\n","[NNConv/F0] Ep129 | PR=0.8553 ROC=0.9622 F1@0.5=0.7609\n","[NNConv/F0] Ep130 | PR=0.8386 ROC=0.9588 F1@0.5=0.7692\n","[NNConv/F0] Ep131 | PR=0.8427 ROC=0.9578 F1@0.5=0.7601\n","[NNConv/F0] Ep132 | PR=0.8467 ROC=0.9592 F1@0.5=0.7171\n","[NNConv/F0] Ep133 | PR=0.8460 ROC=0.9612 F1@0.5=0.7782\n","[NNConv/F0] Ep134 | PR=0.8424 ROC=0.9613 F1@0.5=0.7432\n","[NNConv/F0] Ep135 | PR=0.8352 ROC=0.9542 F1@0.5=0.7687\n","[NNConv/F0] Ep136 | PR=0.8233 ROC=0.9574 F1@0.5=0.7744\n","[NNConv/F0] Ep137 | PR=0.8573 ROC=0.9614 F1@0.5=0.7586\n","[NNConv/F0] Ep138 | PR=0.8272 ROC=0.9514 F1@0.5=0.7254\n","[NNConv/F0] Ep139 | PR=0.8529 ROC=0.9616 F1@0.5=0.7810\n","[NNConv/F0] Ep140 | PR=0.8271 ROC=0.9581 F1@0.5=0.7656\n","[NNConv/F0] Ep141 | PR=0.8323 ROC=0.9571 F1@0.5=0.7816\n","[NNConv/F0] Ep142 | PR=0.8324 ROC=0.9563 F1@0.5=0.7491\n","[NNConv/F0] Ep143 | PR=0.8522 ROC=0.9603 F1@0.5=0.7171\n","[NNConv/F0] Ep144 | PR=0.8705 ROC=0.9649 F1@0.5=0.7747\n","[NNConv/F0] Ep145 | PR=0.8579 ROC=0.9608 F1@0.5=0.7869\n","[NNConv/F0] Ep146 | PR=0.8387 ROC=0.9580 F1@0.5=0.7564\n","[NNConv/F0] Ep147 | PR=0.8506 ROC=0.9626 F1@0.5=0.7687\n","[NNConv/F0] Ep148 | PR=0.8379 ROC=0.9631 F1@0.5=0.7742\n","[NNConv/F0] Ep149 | PR=0.8582 ROC=0.9631 F1@0.5=0.7749\n","[NNConv/F0] Ep150 | PR=0.8492 ROC=0.9620 F1@0.5=0.7926\n","[NNConv/F0] Ep151 | PR=0.8540 ROC=0.9596 F1@0.5=0.7509\n","[NNConv/F0] Ep152 | PR=0.8547 ROC=0.9623 F1@0.5=0.8078\n","[NNConv/F0] Ep153 | PR=0.8553 ROC=0.9634 F1@0.5=0.8110\n","[NNConv/F0] Ep154 | PR=0.8606 ROC=0.9666 F1@0.5=0.8163\n","âœ… EarlyStopping (best Val PR-AUC=0.8705) [NNConv/F0]\n","â­ Fold0 best Î±=0.40 (Val PR-AUC=0.8858 [weighted])\n","âœ… Fold0 [Transformer] ROC=0.8571 PR=0.5436 F1=0.5364\n","âœ… Fold0 [NNConv]      ROC=0.7909 PR=0.5742 F1=0.5305\n","âœ… Fold0 [Ensemble]    ROC=0.8834 PR=0.6039 F1=0.5878\n","ğŸ” Fold 1: pos-oversample | base_pos=1088, neg=4184, pos_rate=0.206 -> target=0.30, per_pos_aug=1, +aug=1088, new_train=6360\n","\n","ğŸ“‚ Fold 1 | train=6360 val=585 test=1464\n","[Transformer/F1] Ep001 | PR=0.3182 ROC=0.6957 F1@0.5=0.2077\n","[Transformer/F1] Ep002 | PR=0.4476 ROC=0.7886 F1@0.5=0.4072\n","[Transformer/F1] Ep003 | PR=0.5219 ROC=0.8148 F1@0.5=0.5014\n","[Transformer/F1] Ep004 | PR=0.5203 ROC=0.8248 F1@0.5=0.4671\n","[Transformer/F1] Ep005 | PR=0.5375 ROC=0.8369 F1@0.5=0.4473\n","[Transformer/F1] Ep006 | PR=0.5503 ROC=0.8402 F1@0.5=0.5187\n","[Transformer/F1] Ep007 | PR=0.5548 ROC=0.8503 F1@0.5=0.5531\n","[Transformer/F1] Ep008 | PR=0.5602 ROC=0.8547 F1@0.5=0.4833\n","[Transformer/F1] Ep009 | PR=0.5874 ROC=0.8677 F1@0.5=0.5395\n","[Transformer/F1] Ep010 | PR=0.5757 ROC=0.8646 F1@0.5=0.5503\n","[Transformer/F1] Ep011 | PR=0.5913 ROC=0.8750 F1@0.5=0.5277\n","[Transformer/F1] Ep012 | PR=0.6091 ROC=0.8790 F1@0.5=0.5857\n","[Transformer/F1] Ep013 | PR=0.6167 ROC=0.8786 F1@0.5=0.5697\n","[Transformer/F1] Ep014 | PR=0.6161 ROC=0.8864 F1@0.5=0.5445\n","[Transformer/F1] Ep015 | PR=0.6194 ROC=0.8864 F1@0.5=0.5965\n","[Transformer/F1] Ep016 | PR=0.6429 ROC=0.8958 F1@0.5=0.5676\n","[Transformer/F1] Ep017 | PR=0.6535 ROC=0.9032 F1@0.5=0.5879\n","[Transformer/F1] Ep018 | PR=0.6426 ROC=0.8986 F1@0.5=0.5651\n","[Transformer/F1] Ep019 | PR=0.6330 ROC=0.9030 F1@0.5=0.5913\n","[Transformer/F1] Ep020 | PR=0.6687 ROC=0.9027 F1@0.5=0.6077\n","[Transformer/F1] Ep021 | PR=0.6778 ROC=0.9091 F1@0.5=0.6226\n","[Transformer/F1] Ep022 | PR=0.6731 ROC=0.9095 F1@0.5=0.6235\n","[Transformer/F1] Ep023 | PR=0.6675 ROC=0.9159 F1@0.5=0.6621\n","[Transformer/F1] Ep024 | PR=0.6846 ROC=0.9174 F1@0.5=0.6667\n","[Transformer/F1] Ep025 | PR=0.6848 ROC=0.9173 F1@0.5=0.6667\n","[Transformer/F1] Ep026 | PR=0.6887 ROC=0.9163 F1@0.5=0.6332\n","[Transformer/F1] Ep027 | PR=0.6963 ROC=0.9189 F1@0.5=0.6619\n","[Transformer/F1] Ep028 | PR=0.6794 ROC=0.9215 F1@0.5=0.6231\n","[Transformer/F1] Ep029 | PR=0.6832 ROC=0.9249 F1@0.5=0.6844\n","[Transformer/F1] Ep030 | PR=0.7074 ROC=0.9248 F1@0.5=0.7025\n","[Transformer/F1] Ep031 | PR=0.7062 ROC=0.9234 F1@0.5=0.6643\n","[Transformer/F1] Ep032 | PR=0.6928 ROC=0.9259 F1@0.5=0.6742\n","[Transformer/F1] Ep033 | PR=0.7034 ROC=0.9294 F1@0.5=0.6167\n","[Transformer/F1] Ep034 | PR=0.7273 ROC=0.9321 F1@0.5=0.6623\n","[Transformer/F1] Ep035 | PR=0.7234 ROC=0.9371 F1@0.5=0.6331\n","[Transformer/F1] Ep036 | PR=0.7373 ROC=0.9372 F1@0.5=0.7132\n","[Transformer/F1] Ep037 | PR=0.7559 ROC=0.9338 F1@0.5=0.7004\n","[Transformer/F1] Ep038 | PR=0.7344 ROC=0.9322 F1@0.5=0.6623\n","[Transformer/F1] Ep039 | PR=0.7834 ROC=0.9337 F1@0.5=0.6759\n","[Transformer/F1] Ep040 | PR=0.7324 ROC=0.9380 F1@0.5=0.7079\n","[Transformer/F1] Ep041 | PR=0.7274 ROC=0.9363 F1@0.5=0.6689\n","[Transformer/F1] Ep042 | PR=0.7607 ROC=0.9425 F1@0.5=0.7292\n","[Transformer/F1] Ep043 | PR=0.7583 ROC=0.9436 F1@0.5=0.7023\n","[Transformer/F1] Ep044 | PR=0.7388 ROC=0.9417 F1@0.5=0.6523\n","[Transformer/F1] Ep045 | PR=0.7843 ROC=0.9452 F1@0.5=0.7153\n","[Transformer/F1] Ep046 | PR=0.8149 ROC=0.9457 F1@0.5=0.6820\n","[Transformer/F1] Ep047 | PR=0.8149 ROC=0.9412 F1@0.5=0.6990\n","[Transformer/F1] Ep048 | PR=0.7609 ROC=0.9488 F1@0.5=0.7418\n","[Transformer/F1] Ep049 | PR=0.7943 ROC=0.9472 F1@0.5=0.7071\n","[Transformer/F1] Ep050 | PR=0.7562 ROC=0.9420 F1@0.5=0.7168\n","[Transformer/F1] Ep051 | PR=0.7802 ROC=0.9457 F1@0.5=0.7071\n","[Transformer/F1] Ep052 | PR=0.7819 ROC=0.9406 F1@0.5=0.7117\n","[Transformer/F1] Ep053 | PR=0.8241 ROC=0.9449 F1@0.5=0.7075\n","[Transformer/F1] Ep054 | PR=0.7868 ROC=0.9422 F1@0.5=0.7153\n","[Transformer/F1] Ep055 | PR=0.8185 ROC=0.9491 F1@0.5=0.7154\n","[Transformer/F1] Ep056 | PR=0.8391 ROC=0.9545 F1@0.5=0.7379\n","[Transformer/F1] Ep057 | PR=0.7782 ROC=0.9521 F1@0.5=0.7157\n","[Transformer/F1] Ep058 | PR=0.8177 ROC=0.9496 F1@0.5=0.7384\n","[Transformer/F1] Ep059 | PR=0.8209 ROC=0.9529 F1@0.5=0.7222\n","[Transformer/F1] Ep060 | PR=0.7937 ROC=0.9488 F1@0.5=0.7299\n","[Transformer/F1] Ep061 | PR=0.8454 ROC=0.9546 F1@0.5=0.7286\n","[Transformer/F1] Ep062 | PR=0.8225 ROC=0.9547 F1@0.5=0.7260\n","[Transformer/F1] Ep063 | PR=0.8152 ROC=0.9584 F1@0.5=0.7310\n","[Transformer/F1] Ep064 | PR=0.8084 ROC=0.9562 F1@0.5=0.7266\n","[Transformer/F1] Ep065 | PR=0.8065 ROC=0.9565 F1@0.5=0.7692\n","[Transformer/F1] Ep066 | PR=0.8442 ROC=0.9580 F1@0.5=0.7413\n","[Transformer/F1] Ep067 | PR=0.8667 ROC=0.9596 F1@0.5=0.7546\n","[Transformer/F1] Ep068 | PR=0.8457 ROC=0.9538 F1@0.5=0.7481\n","[Transformer/F1] Ep069 | PR=0.8309 ROC=0.9611 F1@0.5=0.7354\n","[Transformer/F1] Ep070 | PR=0.8402 ROC=0.9559 F1@0.5=0.7647\n","[Transformer/F1] Ep071 | PR=0.8230 ROC=0.9583 F1@0.5=0.7292\n","[Transformer/F1] Ep072 | PR=0.7935 ROC=0.9479 F1@0.5=0.7273\n","[Transformer/F1] Ep073 | PR=0.8089 ROC=0.9565 F1@0.5=0.7322\n","[Transformer/F1] Ep074 | PR=0.8146 ROC=0.9563 F1@0.5=0.7482\n","[Transformer/F1] Ep075 | PR=0.8310 ROC=0.9599 F1@0.5=0.7579\n","[Transformer/F1] Ep076 | PR=0.8043 ROC=0.9553 F1@0.5=0.7500\n","[Transformer/F1] Ep077 | PR=0.8419 ROC=0.9553 F1@0.5=0.7581\n","âœ… EarlyStopping (best Val PR-AUC=0.8667) [Transformer/F1]\n","[NNConv/F1] Ep001 | PR=0.4180 ROC=0.7267 F1@0.5=0.4479\n","[NNConv/F1] Ep002 | PR=0.4002 ROC=0.7374 F1@0.5=0.4494\n","[NNConv/F1] Ep003 | PR=0.3057 ROC=0.6772 F1@0.5=0.0763\n","[NNConv/F1] Ep004 | PR=0.4454 ROC=0.7853 F1@0.5=0.0472\n","[NNConv/F1] Ep005 | PR=0.3917 ROC=0.7669 F1@0.5=0.0752\n","[NNConv/F1] Ep006 | PR=0.4767 ROC=0.8158 F1@0.5=0.2297\n","[NNConv/F1] Ep007 | PR=0.4323 ROC=0.7894 F1@0.5=0.0000\n","[NNConv/F1] Ep008 | PR=0.4808 ROC=0.8167 F1@0.5=0.0640\n","[NNConv/F1] Ep009 | PR=0.4784 ROC=0.8203 F1@0.5=0.2119\n","[NNConv/F1] Ep010 | PR=0.4896 ROC=0.8323 F1@0.5=0.2911\n","[NNConv/F1] Ep011 | PR=0.4828 ROC=0.8313 F1@0.5=0.1606\n","[NNConv/F1] Ep012 | PR=0.4973 ROC=0.8382 F1@0.5=0.4434\n","[NNConv/F1] Ep013 | PR=0.4757 ROC=0.8260 F1@0.5=0.1324\n","[NNConv/F1] Ep014 | PR=0.4786 ROC=0.8259 F1@0.5=0.0640\n","[NNConv/F1] Ep015 | PR=0.5429 ROC=0.8486 F1@0.5=0.5192\n","[NNConv/F1] Ep016 | PR=0.5549 ROC=0.8509 F1@0.5=0.5166\n","[NNConv/F1] Ep017 | PR=0.5652 ROC=0.8531 F1@0.5=0.5282\n","[NNConv/F1] Ep018 | PR=0.5687 ROC=0.8698 F1@0.5=0.5615\n","[NNConv/F1] Ep019 | PR=0.5385 ROC=0.8582 F1@0.5=0.5761\n","[NNConv/F1] Ep020 | PR=0.5402 ROC=0.8583 F1@0.5=0.5294\n","[NNConv/F1] Ep021 | PR=0.5491 ROC=0.8583 F1@0.5=0.5351\n","[NNConv/F1] Ep022 | PR=0.5492 ROC=0.8603 F1@0.5=0.5758\n","[NNConv/F1] Ep023 | PR=0.5516 ROC=0.8641 F1@0.5=0.5507\n","[NNConv/F1] Ep024 | PR=0.5674 ROC=0.8665 F1@0.5=0.5387\n","[NNConv/F1] Ep025 | PR=0.5634 ROC=0.8660 F1@0.5=0.5510\n","[NNConv/F1] Ep026 | PR=0.5685 ROC=0.8619 F1@0.5=0.5697\n","[NNConv/F1] Ep027 | PR=0.5785 ROC=0.8675 F1@0.5=0.5211\n","[NNConv/F1] Ep028 | PR=0.5854 ROC=0.8670 F1@0.5=0.5641\n","[NNConv/F1] Ep029 | PR=0.5784 ROC=0.8690 F1@0.5=0.5519\n","[NNConv/F1] Ep030 | PR=0.5906 ROC=0.8774 F1@0.5=0.5753\n","[NNConv/F1] Ep031 | PR=0.5923 ROC=0.8761 F1@0.5=0.5933\n","[NNConv/F1] Ep032 | PR=0.5687 ROC=0.8624 F1@0.5=0.5595\n","[NNConv/F1] Ep033 | PR=0.5820 ROC=0.8764 F1@0.5=0.5625\n","[NNConv/F1] Ep034 | PR=0.6041 ROC=0.8825 F1@0.5=0.5759\n","[NNConv/F1] Ep035 | PR=0.6135 ROC=0.8784 F1@0.5=0.5522\n","[NNConv/F1] Ep036 | PR=0.6104 ROC=0.8790 F1@0.5=0.5666\n","[NNConv/F1] Ep037 | PR=0.6092 ROC=0.8799 F1@0.5=0.5627\n","[NNConv/F1] Ep038 | PR=0.6338 ROC=0.8875 F1@0.5=0.5654\n","[NNConv/F1] Ep039 | PR=0.6295 ROC=0.8885 F1@0.5=0.5627\n","[NNConv/F1] Ep040 | PR=0.6303 ROC=0.8862 F1@0.5=0.5772\n","[NNConv/F1] Ep041 | PR=0.6601 ROC=0.8916 F1@0.5=0.5863\n","[NNConv/F1] Ep042 | PR=0.6215 ROC=0.8862 F1@0.5=0.5758\n","[NNConv/F1] Ep043 | PR=0.6479 ROC=0.8921 F1@0.5=0.5688\n","[NNConv/F1] Ep044 | PR=0.6497 ROC=0.8912 F1@0.5=0.5615\n","[NNConv/F1] Ep045 | PR=0.6729 ROC=0.8914 F1@0.5=0.5476\n","[NNConv/F1] Ep046 | PR=0.6466 ROC=0.8928 F1@0.5=0.6148\n","[NNConv/F1] Ep047 | PR=0.6907 ROC=0.8982 F1@0.5=0.5791\n","[NNConv/F1] Ep048 | PR=0.6774 ROC=0.9011 F1@0.5=0.6008\n","[NNConv/F1] Ep049 | PR=0.7093 ROC=0.8983 F1@0.5=0.5754\n","[NNConv/F1] Ep050 | PR=0.6826 ROC=0.8987 F1@0.5=0.5993\n","[NNConv/F1] Ep051 | PR=0.6791 ROC=0.8944 F1@0.5=0.5696\n","[NNConv/F1] Ep052 | PR=0.7055 ROC=0.9021 F1@0.5=0.6039\n","[NNConv/F1] Ep053 | PR=0.6943 ROC=0.9009 F1@0.5=0.5795\n","[NNConv/F1] Ep054 | PR=0.6863 ROC=0.9007 F1@0.5=0.6250\n","[NNConv/F1] Ep055 | PR=0.6953 ROC=0.8993 F1@0.5=0.5690\n","[NNConv/F1] Ep056 | PR=0.6904 ROC=0.8950 F1@0.5=0.5641\n","[NNConv/F1] Ep057 | PR=0.7088 ROC=0.9022 F1@0.5=0.5786\n","[NNConv/F1] Ep058 | PR=0.7023 ROC=0.8996 F1@0.5=0.5847\n","[NNConv/F1] Ep059 | PR=0.7288 ROC=0.9042 F1@0.5=0.5706\n","[NNConv/F1] Ep060 | PR=0.7059 ROC=0.8980 F1@0.5=0.5874\n","[NNConv/F1] Ep061 | PR=0.7383 ROC=0.9092 F1@0.5=0.5859\n","[NNConv/F1] Ep062 | PR=0.7239 ROC=0.9014 F1@0.5=0.6083\n","[NNConv/F1] Ep063 | PR=0.7185 ROC=0.9037 F1@0.5=0.6109\n","[NNConv/F1] Ep064 | PR=0.7411 ROC=0.9111 F1@0.5=0.6021\n","[NNConv/F1] Ep065 | PR=0.7406 ROC=0.9098 F1@0.5=0.6090\n","[NNConv/F1] Ep066 | PR=0.7394 ROC=0.9055 F1@0.5=0.5944\n","[NNConv/F1] Ep067 | PR=0.7360 ROC=0.9096 F1@0.5=0.6084\n","[NNConv/F1] Ep068 | PR=0.6894 ROC=0.8879 F1@0.5=0.5672\n","[NNConv/F1] Ep069 | PR=0.7214 ROC=0.9098 F1@0.5=0.6113\n","[NNConv/F1] Ep070 | PR=0.7222 ROC=0.9084 F1@0.5=0.5831\n","[NNConv/F1] Ep071 | PR=0.7596 ROC=0.9112 F1@0.5=0.6111\n","[NNConv/F1] Ep072 | PR=0.7145 ROC=0.9075 F1@0.5=0.5938\n","[NNConv/F1] Ep073 | PR=0.7408 ROC=0.9124 F1@0.5=0.6132\n","[NNConv/F1] Ep074 | PR=0.7432 ROC=0.9031 F1@0.5=0.6222\n","[NNConv/F1] Ep075 | PR=0.7569 ROC=0.9183 F1@0.5=0.6234\n","[NNConv/F1] Ep076 | PR=0.7304 ROC=0.9125 F1@0.5=0.6067\n","[NNConv/F1] Ep077 | PR=0.7356 ROC=0.9127 F1@0.5=0.6179\n","[NNConv/F1] Ep078 | PR=0.7372 ROC=0.9089 F1@0.5=0.5939\n","[NNConv/F1] Ep079 | PR=0.7399 ROC=0.9033 F1@0.5=0.6008\n","[NNConv/F1] Ep080 | PR=0.7383 ROC=0.9126 F1@0.5=0.6489\n","[NNConv/F1] Ep081 | PR=0.7424 ROC=0.9081 F1@0.5=0.6164\n","âœ… EarlyStopping (best Val PR-AUC=0.7596) [NNConv/F1]\n","â­ Fold1 best Î±=0.80 (Val PR-AUC=0.8712 [weighted])\n","âœ… Fold1 [Transformer] ROC=0.7875 PR=0.5116 F1=0.5156\n","âœ… Fold1 [NNConv]      ROC=0.8355 PR=0.5948 F1=0.5576\n","âœ… Fold1 [Ensemble]    ROC=0.8325 PR=0.5681 F1=0.5216\n","ğŸ” Fold 2: pos-oversample | base_pos=1082, neg=4190, pos_rate=0.205 -> target=0.30, per_pos_aug=1, +aug=1082, new_train=6354\n","\n","ğŸ“‚ Fold 2 | train=6354 val=585 test=1464\n","[Transformer/F2] Ep001 | PR=0.4550 ROC=0.7860 F1@0.5=0.2791\n","[Transformer/F2] Ep002 | PR=0.4894 ROC=0.7997 F1@0.5=0.5106\n","[Transformer/F2] Ep003 | PR=0.5261 ROC=0.8267 F1@0.5=0.5638\n","[Transformer/F2] Ep004 | PR=0.5761 ROC=0.8385 F1@0.5=0.5528\n","[Transformer/F2] Ep005 | PR=0.6150 ROC=0.8629 F1@0.5=0.5622\n","[Transformer/F2] Ep006 | PR=0.6374 ROC=0.8678 F1@0.5=0.5870\n","[Transformer/F2] Ep007 | PR=0.6428 ROC=0.8776 F1@0.5=0.6049\n","[Transformer/F2] Ep008 | PR=0.6645 ROC=0.8755 F1@0.5=0.6144\n","[Transformer/F2] Ep009 | PR=0.6900 ROC=0.8923 F1@0.5=0.6312\n","[Transformer/F2] Ep010 | PR=0.6948 ROC=0.9003 F1@0.5=0.6080\n","[Transformer/F2] Ep011 | PR=0.6957 ROC=0.8887 F1@0.5=0.6330\n","[Transformer/F2] Ep012 | PR=0.7061 ROC=0.8999 F1@0.5=0.6250\n","[Transformer/F2] Ep013 | PR=0.7310 ROC=0.9036 F1@0.5=0.6344\n","[Transformer/F2] Ep014 | PR=0.7255 ROC=0.8987 F1@0.5=0.6483\n","[Transformer/F2] Ep015 | PR=0.7403 ROC=0.9075 F1@0.5=0.6338\n","[Transformer/F2] Ep016 | PR=0.7371 ROC=0.9062 F1@0.5=0.6351\n","[Transformer/F2] Ep017 | PR=0.7554 ROC=0.9200 F1@0.5=0.6882\n","[Transformer/F2] Ep018 | PR=0.7584 ROC=0.9215 F1@0.5=0.6290\n","[Transformer/F2] Ep019 | PR=0.7540 ROC=0.9194 F1@0.5=0.6607\n","[Transformer/F2] Ep020 | PR=0.7652 ROC=0.9231 F1@0.5=0.6585\n","[Transformer/F2] Ep021 | PR=0.7485 ROC=0.9175 F1@0.5=0.6818\n","[Transformer/F2] Ep022 | PR=0.7706 ROC=0.9252 F1@0.5=0.6726\n","[Transformer/F2] Ep023 | PR=0.7774 ROC=0.9316 F1@0.5=0.6765\n","[Transformer/F2] Ep024 | PR=0.7989 ROC=0.9311 F1@0.5=0.7114\n","[Transformer/F2] Ep025 | PR=0.7980 ROC=0.9344 F1@0.5=0.7181\n","[Transformer/F2] Ep026 | PR=0.7942 ROC=0.9368 F1@0.5=0.7279\n","[Transformer/F2] Ep027 | PR=0.8086 ROC=0.9396 F1@0.5=0.7097\n","[Transformer/F2] Ep028 | PR=0.8108 ROC=0.9374 F1@0.5=0.7300\n","[Transformer/F2] Ep029 | PR=0.8162 ROC=0.9385 F1@0.5=0.7260\n","[Transformer/F2] Ep030 | PR=0.8165 ROC=0.9371 F1@0.5=0.7329\n","[Transformer/F2] Ep031 | PR=0.8337 ROC=0.9470 F1@0.5=0.7465\n","[Transformer/F2] Ep032 | PR=0.8325 ROC=0.9442 F1@0.5=0.7297\n","[Transformer/F2] Ep033 | PR=0.8206 ROC=0.9416 F1@0.5=0.7390\n","[Transformer/F2] Ep034 | PR=0.8444 ROC=0.9529 F1@0.5=0.7635\n","[Transformer/F2] Ep035 | PR=0.8379 ROC=0.9517 F1@0.5=0.7551\n","[Transformer/F2] Ep036 | PR=0.8358 ROC=0.9505 F1@0.5=0.7456\n","[Transformer/F2] Ep037 | PR=0.8314 ROC=0.9484 F1@0.5=0.7525\n","[Transformer/F2] Ep038 | PR=0.8334 ROC=0.9496 F1@0.5=0.7579\n","[Transformer/F2] Ep039 | PR=0.8189 ROC=0.9428 F1@0.5=0.7304\n","[Transformer/F2] Ep040 | PR=0.8475 ROC=0.9544 F1@0.5=0.7382\n","[Transformer/F2] Ep041 | PR=0.8587 ROC=0.9570 F1@0.5=0.7801\n","[Transformer/F2] Ep042 | PR=0.8398 ROC=0.9532 F1@0.5=0.7352\n","[Transformer/F2] Ep043 | PR=0.8538 ROC=0.9557 F1@0.5=0.7476\n","[Transformer/F2] Ep044 | PR=0.8386 ROC=0.9479 F1@0.5=0.7467\n","[Transformer/F2] Ep045 | PR=0.8547 ROC=0.9558 F1@0.5=0.7568\n","[Transformer/F2] Ep046 | PR=0.8370 ROC=0.9522 F1@0.5=0.7651\n","[Transformer/F2] Ep047 | PR=0.8515 ROC=0.9558 F1@0.5=0.7833\n","[Transformer/F2] Ep048 | PR=0.8501 ROC=0.9548 F1@0.5=0.7719\n","[Transformer/F2] Ep049 | PR=0.8596 ROC=0.9578 F1@0.5=0.7826\n","[Transformer/F2] Ep050 | PR=0.8635 ROC=0.9578 F1@0.5=0.7712\n","[Transformer/F2] Ep051 | PR=0.8591 ROC=0.9572 F1@0.5=0.7762\n","[Transformer/F2] Ep052 | PR=0.8742 ROC=0.9617 F1@0.5=0.8014\n","[Transformer/F2] Ep053 | PR=0.8790 ROC=0.9644 F1@0.5=0.8082\n","[Transformer/F2] Ep054 | PR=0.8737 ROC=0.9629 F1@0.5=0.7864\n","[Transformer/F2] Ep055 | PR=0.8907 ROC=0.9672 F1@0.5=0.7767\n","[Transformer/F2] Ep056 | PR=0.8775 ROC=0.9617 F1@0.5=0.7917\n","[Transformer/F2] Ep057 | PR=0.8691 ROC=0.9617 F1@0.5=0.8000\n","[Transformer/F2] Ep058 | PR=0.8875 ROC=0.9648 F1@0.5=0.8075\n","[Transformer/F2] Ep059 | PR=0.8779 ROC=0.9633 F1@0.5=0.7841\n","[Transformer/F2] Ep060 | PR=0.8744 ROC=0.9631 F1@0.5=0.7740\n","[Transformer/F2] Ep061 | PR=0.8898 ROC=0.9666 F1@0.5=0.8055\n","[Transformer/F2] Ep062 | PR=0.8847 ROC=0.9653 F1@0.5=0.7850\n","[Transformer/F2] Ep063 | PR=0.8856 ROC=0.9646 F1@0.5=0.8110\n","[Transformer/F2] Ep064 | PR=0.8802 ROC=0.9657 F1@0.5=0.8214\n","[Transformer/F2] Ep065 | PR=0.8699 ROC=0.9585 F1@0.5=0.7870\n","âœ… EarlyStopping (best Val PR-AUC=0.8907) [Transformer/F2]\n","[NNConv/F2] Ep001 | PR=0.4214 ROC=0.7231 F1@0.5=0.4481\n","[NNConv/F2] Ep002 | PR=0.4799 ROC=0.7781 F1@0.5=0.4511\n","[NNConv/F2] Ep003 | PR=0.5034 ROC=0.8288 F1@0.5=0.4667\n","[NNConv/F2] Ep004 | PR=0.5405 ROC=0.8394 F1@0.5=0.6224\n","[NNConv/F2] Ep005 | PR=0.5364 ROC=0.8503 F1@0.5=0.5075\n","[NNConv/F2] Ep006 | PR=0.5456 ROC=0.8483 F1@0.5=0.6183\n","[NNConv/F2] Ep007 | PR=0.5621 ROC=0.8624 F1@0.5=0.6015\n","[NNConv/F2] Ep008 | PR=0.6003 ROC=0.8735 F1@0.5=0.5969\n","[NNConv/F2] Ep009 | PR=0.5821 ROC=0.8699 F1@0.5=0.6272\n","[NNConv/F2] Ep010 | PR=0.5812 ROC=0.8735 F1@0.5=0.6247\n","[NNConv/F2] Ep011 | PR=0.5731 ROC=0.8588 F1@0.5=0.6007\n","[NNConv/F2] Ep012 | PR=0.5994 ROC=0.8680 F1@0.5=0.3409\n","[NNConv/F2] Ep013 | PR=0.6205 ROC=0.8887 F1@0.5=0.6182\n","[NNConv/F2] Ep014 | PR=0.6157 ROC=0.8849 F1@0.5=0.5900\n","[NNConv/F2] Ep015 | PR=0.6358 ROC=0.8884 F1@0.5=0.6584\n","[NNConv/F2] Ep016 | PR=0.6388 ROC=0.8884 F1@0.5=0.6595\n","[NNConv/F2] Ep017 | PR=0.6412 ROC=0.8931 F1@0.5=0.6582\n","[NNConv/F2] Ep018 | PR=0.6611 ROC=0.8943 F1@0.5=0.6515\n","[NNConv/F2] Ep019 | PR=0.6424 ROC=0.8812 F1@0.5=0.6268\n","[NNConv/F2] Ep020 | PR=0.6667 ROC=0.9000 F1@0.5=0.6569\n","[NNConv/F2] Ep021 | PR=0.6592 ROC=0.8967 F1@0.5=0.6828\n","[NNConv/F2] Ep022 | PR=0.6724 ROC=0.8882 F1@0.5=0.6270\n","[NNConv/F2] Ep023 | PR=0.6744 ROC=0.9014 F1@0.5=0.6250\n","[NNConv/F2] Ep024 | PR=0.6522 ROC=0.8910 F1@0.5=0.6667\n","[NNConv/F2] Ep025 | PR=0.7173 ROC=0.9133 F1@0.5=0.6490\n","[NNConv/F2] Ep026 | PR=0.6634 ROC=0.9007 F1@0.5=0.6890\n","[NNConv/F2] Ep027 | PR=0.7182 ROC=0.9105 F1@0.5=0.6873\n","[NNConv/F2] Ep028 | PR=0.6987 ROC=0.9002 F1@0.5=0.6901\n","[NNConv/F2] Ep029 | PR=0.6735 ROC=0.8972 F1@0.5=0.6894\n","[NNConv/F2] Ep030 | PR=0.6716 ROC=0.8897 F1@0.5=0.6265\n","[NNConv/F2] Ep031 | PR=0.6749 ROC=0.9027 F1@0.5=0.6324\n","[NNConv/F2] Ep032 | PR=0.6975 ROC=0.9104 F1@0.5=0.6510\n","[NNConv/F2] Ep033 | PR=0.7004 ROC=0.9035 F1@0.5=0.6824\n","[NNConv/F2] Ep034 | PR=0.7212 ROC=0.9154 F1@0.5=0.6853\n","[NNConv/F2] Ep035 | PR=0.7427 ROC=0.9095 F1@0.5=0.6914\n","[NNConv/F2] Ep036 | PR=0.6900 ROC=0.9083 F1@0.5=0.6371\n","[NNConv/F2] Ep037 | PR=0.7238 ROC=0.9073 F1@0.5=0.6711\n","[NNConv/F2] Ep038 | PR=0.7187 ROC=0.9126 F1@0.5=0.7042\n","[NNConv/F2] Ep039 | PR=0.7287 ROC=0.9158 F1@0.5=0.7020\n","[NNConv/F2] Ep040 | PR=0.7547 ROC=0.9148 F1@0.5=0.6795\n","[NNConv/F2] Ep041 | PR=0.7372 ROC=0.9173 F1@0.5=0.6766\n","[NNConv/F2] Ep042 | PR=0.7214 ROC=0.9017 F1@0.5=0.6739\n","[NNConv/F2] Ep043 | PR=0.7141 ROC=0.9117 F1@0.5=0.6879\n","[NNConv/F2] Ep044 | PR=0.7440 ROC=0.9263 F1@0.5=0.6935\n","[NNConv/F2] Ep045 | PR=0.7465 ROC=0.9063 F1@0.5=0.6820\n","[NNConv/F2] Ep046 | PR=0.7421 ROC=0.9222 F1@0.5=0.7158\n","[NNConv/F2] Ep047 | PR=0.7512 ROC=0.9208 F1@0.5=0.6516\n","[NNConv/F2] Ep048 | PR=0.7593 ROC=0.9199 F1@0.5=0.6935\n","[NNConv/F2] Ep049 | PR=0.7677 ROC=0.9252 F1@0.5=0.6915\n","[NNConv/F2] Ep050 | PR=0.7354 ROC=0.9138 F1@0.5=0.7127\n","[NNConv/F2] Ep051 | PR=0.7692 ROC=0.9257 F1@0.5=0.7067\n","[NNConv/F2] Ep052 | PR=0.7549 ROC=0.9255 F1@0.5=0.7120\n","[NNConv/F2] Ep053 | PR=0.7707 ROC=0.9223 F1@0.5=0.6827\n","[NNConv/F2] Ep054 | PR=0.7912 ROC=0.9344 F1@0.5=0.7509\n","[NNConv/F2] Ep055 | PR=0.7692 ROC=0.9231 F1@0.5=0.7126\n","[NNConv/F2] Ep056 | PR=0.7712 ROC=0.9224 F1@0.5=0.6989\n","[NNConv/F2] Ep057 | PR=0.8037 ROC=0.9320 F1@0.5=0.7224\n","[NNConv/F2] Ep058 | PR=0.7944 ROC=0.9292 F1@0.5=0.7059\n","[NNConv/F2] Ep059 | PR=0.7873 ROC=0.9365 F1@0.5=0.7317\n","[NNConv/F2] Ep060 | PR=0.7862 ROC=0.9255 F1@0.5=0.7327\n","[NNConv/F2] Ep061 | PR=0.7967 ROC=0.9255 F1@0.5=0.5588\n","[NNConv/F2] Ep062 | PR=0.7966 ROC=0.9308 F1@0.5=0.6667\n","[NNConv/F2] Ep063 | PR=0.8134 ROC=0.9314 F1@0.5=0.7273\n","[NNConv/F2] Ep064 | PR=0.8214 ROC=0.9286 F1@0.5=0.7020\n","[NNConv/F2] Ep065 | PR=0.7687 ROC=0.9247 F1@0.5=0.7085\n","[NNConv/F2] Ep066 | PR=0.8103 ROC=0.9316 F1@0.5=0.7368\n","[NNConv/F2] Ep067 | PR=0.8113 ROC=0.9352 F1@0.5=0.7544\n","[NNConv/F2] Ep068 | PR=0.8189 ROC=0.9370 F1@0.5=0.7415\n","[NNConv/F2] Ep069 | PR=0.8017 ROC=0.9277 F1@0.5=0.7353\n","[NNConv/F2] Ep070 | PR=0.8253 ROC=0.9415 F1@0.5=0.7422\n","[NNConv/F2] Ep071 | PR=0.8029 ROC=0.9394 F1@0.5=0.7331\n","[NNConv/F2] Ep072 | PR=0.7904 ROC=0.9318 F1@0.5=0.6954\n","[NNConv/F2] Ep073 | PR=0.8306 ROC=0.9346 F1@0.5=0.7200\n","[NNConv/F2] Ep074 | PR=0.8210 ROC=0.9435 F1@0.5=0.7500\n","[NNConv/F2] Ep075 | PR=0.8143 ROC=0.9400 F1@0.5=0.7321\n","[NNConv/F2] Ep076 | PR=0.8177 ROC=0.9447 F1@0.5=0.7344\n","[NNConv/F2] Ep077 | PR=0.7911 ROC=0.9394 F1@0.5=0.6939\n","[NNConv/F2] Ep078 | PR=0.8265 ROC=0.9399 F1@0.5=0.7599\n","[NNConv/F2] Ep079 | PR=0.8455 ROC=0.9382 F1@0.5=0.7279\n","[NNConv/F2] Ep080 | PR=0.8465 ROC=0.9478 F1@0.5=0.7579\n","[NNConv/F2] Ep081 | PR=0.8548 ROC=0.9445 F1@0.5=0.7704\n","[NNConv/F2] Ep082 | PR=0.8238 ROC=0.9373 F1@0.5=0.7266\n","[NNConv/F2] Ep083 | PR=0.8522 ROC=0.9461 F1@0.5=0.7645\n","[NNConv/F2] Ep084 | PR=0.8593 ROC=0.9512 F1@0.5=0.7634\n","[NNConv/F2] Ep085 | PR=0.8326 ROC=0.9431 F1@0.5=0.7529\n","[NNConv/F2] Ep086 | PR=0.8552 ROC=0.9426 F1@0.5=0.7653\n","[NNConv/F2] Ep087 | PR=0.8245 ROC=0.9399 F1@0.5=0.7533\n","[NNConv/F2] Ep088 | PR=0.8470 ROC=0.9496 F1@0.5=0.7390\n","[NNConv/F2] Ep089 | PR=0.8555 ROC=0.9475 F1@0.5=0.7770\n","[NNConv/F2] Ep090 | PR=0.8364 ROC=0.9459 F1@0.5=0.7333\n","[NNConv/F2] Ep091 | PR=0.8496 ROC=0.9536 F1@0.5=0.7588\n","[NNConv/F2] Ep092 | PR=0.8545 ROC=0.9543 F1@0.5=0.7807\n","[NNConv/F2] Ep093 | PR=0.8696 ROC=0.9481 F1@0.5=0.7429\n","[NNConv/F2] Ep094 | PR=0.8483 ROC=0.9507 F1@0.5=0.7766\n","[NNConv/F2] Ep095 | PR=0.8710 ROC=0.9547 F1@0.5=0.7404\n","[NNConv/F2] Ep096 | PR=0.8717 ROC=0.9546 F1@0.5=0.7770\n","[NNConv/F2] Ep097 | PR=0.8667 ROC=0.9507 F1@0.5=0.7770\n","[NNConv/F2] Ep098 | PR=0.8613 ROC=0.9404 F1@0.5=0.7100\n","[NNConv/F2] Ep099 | PR=0.8739 ROC=0.9538 F1@0.5=0.7577\n","[NNConv/F2] Ep100 | PR=0.8596 ROC=0.9514 F1@0.5=0.7697\n","[NNConv/F2] Ep101 | PR=0.8647 ROC=0.9522 F1@0.5=0.7744\n","[NNConv/F2] Ep102 | PR=0.8780 ROC=0.9592 F1@0.5=0.8132\n","[NNConv/F2] Ep103 | PR=0.8660 ROC=0.9526 F1@0.5=0.7923\n","[NNConv/F2] Ep104 | PR=0.8811 ROC=0.9568 F1@0.5=0.8031\n","[NNConv/F2] Ep105 | PR=0.8811 ROC=0.9575 F1@0.5=0.8015\n","[NNConv/F2] Ep106 | PR=0.8979 ROC=0.9592 F1@0.5=0.7744\n","[NNConv/F2] Ep107 | PR=0.8795 ROC=0.9534 F1@0.5=0.7631\n","[NNConv/F2] Ep108 | PR=0.9033 ROC=0.9642 F1@0.5=0.7986\n","[NNConv/F2] Ep109 | PR=0.8784 ROC=0.9543 F1@0.5=0.7313\n","[NNConv/F2] Ep110 | PR=0.8889 ROC=0.9531 F1@0.5=0.7722\n","[NNConv/F2] Ep111 | PR=0.9048 ROC=0.9611 F1@0.5=0.8016\n","[NNConv/F2] Ep112 | PR=0.8872 ROC=0.9557 F1@0.5=0.7664\n","[NNConv/F2] Ep113 | PR=0.8966 ROC=0.9616 F1@0.5=0.7986\n","[NNConv/F2] Ep114 | PR=0.9047 ROC=0.9636 F1@0.5=0.8110\n","[NNConv/F2] Ep115 | PR=0.8924 ROC=0.9564 F1@0.5=0.8031\n","[NNConv/F2] Ep116 | PR=0.9063 ROC=0.9639 F1@0.5=0.7935\n","[NNConv/F2] Ep117 | PR=0.9132 ROC=0.9665 F1@0.5=0.7969\n","[NNConv/F2] Ep118 | PR=0.9093 ROC=0.9628 F1@0.5=0.7970\n","[NNConv/F2] Ep119 | PR=0.8953 ROC=0.9628 F1@0.5=0.8075\n","[NNConv/F2] Ep120 | PR=0.9124 ROC=0.9664 F1@0.5=0.8235\n","[NNConv/F2] Ep121 | PR=0.9129 ROC=0.9676 F1@0.5=0.8253\n","[NNConv/F2] Ep122 | PR=0.9001 ROC=0.9613 F1@0.5=0.7591\n","[NNConv/F2] Ep123 | PR=0.9176 ROC=0.9680 F1@0.5=0.8159\n","[NNConv/F2] Ep124 | PR=0.9005 ROC=0.9672 F1@0.5=0.7986\n","[NNConv/F2] Ep125 | PR=0.8936 ROC=0.9625 F1@0.5=0.8145\n","[NNConv/F2] Ep126 | PR=0.9045 ROC=0.9641 F1@0.5=0.8043\n","[NNConv/F2] Ep127 | PR=0.9259 ROC=0.9677 F1@0.5=0.8016\n","[NNConv/F2] Ep128 | PR=0.8923 ROC=0.9620 F1@0.5=0.7888\n","[NNConv/F2] Ep129 | PR=0.9228 ROC=0.9678 F1@0.5=0.8313\n","[NNConv/F2] Ep130 | PR=0.8816 ROC=0.9656 F1@0.5=0.8226\n","[NNConv/F2] Ep131 | PR=0.9135 ROC=0.9672 F1@0.5=0.8041\n","[NNConv/F2] Ep132 | PR=0.9237 ROC=0.9707 F1@0.5=0.8453\n","[NNConv/F2] Ep133 | PR=0.9060 ROC=0.9663 F1@0.5=0.8278\n","[NNConv/F2] Ep134 | PR=0.9104 ROC=0.9669 F1@0.5=0.8364\n","[NNConv/F2] Ep135 | PR=0.8993 ROC=0.9659 F1@0.5=0.8227\n","[NNConv/F2] Ep136 | PR=0.8959 ROC=0.9616 F1@0.5=0.7925\n","[NNConv/F2] Ep137 | PR=0.9022 ROC=0.9701 F1@0.5=0.8390\n","âœ… EarlyStopping (best Val PR-AUC=0.9259) [NNConv/F2]\n","â­ Fold2 best Î±=0.40 (Val PR-AUC=0.9425 [weighted])\n","âœ… Fold2 [Transformer] ROC=0.8126 PR=0.5987 F1=0.6014\n","âœ… Fold2 [NNConv]      ROC=0.7707 PR=0.5829 F1=0.5057\n","âœ… Fold2 [Ensemble]    ROC=0.8213 PR=0.6202 F1=0.4981\n","ğŸ” Fold 3: pos-oversample | base_pos=1095, neg=4177, pos_rate=0.208 -> target=0.30, per_pos_aug=1, +aug=1095, new_train=6367\n","\n","ğŸ“‚ Fold 3 | train=6367 val=585 test=1464\n","[Transformer/F3] Ep001 | PR=0.4327 ROC=0.7744 F1@0.5=0.3715\n","[Transformer/F3] Ep002 | PR=0.5005 ROC=0.8049 F1@0.5=0.5244\n","[Transformer/F3] Ep003 | PR=0.5181 ROC=0.8116 F1@0.5=0.5056\n","[Transformer/F3] Ep004 | PR=0.5315 ROC=0.8216 F1@0.5=0.5375\n","[Transformer/F3] Ep005 | PR=0.5437 ROC=0.8238 F1@0.5=0.4987\n","[Transformer/F3] Ep006 | PR=0.5615 ROC=0.8414 F1@0.5=0.5620\n","[Transformer/F3] Ep007 | PR=0.5439 ROC=0.8372 F1@0.5=0.5179\n","[Transformer/F3] Ep008 | PR=0.5626 ROC=0.8502 F1@0.5=0.5181\n","[Transformer/F3] Ep009 | PR=0.5641 ROC=0.8599 F1@0.5=0.5755\n","[Transformer/F3] Ep010 | PR=0.5917 ROC=0.8711 F1@0.5=0.5337\n","[Transformer/F3] Ep011 | PR=0.5929 ROC=0.8662 F1@0.5=0.5278\n","[Transformer/F3] Ep012 | PR=0.5967 ROC=0.8739 F1@0.5=0.5640\n","[Transformer/F3] Ep013 | PR=0.6244 ROC=0.8850 F1@0.5=0.5894\n","[Transformer/F3] Ep014 | PR=0.6123 ROC=0.8891 F1@0.5=0.5836\n","[Transformer/F3] Ep015 | PR=0.6725 ROC=0.9005 F1@0.5=0.6189\n","[Transformer/F3] Ep016 | PR=0.6647 ROC=0.9048 F1@0.5=0.6034\n","[Transformer/F3] Ep017 | PR=0.6402 ROC=0.9014 F1@0.5=0.5779\n","[Transformer/F3] Ep018 | PR=0.6803 ROC=0.9057 F1@0.5=0.6385\n","[Transformer/F3] Ep019 | PR=0.6490 ROC=0.9056 F1@0.5=0.5900\n","[Transformer/F3] Ep020 | PR=0.7219 ROC=0.9204 F1@0.5=0.6690\n","[Transformer/F3] Ep021 | PR=0.7255 ROC=0.9238 F1@0.5=0.6643\n","[Transformer/F3] Ep022 | PR=0.7072 ROC=0.9218 F1@0.5=0.6667\n","[Transformer/F3] Ep023 | PR=0.7096 ROC=0.9198 F1@0.5=0.6443\n","[Transformer/F3] Ep024 | PR=0.7232 ROC=0.9291 F1@0.5=0.6690\n","[Transformer/F3] Ep025 | PR=0.7387 ROC=0.9295 F1@0.5=0.6868\n","[Transformer/F3] Ep026 | PR=0.7520 ROC=0.9330 F1@0.5=0.6923\n","[Transformer/F3] Ep027 | PR=0.7529 ROC=0.9287 F1@0.5=0.6667\n","[Transformer/F3] Ep028 | PR=0.7461 ROC=0.9331 F1@0.5=0.6824\n","[Transformer/F3] Ep029 | PR=0.7700 ROC=0.9331 F1@0.5=0.6583\n","[Transformer/F3] Ep030 | PR=0.7733 ROC=0.9345 F1@0.5=0.7004\n","[Transformer/F3] Ep031 | PR=0.7765 ROC=0.9386 F1@0.5=0.7041\n","[Transformer/F3] Ep032 | PR=0.7762 ROC=0.9399 F1@0.5=0.7218\n","[Transformer/F3] Ep033 | PR=0.7822 ROC=0.9404 F1@0.5=0.7218\n","[Transformer/F3] Ep034 | PR=0.7803 ROC=0.9402 F1@0.5=0.7047\n","[Transformer/F3] Ep035 | PR=0.7879 ROC=0.9445 F1@0.5=0.7500\n","[Transformer/F3] Ep036 | PR=0.7824 ROC=0.9428 F1@0.5=0.7082\n","[Transformer/F3] Ep037 | PR=0.7984 ROC=0.9445 F1@0.5=0.7279\n","[Transformer/F3] Ep038 | PR=0.7765 ROC=0.9402 F1@0.5=0.6866\n","[Transformer/F3] Ep039 | PR=0.7899 ROC=0.9455 F1@0.5=0.7328\n","[Transformer/F3] Ep040 | PR=0.7951 ROC=0.9469 F1@0.5=0.7410\n","[Transformer/F3] Ep041 | PR=0.7921 ROC=0.9435 F1@0.5=0.7097\n","[Transformer/F3] Ep042 | PR=0.7963 ROC=0.9433 F1@0.5=0.7148\n","[Transformer/F3] Ep043 | PR=0.7777 ROC=0.9443 F1@0.5=0.7203\n","[Transformer/F3] Ep044 | PR=0.8025 ROC=0.9467 F1@0.5=0.7381\n","[Transformer/F3] Ep045 | PR=0.7904 ROC=0.9455 F1@0.5=0.7315\n","[Transformer/F3] Ep046 | PR=0.7995 ROC=0.9503 F1@0.5=0.7491\n","[Transformer/F3] Ep047 | PR=0.7829 ROC=0.9419 F1@0.5=0.7132\n","[Transformer/F3] Ep048 | PR=0.8067 ROC=0.9478 F1@0.5=0.7537\n","[Transformer/F3] Ep049 | PR=0.8084 ROC=0.9494 F1@0.5=0.7299\n","[Transformer/F3] Ep050 | PR=0.8017 ROC=0.9514 F1@0.5=0.7481\n","[Transformer/F3] Ep051 | PR=0.7913 ROC=0.9484 F1@0.5=0.7326\n","[Transformer/F3] Ep052 | PR=0.7950 ROC=0.9506 F1@0.5=0.7623\n","[Transformer/F3] Ep053 | PR=0.8021 ROC=0.9524 F1@0.5=0.7437\n","[Transformer/F3] Ep054 | PR=0.7995 ROC=0.9508 F1@0.5=0.7574\n","[Transformer/F3] Ep055 | PR=0.8111 ROC=0.9496 F1@0.5=0.7250\n","[Transformer/F3] Ep056 | PR=0.7934 ROC=0.9479 F1@0.5=0.7265\n","[Transformer/F3] Ep057 | PR=0.8088 ROC=0.9504 F1@0.5=0.7206\n","[Transformer/F3] Ep058 | PR=0.8168 ROC=0.9531 F1@0.5=0.7500\n","[Transformer/F3] Ep059 | PR=0.8127 ROC=0.9562 F1@0.5=0.7561\n","[Transformer/F3] Ep060 | PR=0.8088 ROC=0.9509 F1@0.5=0.7438\n","[Transformer/F3] Ep061 | PR=0.8143 ROC=0.9549 F1@0.5=0.7631\n","[Transformer/F3] Ep062 | PR=0.8266 ROC=0.9587 F1@0.5=0.7722\n","[Transformer/F3] Ep063 | PR=0.7996 ROC=0.9494 F1@0.5=0.7245\n","[Transformer/F3] Ep064 | PR=0.8115 ROC=0.9522 F1@0.5=0.7279\n","[Transformer/F3] Ep065 | PR=0.8060 ROC=0.9515 F1@0.5=0.7273\n","[Transformer/F3] Ep066 | PR=0.8140 ROC=0.9514 F1@0.5=0.7510\n","[Transformer/F3] Ep067 | PR=0.8282 ROC=0.9582 F1@0.5=0.7799\n","[Transformer/F3] Ep068 | PR=0.8155 ROC=0.9530 F1@0.5=0.7480\n","[Transformer/F3] Ep069 | PR=0.8208 ROC=0.9546 F1@0.5=0.7510\n","[Transformer/F3] Ep070 | PR=0.8213 ROC=0.9524 F1@0.5=0.7386\n","[Transformer/F3] Ep071 | PR=0.8250 ROC=0.9579 F1@0.5=0.7645\n","[Transformer/F3] Ep072 | PR=0.8155 ROC=0.9548 F1@0.5=0.7452\n","[Transformer/F3] Ep073 | PR=0.8181 ROC=0.9540 F1@0.5=0.7350\n","[Transformer/F3] Ep074 | PR=0.8207 ROC=0.9561 F1@0.5=0.7420\n","[Transformer/F3] Ep075 | PR=0.8381 ROC=0.9583 F1@0.5=0.7442\n","[Transformer/F3] Ep076 | PR=0.8258 ROC=0.9557 F1@0.5=0.7429\n","[Transformer/F3] Ep077 | PR=0.8229 ROC=0.9553 F1@0.5=0.7581\n","[Transformer/F3] Ep078 | PR=0.8186 ROC=0.9579 F1@0.5=0.7541\n","[Transformer/F3] Ep079 | PR=0.8296 ROC=0.9589 F1@0.5=0.7769\n","[Transformer/F3] Ep080 | PR=0.8251 ROC=0.9590 F1@0.5=0.7846\n","[Transformer/F3] Ep081 | PR=0.8343 ROC=0.9582 F1@0.5=0.7584\n","[Transformer/F3] Ep082 | PR=0.8360 ROC=0.9606 F1@0.5=0.8032\n","[Transformer/F3] Ep083 | PR=0.8200 ROC=0.9571 F1@0.5=0.7447\n","[Transformer/F3] Ep084 | PR=0.8372 ROC=0.9568 F1@0.5=0.7552\n","[Transformer/F3] Ep085 | PR=0.8347 ROC=0.9609 F1@0.5=0.7761\n","âœ… EarlyStopping (best Val PR-AUC=0.8381) [Transformer/F3]\n","[NNConv/F3] Ep001 | PR=0.3300 ROC=0.6840 F1@0.5=0.0000\n","[NNConv/F3] Ep002 | PR=0.4438 ROC=0.7744 F1@0.5=0.4809\n","[NNConv/F3] Ep003 | PR=0.5036 ROC=0.8073 F1@0.5=0.5338\n","[NNConv/F3] Ep004 | PR=0.4905 ROC=0.8014 F1@0.5=0.4643\n","[NNConv/F3] Ep005 | PR=0.5237 ROC=0.8181 F1@0.5=0.5041\n","[NNConv/F3] Ep006 | PR=0.5197 ROC=0.8220 F1@0.5=0.5309\n","[NNConv/F3] Ep007 | PR=0.5002 ROC=0.8227 F1@0.5=0.5449\n","[NNConv/F3] Ep008 | PR=0.5417 ROC=0.8462 F1@0.5=0.5415\n","[NNConv/F3] Ep009 | PR=0.5522 ROC=0.8467 F1@0.5=0.5714\n","[NNConv/F3] Ep010 | PR=0.5358 ROC=0.8398 F1@0.5=0.5299\n","[NNConv/F3] Ep011 | PR=0.6003 ROC=0.8700 F1@0.5=0.5851\n","[NNConv/F3] Ep012 | PR=0.5847 ROC=0.8689 F1@0.5=0.6000\n","[NNConv/F3] Ep013 | PR=0.6605 ROC=0.8867 F1@0.5=0.6056\n","[NNConv/F3] Ep014 | PR=0.6230 ROC=0.8818 F1@0.5=0.6194\n","[NNConv/F3] Ep015 | PR=0.6069 ROC=0.8756 F1@0.5=0.5905\n","[NNConv/F3] Ep016 | PR=0.6355 ROC=0.8884 F1@0.5=0.6029\n","[NNConv/F3] Ep017 | PR=0.6430 ROC=0.8926 F1@0.5=0.6187\n","[NNConv/F3] Ep018 | PR=0.6801 ROC=0.9041 F1@0.5=0.6343\n","[NNConv/F3] Ep019 | PR=0.6742 ROC=0.9022 F1@0.5=0.6018\n","[NNConv/F3] Ep020 | PR=0.6819 ROC=0.9048 F1@0.5=0.6500\n","[NNConv/F3] Ep021 | PR=0.6766 ROC=0.8989 F1@0.5=0.5983\n","[NNConv/F3] Ep022 | PR=0.6923 ROC=0.9088 F1@0.5=0.6608\n","[NNConv/F3] Ep023 | PR=0.7179 ROC=0.9166 F1@0.5=0.6338\n","[NNConv/F3] Ep024 | PR=0.6795 ROC=0.9143 F1@0.5=0.6943\n","[NNConv/F3] Ep025 | PR=0.6560 ROC=0.9000 F1@0.5=0.6312\n","[NNConv/F3] Ep026 | PR=0.6729 ROC=0.9081 F1@0.5=0.6410\n","[NNConv/F3] Ep027 | PR=0.6688 ROC=0.9078 F1@0.5=0.6498\n","[NNConv/F3] Ep028 | PR=0.6753 ROC=0.9007 F1@0.5=0.6769\n","[NNConv/F3] Ep029 | PR=0.7012 ROC=0.9193 F1@0.5=0.7000\n","[NNConv/F3] Ep030 | PR=0.7116 ROC=0.9105 F1@0.5=0.6335\n","[NNConv/F3] Ep031 | PR=0.7138 ROC=0.9212 F1@0.5=0.6862\n","[NNConv/F3] Ep032 | PR=0.7228 ROC=0.9208 F1@0.5=0.6759\n","[NNConv/F3] Ep033 | PR=0.7577 ROC=0.9300 F1@0.5=0.6904\n","[NNConv/F3] Ep034 | PR=0.7260 ROC=0.9206 F1@0.5=0.6542\n","[NNConv/F3] Ep035 | PR=0.7267 ROC=0.9273 F1@0.5=0.6904\n","[NNConv/F3] Ep036 | PR=0.7553 ROC=0.9271 F1@0.5=0.6481\n","[NNConv/F3] Ep037 | PR=0.7540 ROC=0.9327 F1@0.5=0.6846\n","[NNConv/F3] Ep038 | PR=0.7887 ROC=0.9381 F1@0.5=0.6777\n","[NNConv/F3] Ep039 | PR=0.7624 ROC=0.9341 F1@0.5=0.6934\n","[NNConv/F3] Ep040 | PR=0.7553 ROC=0.9318 F1@0.5=0.6821\n","[NNConv/F3] Ep041 | PR=0.7706 ROC=0.9362 F1@0.5=0.6869\n","[NNConv/F3] Ep042 | PR=0.7964 ROC=0.9390 F1@0.5=0.7132\n","[NNConv/F3] Ep043 | PR=0.7607 ROC=0.9290 F1@0.5=0.6940\n","[NNConv/F3] Ep044 | PR=0.7856 ROC=0.9379 F1@0.5=0.7252\n","[NNConv/F3] Ep045 | PR=0.8038 ROC=0.9409 F1@0.5=0.7197\n","[NNConv/F3] Ep046 | PR=0.7840 ROC=0.9357 F1@0.5=0.7174\n","[NNConv/F3] Ep047 | PR=0.7610 ROC=0.9276 F1@0.5=0.6518\n","[NNConv/F3] Ep048 | PR=0.7824 ROC=0.9340 F1@0.5=0.7021\n","[NNConv/F3] Ep049 | PR=0.7983 ROC=0.9360 F1@0.5=0.6920\n","[NNConv/F3] Ep050 | PR=0.8063 ROC=0.9420 F1@0.5=0.7073\n","[NNConv/F3] Ep051 | PR=0.7865 ROC=0.9343 F1@0.5=0.6846\n","[NNConv/F3] Ep052 | PR=0.8093 ROC=0.9396 F1@0.5=0.6973\n","[NNConv/F3] Ep053 | PR=0.7971 ROC=0.9365 F1@0.5=0.6794\n","[NNConv/F3] Ep054 | PR=0.8128 ROC=0.9413 F1@0.5=0.6957\n","[NNConv/F3] Ep055 | PR=0.8262 ROC=0.9470 F1@0.5=0.7168\n","[NNConv/F3] Ep056 | PR=0.7992 ROC=0.9373 F1@0.5=0.6905\n","[NNConv/F3] Ep057 | PR=0.8304 ROC=0.9487 F1@0.5=0.6977\n","[NNConv/F3] Ep058 | PR=0.7945 ROC=0.9381 F1@0.5=0.7294\n","[NNConv/F3] Ep059 | PR=0.8108 ROC=0.9433 F1@0.5=0.7143\n","[NNConv/F3] Ep060 | PR=0.8084 ROC=0.9417 F1@0.5=0.6803\n","[NNConv/F3] Ep061 | PR=0.7782 ROC=0.9330 F1@0.5=0.6575\n","[NNConv/F3] Ep062 | PR=0.8035 ROC=0.9410 F1@0.5=0.6726\n","[NNConv/F3] Ep063 | PR=0.8279 ROC=0.9479 F1@0.5=0.7079\n","[NNConv/F3] Ep064 | PR=0.7796 ROC=0.9278 F1@0.5=0.7154\n","[NNConv/F3] Ep065 | PR=0.8228 ROC=0.9469 F1@0.5=0.7160\n","[NNConv/F3] Ep066 | PR=0.8097 ROC=0.9433 F1@0.5=0.7295\n","[NNConv/F3] Ep067 | PR=0.8181 ROC=0.9426 F1@0.5=0.7241\n","âœ… EarlyStopping (best Val PR-AUC=0.8304) [NNConv/F3]\n","â­ Fold3 best Î±=0.50 (Val PR-AUC=0.8748 [weighted])\n","âœ… Fold3 [Transformer] ROC=0.7920 PR=0.5853 F1=0.5668\n","âœ… Fold3 [NNConv]      ROC=0.8215 PR=0.6271 F1=0.5958\n","âœ… Fold3 [Ensemble]    ROC=0.8194 PR=0.6409 F1=0.5991\n","ğŸ” Fold 4: pos-oversample | base_pos=1089, neg=4183, pos_rate=0.207 -> target=0.30, per_pos_aug=1, +aug=1089, new_train=6361\n","\n","ğŸ“‚ Fold 4 | train=6361 val=585 test=1464\n","[Transformer/F4] Ep001 | PR=0.3987 ROC=0.7418 F1@0.5=0.4719\n","[Transformer/F4] Ep002 | PR=0.4402 ROC=0.7634 F1@0.5=0.4590\n","[Transformer/F4] Ep003 | PR=0.4745 ROC=0.7889 F1@0.5=0.5082\n","[Transformer/F4] Ep004 | PR=0.4950 ROC=0.8090 F1@0.5=0.4841\n","[Transformer/F4] Ep005 | PR=0.5048 ROC=0.8058 F1@0.5=0.4346\n","[Transformer/F4] Ep006 | PR=0.4979 ROC=0.8193 F1@0.5=0.5669\n","[Transformer/F4] Ep007 | PR=0.4996 ROC=0.8252 F1@0.5=0.5321\n","[Transformer/F4] Ep008 | PR=0.5010 ROC=0.8194 F1@0.5=0.5227\n","[Transformer/F4] Ep009 | PR=0.5167 ROC=0.8333 F1@0.5=0.5798\n","[Transformer/F4] Ep010 | PR=0.5050 ROC=0.8183 F1@0.5=0.5169\n","[Transformer/F4] Ep011 | PR=0.5208 ROC=0.8388 F1@0.5=0.5668\n","[Transformer/F4] Ep012 | PR=0.5172 ROC=0.8470 F1@0.5=0.4898\n","[Transformer/F4] Ep013 | PR=0.5434 ROC=0.8503 F1@0.5=0.5960\n","[Transformer/F4] Ep014 | PR=0.5478 ROC=0.8335 F1@0.5=0.5936\n","[Transformer/F4] Ep015 | PR=0.5631 ROC=0.8506 F1@0.5=0.6125\n","[Transformer/F4] Ep016 | PR=0.5630 ROC=0.8572 F1@0.5=0.6154\n","[Transformer/F4] Ep017 | PR=0.5699 ROC=0.8680 F1@0.5=0.6090\n","[Transformer/F4] Ep018 | PR=0.5758 ROC=0.8548 F1@0.5=0.6021\n","[Transformer/F4] Ep019 | PR=0.5951 ROC=0.8705 F1@0.5=0.6048\n","[Transformer/F4] Ep020 | PR=0.6271 ROC=0.8844 F1@0.5=0.6006\n","[Transformer/F4] Ep021 | PR=0.6245 ROC=0.8807 F1@0.5=0.6032\n","[Transformer/F4] Ep022 | PR=0.6381 ROC=0.8841 F1@0.5=0.6361\n","[Transformer/F4] Ep023 | PR=0.6286 ROC=0.8891 F1@0.5=0.6382\n","[Transformer/F4] Ep024 | PR=0.6251 ROC=0.8788 F1@0.5=0.6188\n","[Transformer/F4] Ep025 | PR=0.6561 ROC=0.8916 F1@0.5=0.6617\n","[Transformer/F4] Ep026 | PR=0.6502 ROC=0.8948 F1@0.5=0.6059\n","[Transformer/F4] Ep027 | PR=0.6646 ROC=0.8956 F1@0.5=0.6309\n","[Transformer/F4] Ep028 | PR=0.6693 ROC=0.8987 F1@0.5=0.6246\n","[Transformer/F4] Ep029 | PR=0.6752 ROC=0.9027 F1@0.5=0.6437\n","[Transformer/F4] Ep030 | PR=0.6825 ROC=0.9030 F1@0.5=0.6689\n","[Transformer/F4] Ep031 | PR=0.6712 ROC=0.8953 F1@0.5=0.6449\n","[Transformer/F4] Ep032 | PR=0.7125 ROC=0.9147 F1@0.5=0.6570\n","[Transformer/F4] Ep033 | PR=0.6914 ROC=0.9093 F1@0.5=0.6512\n","[Transformer/F4] Ep034 | PR=0.6991 ROC=0.9058 F1@0.5=0.6447\n","[Transformer/F4] Ep035 | PR=0.7163 ROC=0.9190 F1@0.5=0.6851\n","[Transformer/F4] Ep036 | PR=0.7312 ROC=0.9209 F1@0.5=0.6607\n","[Transformer/F4] Ep037 | PR=0.6890 ROC=0.9070 F1@0.5=0.6415\n","[Transformer/F4] Ep038 | PR=0.7341 ROC=0.9195 F1@0.5=0.6818\n","[Transformer/F4] Ep039 | PR=0.7285 ROC=0.9192 F1@0.5=0.6774\n","[Transformer/F4] Ep040 | PR=0.7249 ROC=0.9142 F1@0.5=0.6986\n","[Transformer/F4] Ep041 | PR=0.7409 ROC=0.9164 F1@0.5=0.6497\n","[Transformer/F4] Ep042 | PR=0.7234 ROC=0.9195 F1@0.5=0.6622\n","[Transformer/F4] Ep043 | PR=0.7526 ROC=0.9236 F1@0.5=0.7105\n","[Transformer/F4] Ep044 | PR=0.7257 ROC=0.9154 F1@0.5=0.6646\n","[Transformer/F4] Ep045 | PR=0.7562 ROC=0.9247 F1@0.5=0.6646\n","[Transformer/F4] Ep046 | PR=0.7615 ROC=0.9301 F1@0.5=0.6865\n","[Transformer/F4] Ep047 | PR=0.7453 ROC=0.9261 F1@0.5=0.7448\n","[Transformer/F4] Ep048 | PR=0.7677 ROC=0.9336 F1@0.5=0.7194\n","[Transformer/F4] Ep049 | PR=0.7350 ROC=0.9178 F1@0.5=0.7031\n","[Transformer/F4] Ep050 | PR=0.7793 ROC=0.9354 F1@0.5=0.6607\n","[Transformer/F4] Ep051 | PR=0.7551 ROC=0.9227 F1@0.5=0.7194\n","[Transformer/F4] Ep052 | PR=0.7499 ROC=0.9287 F1@0.5=0.7365\n","[Transformer/F4] Ep053 | PR=0.7788 ROC=0.9294 F1@0.5=0.7007\n","[Transformer/F4] Ep054 | PR=0.7988 ROC=0.9421 F1@0.5=0.7599\n","[Transformer/F4] Ep055 | PR=0.8063 ROC=0.9447 F1@0.5=0.6968\n","[Transformer/F4] Ep056 | PR=0.7727 ROC=0.9367 F1@0.5=0.7248\n","[Transformer/F4] Ep057 | PR=0.8074 ROC=0.9490 F1@0.5=0.7255\n","[Transformer/F4] Ep058 | PR=0.7924 ROC=0.9428 F1@0.5=0.7640\n","[Transformer/F4] Ep059 | PR=0.8040 ROC=0.9485 F1@0.5=0.7629\n","[Transformer/F4] Ep060 | PR=0.7792 ROC=0.9359 F1@0.5=0.7734\n","[Transformer/F4] Ep061 | PR=0.7763 ROC=0.9350 F1@0.5=0.7055\n","[Transformer/F4] Ep062 | PR=0.7929 ROC=0.9391 F1@0.5=0.7090\n","[Transformer/F4] Ep063 | PR=0.8143 ROC=0.9434 F1@0.5=0.7336\n","[Transformer/F4] Ep064 | PR=0.7938 ROC=0.9337 F1@0.5=0.7321\n","[Transformer/F4] Ep065 | PR=0.8182 ROC=0.9518 F1@0.5=0.7676\n","[Transformer/F4] Ep066 | PR=0.8066 ROC=0.9480 F1@0.5=0.7623\n","[Transformer/F4] Ep067 | PR=0.8189 ROC=0.9474 F1@0.5=0.7423\n","[Transformer/F4] Ep068 | PR=0.8387 ROC=0.9571 F1@0.5=0.7560\n","[Transformer/F4] Ep069 | PR=0.8224 ROC=0.9505 F1@0.5=0.7534\n","[Transformer/F4] Ep070 | PR=0.8388 ROC=0.9549 F1@0.5=0.7868\n","[Transformer/F4] Ep071 | PR=0.8353 ROC=0.9545 F1@0.5=0.7551\n","[Transformer/F4] Ep072 | PR=0.8090 ROC=0.9484 F1@0.5=0.7584\n","[Transformer/F4] Ep073 | PR=0.8257 ROC=0.9547 F1@0.5=0.7742\n","[Transformer/F4] Ep074 | PR=0.8170 ROC=0.9514 F1@0.5=0.7157\n","[Transformer/F4] Ep075 | PR=0.8265 ROC=0.9529 F1@0.5=0.7795\n","[Transformer/F4] Ep076 | PR=0.8218 ROC=0.9498 F1@0.5=0.7744\n","[Transformer/F4] Ep077 | PR=0.8301 ROC=0.9548 F1@0.5=0.7509\n","[Transformer/F4] Ep078 | PR=0.8475 ROC=0.9576 F1@0.5=0.8142\n","[Transformer/F4] Ep079 | PR=0.8132 ROC=0.9496 F1@0.5=0.7766\n","[Transformer/F4] Ep080 | PR=0.8161 ROC=0.9505 F1@0.5=0.7224\n","[Transformer/F4] Ep081 | PR=0.8557 ROC=0.9591 F1@0.5=0.7676\n","[Transformer/F4] Ep082 | PR=0.8159 ROC=0.9484 F1@0.5=0.7734\n","[Transformer/F4] Ep083 | PR=0.8449 ROC=0.9537 F1@0.5=0.7698\n","[Transformer/F4] Ep084 | PR=0.8177 ROC=0.9478 F1@0.5=0.7807\n","[Transformer/F4] Ep085 | PR=0.8320 ROC=0.9559 F1@0.5=0.7726\n","[Transformer/F4] Ep086 | PR=0.8294 ROC=0.9389 F1@0.5=0.7445\n","[Transformer/F4] Ep087 | PR=0.8567 ROC=0.9572 F1@0.5=0.8030\n","[Transformer/F4] Ep088 | PR=0.8639 ROC=0.9592 F1@0.5=0.7985\n","[Transformer/F4] Ep089 | PR=0.8282 ROC=0.9516 F1@0.5=0.8015\n","[Transformer/F4] Ep090 | PR=0.8271 ROC=0.9530 F1@0.5=0.7814\n","[Transformer/F4] Ep091 | PR=0.8570 ROC=0.9548 F1@0.5=0.7709\n","[Transformer/F4] Ep092 | PR=0.8178 ROC=0.9475 F1@0.5=0.7586\n","[Transformer/F4] Ep093 | PR=0.8382 ROC=0.9529 F1@0.5=0.7891\n","[Transformer/F4] Ep094 | PR=0.8630 ROC=0.9570 F1@0.5=0.7970\n","[Transformer/F4] Ep095 | PR=0.8706 ROC=0.9573 F1@0.5=0.8230\n","[Transformer/F4] Ep096 | PR=0.8346 ROC=0.9501 F1@0.5=0.7473\n","[Transformer/F4] Ep097 | PR=0.8427 ROC=0.9547 F1@0.5=0.7955\n","[Transformer/F4] Ep098 | PR=0.8448 ROC=0.9557 F1@0.5=0.7639\n","[Transformer/F4] Ep099 | PR=0.8476 ROC=0.9559 F1@0.5=0.7955\n","[Transformer/F4] Ep100 | PR=0.8634 ROC=0.9573 F1@0.5=0.7888\n","[Transformer/F4] Ep101 | PR=0.8567 ROC=0.9580 F1@0.5=0.7799\n","[Transformer/F4] Ep102 | PR=0.8528 ROC=0.9534 F1@0.5=0.7836\n","[Transformer/F4] Ep103 | PR=0.8354 ROC=0.9514 F1@0.5=0.7803\n","[Transformer/F4] Ep104 | PR=0.8296 ROC=0.9494 F1@0.5=0.7874\n","[Transformer/F4] Ep105 | PR=0.8428 ROC=0.9549 F1@0.5=0.8046\n","âœ… EarlyStopping (best Val PR-AUC=0.8706) [Transformer/F4]\n","[NNConv/F4] Ep001 | PR=0.3681 ROC=0.7182 F1@0.5=0.0168\n","[NNConv/F4] Ep002 | PR=0.3913 ROC=0.7507 F1@0.5=0.4612\n","[NNConv/F4] Ep003 | PR=0.4275 ROC=0.7557 F1@0.5=0.4709\n","[NNConv/F4] Ep004 | PR=0.4606 ROC=0.7825 F1@0.5=0.4615\n","[NNConv/F4] Ep005 | PR=0.4579 ROC=0.7779 F1@0.5=0.4970\n","[NNConv/F4] Ep006 | PR=0.4462 ROC=0.7818 F1@0.5=0.5040\n","[NNConv/F4] Ep007 | PR=0.4380 ROC=0.7824 F1@0.5=0.4983\n","[NNConv/F4] Ep008 | PR=0.4672 ROC=0.8010 F1@0.5=0.5109\n","[NNConv/F4] Ep009 | PR=0.4654 ROC=0.7939 F1@0.5=0.5382\n","[NNConv/F4] Ep010 | PR=0.4659 ROC=0.7999 F1@0.5=0.5318\n","[NNConv/F4] Ep011 | PR=0.4690 ROC=0.8133 F1@0.5=0.5080\n","[NNConv/F4] Ep012 | PR=0.4798 ROC=0.8089 F1@0.5=0.5260\n","[NNConv/F4] Ep013 | PR=0.4827 ROC=0.8094 F1@0.5=0.5382\n","[NNConv/F4] Ep014 | PR=0.4763 ROC=0.8078 F1@0.5=0.5329\n","[NNConv/F4] Ep015 | PR=0.4709 ROC=0.8085 F1@0.5=0.5105\n","[NNConv/F4] Ep016 | PR=0.4920 ROC=0.8204 F1@0.5=0.5040\n","[NNConv/F4] Ep017 | PR=0.4867 ROC=0.8133 F1@0.5=0.5333\n","[NNConv/F4] Ep018 | PR=0.4916 ROC=0.8166 F1@0.5=0.5150\n","[NNConv/F4] Ep019 | PR=0.4927 ROC=0.8178 F1@0.5=0.5270\n","[NNConv/F4] Ep020 | PR=0.5062 ROC=0.8241 F1@0.5=0.5298\n","[NNConv/F4] Ep021 | PR=0.4990 ROC=0.8252 F1@0.5=0.5260\n","[NNConv/F4] Ep022 | PR=0.5201 ROC=0.8279 F1@0.5=0.5369\n","[NNConv/F4] Ep023 | PR=0.5173 ROC=0.8291 F1@0.5=0.5108\n","[NNConv/F4] Ep024 | PR=0.5157 ROC=0.8351 F1@0.5=0.5299\n","[NNConv/F4] Ep025 | PR=0.5184 ROC=0.8363 F1@0.5=0.5471\n","[NNConv/F4] Ep026 | PR=0.5090 ROC=0.8386 F1@0.5=0.5696\n","[NNConv/F4] Ep027 | PR=0.5139 ROC=0.8375 F1@0.5=0.5578\n","[NNConv/F4] Ep028 | PR=0.5307 ROC=0.8522 F1@0.5=0.5798\n","[NNConv/F4] Ep029 | PR=0.5325 ROC=0.8446 F1@0.5=0.5705\n","[NNConv/F4] Ep030 | PR=0.5485 ROC=0.8539 F1@0.5=0.6061\n","[NNConv/F4] Ep031 | PR=0.5394 ROC=0.8537 F1@0.5=0.6062\n","[NNConv/F4] Ep032 | PR=0.5460 ROC=0.8550 F1@0.5=0.5905\n","[NNConv/F4] Ep033 | PR=0.5599 ROC=0.8387 F1@0.5=0.5461\n","[NNConv/F4] Ep034 | PR=0.5625 ROC=0.8612 F1@0.5=0.6319\n","[NNConv/F4] Ep035 | PR=0.5645 ROC=0.8607 F1@0.5=0.6006\n","[NNConv/F4] Ep036 | PR=0.5524 ROC=0.8475 F1@0.5=0.5817\n","[NNConv/F4] Ep037 | PR=0.5866 ROC=0.8640 F1@0.5=0.6231\n","[NNConv/F4] Ep038 | PR=0.6071 ROC=0.8709 F1@0.5=0.6288\n","[NNConv/F4] Ep039 | PR=0.5979 ROC=0.8663 F1@0.5=0.6055\n","[NNConv/F4] Ep040 | PR=0.6059 ROC=0.8750 F1@0.5=0.6181\n","[NNConv/F4] Ep041 | PR=0.6003 ROC=0.8674 F1@0.5=0.6306\n","[NNConv/F4] Ep042 | PR=0.6042 ROC=0.8705 F1@0.5=0.6261\n","[NNConv/F4] Ep043 | PR=0.6240 ROC=0.8779 F1@0.5=0.6494\n","[NNConv/F4] Ep044 | PR=0.6428 ROC=0.8827 F1@0.5=0.6454\n","[NNConv/F4] Ep045 | PR=0.6477 ROC=0.8888 F1@0.5=0.6572\n","[NNConv/F4] Ep046 | PR=0.6339 ROC=0.8831 F1@0.5=0.6528\n","[NNConv/F4] Ep047 | PR=0.6568 ROC=0.8926 F1@0.5=0.6667\n","[NNConv/F4] Ep048 | PR=0.6723 ROC=0.8901 F1@0.5=0.6667\n","[NNConv/F4] Ep049 | PR=0.6595 ROC=0.8888 F1@0.5=0.6254\n","[NNConv/F4] Ep050 | PR=0.6661 ROC=0.8922 F1@0.5=0.6573\n","[NNConv/F4] Ep051 | PR=0.6684 ROC=0.8928 F1@0.5=0.6689\n","[NNConv/F4] Ep052 | PR=0.6723 ROC=0.8870 F1@0.5=0.6566\n","[NNConv/F4] Ep053 | PR=0.6648 ROC=0.8924 F1@0.5=0.6667\n","[NNConv/F4] Ep054 | PR=0.6898 ROC=0.8983 F1@0.5=0.6713\n","[NNConv/F4] Ep055 | PR=0.6605 ROC=0.8926 F1@0.5=0.6622\n","[NNConv/F4] Ep056 | PR=0.6988 ROC=0.9021 F1@0.5=0.6781\n","[NNConv/F4] Ep057 | PR=0.6922 ROC=0.8996 F1@0.5=0.6780\n","[NNConv/F4] Ep058 | PR=0.6759 ROC=0.8980 F1@0.5=0.6735\n","[NNConv/F4] Ep059 | PR=0.6835 ROC=0.8943 F1@0.5=0.6532\n","[NNConv/F4] Ep060 | PR=0.7114 ROC=0.9077 F1@0.5=0.6871\n","[NNConv/F4] Ep061 | PR=0.7193 ROC=0.9099 F1@0.5=0.6873\n","[NNConv/F4] Ep062 | PR=0.7318 ROC=0.9108 F1@0.5=0.6776\n","[NNConv/F4] Ep063 | PR=0.6948 ROC=0.9015 F1@0.5=0.6690\n","[NNConv/F4] Ep064 | PR=0.7117 ROC=0.9092 F1@0.5=0.6765\n","[NNConv/F4] Ep065 | PR=0.7069 ROC=0.9057 F1@0.5=0.6766\n","[NNConv/F4] Ep066 | PR=0.7005 ROC=0.9064 F1@0.5=0.6667\n","[NNConv/F4] Ep067 | PR=0.7102 ROC=0.9048 F1@0.5=0.6623\n","[NNConv/F4] Ep068 | PR=0.7157 ROC=0.9070 F1@0.5=0.6871\n","[NNConv/F4] Ep069 | PR=0.7295 ROC=0.9122 F1@0.5=0.6801\n","[NNConv/F4] Ep070 | PR=0.7046 ROC=0.9086 F1@0.5=0.6906\n","[NNConv/F4] Ep071 | PR=0.7384 ROC=0.9157 F1@0.5=0.6855\n","[NNConv/F4] Ep072 | PR=0.7430 ROC=0.9159 F1@0.5=0.6776\n","[NNConv/F4] Ep073 | PR=0.7020 ROC=0.9039 F1@0.5=0.6739\n","[NNConv/F4] Ep074 | PR=0.7311 ROC=0.9133 F1@0.5=0.6960\n","[NNConv/F4] Ep075 | PR=0.7594 ROC=0.9222 F1@0.5=0.7138\n","[NNConv/F4] Ep076 | PR=0.7682 ROC=0.9272 F1@0.5=0.7092\n","[NNConv/F4] Ep077 | PR=0.7641 ROC=0.9229 F1@0.5=0.6879\n","[NNConv/F4] Ep078 | PR=0.7380 ROC=0.9156 F1@0.5=0.7037\n","[NNConv/F4] Ep079 | PR=0.7176 ROC=0.9077 F1@0.5=0.6494\n","[NNConv/F4] Ep080 | PR=0.7751 ROC=0.9280 F1@0.5=0.6939\n","[NNConv/F4] Ep081 | PR=0.7500 ROC=0.9202 F1@0.5=0.6915\n","[NNConv/F4] Ep082 | PR=0.7473 ROC=0.9162 F1@0.5=0.6920\n","[NNConv/F4] Ep083 | PR=0.7643 ROC=0.9237 F1@0.5=0.7033\n","[NNConv/F4] Ep084 | PR=0.7718 ROC=0.9281 F1@0.5=0.7206\n","[NNConv/F4] Ep085 | PR=0.7622 ROC=0.9222 F1@0.5=0.7088\n","[NNConv/F4] Ep086 | PR=0.7664 ROC=0.9251 F1@0.5=0.7159\n","[NNConv/F4] Ep087 | PR=0.7777 ROC=0.9301 F1@0.5=0.7232\n","[NNConv/F4] Ep088 | PR=0.8092 ROC=0.9385 F1@0.5=0.7148\n","[NNConv/F4] Ep089 | PR=0.8138 ROC=0.9410 F1@0.5=0.7574\n","[NNConv/F4] Ep090 | PR=0.8009 ROC=0.9336 F1@0.5=0.6908\n","[NNConv/F4] Ep091 | PR=0.7849 ROC=0.9316 F1@0.5=0.7088\n","[NNConv/F4] Ep092 | PR=0.8096 ROC=0.9396 F1@0.5=0.7108\n","[NNConv/F4] Ep093 | PR=0.7818 ROC=0.9324 F1@0.5=0.6947\n","[NNConv/F4] Ep094 | PR=0.7913 ROC=0.9305 F1@0.5=0.7234\n","[NNConv/F4] Ep095 | PR=0.8129 ROC=0.9380 F1@0.5=0.7095\n","[NNConv/F4] Ep096 | PR=0.8102 ROC=0.9408 F1@0.5=0.7228\n","[NNConv/F4] Ep097 | PR=0.7714 ROC=0.9303 F1@0.5=0.7076\n","[NNConv/F4] Ep098 | PR=0.8159 ROC=0.9436 F1@0.5=0.7410\n","[NNConv/F4] Ep099 | PR=0.8022 ROC=0.9393 F1@0.5=0.7343\n","[NNConv/F4] Ep100 | PR=0.8060 ROC=0.9404 F1@0.5=0.7500\n","[NNConv/F4] Ep101 | PR=0.8202 ROC=0.9431 F1@0.5=0.7234\n","[NNConv/F4] Ep102 | PR=0.8477 ROC=0.9511 F1@0.5=0.7554\n","[NNConv/F4] Ep103 | PR=0.8380 ROC=0.9460 F1@0.5=0.7247\n","[NNConv/F4] Ep104 | PR=0.7842 ROC=0.9281 F1@0.5=0.7068\n","[NNConv/F4] Ep105 | PR=0.8323 ROC=0.9475 F1@0.5=0.7619\n","[NNConv/F4] Ep106 | PR=0.8498 ROC=0.9492 F1@0.5=0.7491\n","[NNConv/F4] Ep107 | PR=0.8699 ROC=0.9553 F1@0.5=0.7423\n","[NNConv/F4] Ep108 | PR=0.8480 ROC=0.9506 F1@0.5=0.7463\n","[NNConv/F4] Ep109 | PR=0.8564 ROC=0.9527 F1@0.5=0.7681\n","[NNConv/F4] Ep110 | PR=0.8631 ROC=0.9525 F1@0.5=0.7345\n","[NNConv/F4] Ep111 | PR=0.8564 ROC=0.9534 F1@0.5=0.7571\n","[NNConv/F4] Ep112 | PR=0.8557 ROC=0.9513 F1@0.5=0.7518\n","[NNConv/F4] Ep113 | PR=0.8338 ROC=0.9476 F1@0.5=0.7552\n","[NNConv/F4] Ep114 | PR=0.8538 ROC=0.9518 F1@0.5=0.7407\n","[NNConv/F4] Ep115 | PR=0.8764 ROC=0.9589 F1@0.5=0.7692\n","[NNConv/F4] Ep116 | PR=0.8427 ROC=0.9490 F1@0.5=0.7619\n","[NNConv/F4] Ep117 | PR=0.8518 ROC=0.9524 F1@0.5=0.7574\n","[NNConv/F4] Ep118 | PR=0.8823 ROC=0.9588 F1@0.5=0.7726\n","[NNConv/F4] Ep119 | PR=0.8069 ROC=0.9407 F1@0.5=0.7546\n","[NNConv/F4] Ep120 | PR=0.8188 ROC=0.9458 F1@0.5=0.7317\n","[NNConv/F4] Ep121 | PR=0.8416 ROC=0.9502 F1@0.5=0.7279\n","[NNConv/F4] Ep122 | PR=0.8683 ROC=0.9587 F1@0.5=0.7833\n","[NNConv/F4] Ep123 | PR=0.8189 ROC=0.9411 F1@0.5=0.7537\n","[NNConv/F4] Ep124 | PR=0.8452 ROC=0.9504 F1@0.5=0.7704\n","[NNConv/F4] Ep125 | PR=0.8525 ROC=0.9553 F1@0.5=0.7879\n","[NNConv/F4] Ep126 | PR=0.8839 ROC=0.9637 F1@0.5=0.7897\n","[NNConv/F4] Ep127 | PR=0.8847 ROC=0.9616 F1@0.5=0.7766\n","[NNConv/F4] Ep128 | PR=0.8638 ROC=0.9562 F1@0.5=0.7596\n","[NNConv/F4] Ep129 | PR=0.8553 ROC=0.9536 F1@0.5=0.7790\n","[NNConv/F4] Ep130 | PR=0.8837 ROC=0.9608 F1@0.5=0.7571\n","[NNConv/F4] Ep131 | PR=0.8644 ROC=0.9583 F1@0.5=0.8092\n","[NNConv/F4] Ep132 | PR=0.8744 ROC=0.9617 F1@0.5=0.7857\n","[NNConv/F4] Ep133 | PR=0.8741 ROC=0.9623 F1@0.5=0.7940\n","[NNConv/F4] Ep134 | PR=0.8846 ROC=0.9629 F1@0.5=0.7798\n","[NNConv/F4] Ep135 | PR=0.8866 ROC=0.9615 F1@0.5=0.7914\n","[NNConv/F4] Ep136 | PR=0.8691 ROC=0.9533 F1@0.5=0.7574\n","[NNConv/F4] Ep137 | PR=0.8890 ROC=0.9630 F1@0.5=0.7855\n","[NNConv/F4] Ep138 | PR=0.8637 ROC=0.9585 F1@0.5=0.7735\n","[NNConv/F4] Ep139 | PR=0.8885 ROC=0.9655 F1@0.5=0.7839\n","[NNConv/F4] Ep140 | PR=0.8835 ROC=0.9649 F1@0.5=0.7985\n","[NNConv/F4] Ep141 | PR=0.8949 ROC=0.9642 F1@0.5=0.7703\n","[NNConv/F4] Ep142 | PR=0.8996 ROC=0.9673 F1@0.5=0.8137\n","[NNConv/F4] Ep143 | PR=0.8832 ROC=0.9647 F1@0.5=0.7766\n","[NNConv/F4] Ep144 | PR=0.8842 ROC=0.9611 F1@0.5=0.7732\n","[NNConv/F4] Ep145 | PR=0.8978 ROC=0.9674 F1@0.5=0.7829\n","[NNConv/F4] Ep146 | PR=0.8700 ROC=0.9587 F1@0.5=0.7754\n","[NNConv/F4] Ep147 | PR=0.8744 ROC=0.9617 F1@0.5=0.7817\n","[NNConv/F4] Ep148 | PR=0.9027 ROC=0.9687 F1@0.5=0.7941\n","[NNConv/F4] Ep149 | PR=0.8896 ROC=0.9637 F1@0.5=0.8000\n","[NNConv/F4] Ep150 | PR=0.9090 ROC=0.9684 F1@0.5=0.8077\n","[NNConv/F4] Ep151 | PR=0.8956 ROC=0.9660 F1@0.5=0.8000\n","[NNConv/F4] Ep152 | PR=0.9017 ROC=0.9670 F1@0.5=0.7929\n","[NNConv/F4] Ep153 | PR=0.8915 ROC=0.9690 F1@0.5=0.8148\n","[NNConv/F4] Ep154 | PR=0.9074 ROC=0.9697 F1@0.5=0.7912\n","[NNConv/F4] Ep155 | PR=0.8826 ROC=0.9622 F1@0.5=0.7857\n","[NNConv/F4] Ep156 | PR=0.8776 ROC=0.9646 F1@0.5=0.7849\n","[NNConv/F4] Ep157 | PR=0.8739 ROC=0.9607 F1@0.5=0.7560\n","[NNConv/F4] Ep158 | PR=0.8752 ROC=0.9639 F1@0.5=0.7852\n","[NNConv/F4] Ep159 | PR=0.8862 ROC=0.9653 F1@0.5=0.8030\n","[NNConv/F4] Ep160 | PR=0.9021 ROC=0.9703 F1@0.5=0.8060\n","âœ… EarlyStopping (best Val PR-AUC=0.9090) [NNConv/F4]\n","â­ Fold4 best Î±=0.40 (Val PR-AUC=0.9371 [weighted])\n","âœ… Fold4 [Transformer] ROC=0.8017 PR=0.5908 F1=0.5199\n","âœ… Fold4 [NNConv]      ROC=0.8233 PR=0.6352 F1=0.6080\n","âœ… Fold4 [Ensemble]    ROC=0.8432 PR=0.6595 F1=0.5801\n","\n","ğŸ‰ LCO-CV å®Œäº†ï¼\n","å¹³å‡å€¤: {'Transformer_ROC': 0.8101838293366385, 'Transformer_PR': 0.5660193499913062, 'Transformer_F1': 0.548024225723031, 'NNConv_ROC': 0.8083624470755968, 'NNConv_PR': 0.6028363126928153, 'NNConv_F1': 0.5595179588844188, 'Ensemble_ROC': 0.8399798072395115, 'Ensemble_PR': 0.6185174288319562, 'Ensemble_F1': 0.5573196322265673}\n","æ¨™æº–åå·®: {'Transformer_ROC': 0.027973505472222156, 'Transformer_PR': 0.03714954899622764, 'Transformer_F1': 0.035972155025195934, 'NNConv_ROC': 0.02669756533697697, 'NNConv_PR': 0.027035299797037154, 'NNConv_F1': 0.043037282896615, 'Ensemble_ROC': 0.026103957118230322, 'Ensemble_PR': 0.03513740832306142, 'Ensemble_F1': 0.04464054237757197}\n","Î±* [0.4, 0.8, 0.4, 0.5, 0.4]\n","ä¿å­˜: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/results_lco5_trans_nn_ens_posaug_advanced/lco_cv_metrics_butina_t0.7.csv\n"]}]},{"cell_type":"markdown","source":["ãƒ¢ãƒ‡ãƒ«å®šç¾©\n","\n","| ãƒ¢ãƒ‡ãƒ«ID | åç§°/ç›®çš„                                            | å…¥åŠ›ç‰¹å¾´                                 | å­¦ç¿’/åˆ†å‰²                                                                                                                                                                              | æ—©æœŸåœæ­¢ãƒ»æœ€é©åŒ–                                                                                                                           | ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿                                                              | ãƒ‡ãƒ¼ã‚¿å…¥å‡ºåŠ›                                                                                                                                    |\n","| ----- | ------------------------------------------------ | ------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------- |\n","| M1    | TransformerConv + NNConv ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆæ¨™æº–5-foldï¼‰        | `d.x + d.g + d.r` ï¼‹ `edge_attr`ï¼ˆPyGï¼‰ | Stratified 5-fold CV                                                                                                                                                               | BCEWithLogits(+`pos_weight`<10) / AdamW(LR=3e-4, WD=1e-4) / CosineAnnealing(T_max=10) / å‹¾é…ã‚¯ãƒªãƒƒãƒ—=5 / **Val ROC-AUC**ã§æ—©åœï¼ˆpatience=10ï¼‰ | **å„foldã®æ¤œè¨¼PR-AUCã§æ­£è¦åŒ–ã—ãŸä¿‚æ•°**ã§**ãƒ­ã‚¸ãƒƒãƒˆ**åŠ é‡ï¼ˆTransformer/NNConvï¼‰             | å…¥åŠ›ï¼š`/.../data_graph_with_smiles.pt` å‡ºåŠ›ï¼š`/.../results_ens_trans_nn_5fold/`ï¼ˆå„foldãƒ¢ãƒ‡ãƒ«ãƒ»å±¥æ­´CSVãƒ»ROC/PRå›³ã€é›†è¨ˆCSV3ç¨®ï¼‰                                 |\n","| M2    | TransformerConv + NNConv ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆScaffold 5-foldï¼‰ | åŒä¸Š                                   | **Murcko Scaffold 5-fold**ï¼ˆç‹¬è‡ªsplitï¼‰                                                                                                                                                | AdamW(LR=3e-4, WD=1e-4) / Cosine(T_max=20) / ã‚¯ãƒªãƒƒãƒ—=5 / **Val ROC-AUC**ã§æ—©åœï¼ˆpatience=15ï¼‰                                              | **æ¤œè¨¼PR-AUCã‚’é‡ã¿**ã¨ã—ã¦**ãƒ­ã‚¸ãƒƒãƒˆ**åŠ é‡ï¼ˆfoldã”ã¨ã«wã‚’æ­£è¦åŒ–ï¼‰                            | å…¥åŠ›ï¼š`/.../data_graph_with_smiles.pt` å‡ºåŠ›ï¼š`/.../results_ens_trans_nn_scaffold5fold/`ï¼ˆfoldåˆ¥ãƒ¢ãƒ‡ãƒ«ãƒ»å­¦ç¿’æ›²ç·šãƒ»ROC/PRå›³ãƒ»çµæœCSVï¼‰                            |\n","| M3    | TransformerConv + NNConv ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆ**LCO-CV** åŸºæœ¬å½¢ï¼‰  | åŒä¸Š                                   | **LCO-CV K=5**ï¼ˆKMeans(ECFP4)ã‚¯ãƒ©ã‚¹ã‚¿ï¼‰/ **é™½æ€§ãŒå°‘ãªã„æ™‚ã®ã¿** SMILESãƒ©ãƒ³ãƒ€ãƒ åŒ–ã§**é™½æ€§ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒ«**ï¼ˆä¸Šé™3/åˆ†å­ã€ç›®æ¨™é™½æ€§ç‡0.30ï¼‰                                                                                      | AdamW(LR=3e-4, WD=1e-4) / Cosine(T_max=20) / ã‚¯ãƒªãƒƒãƒ—=5 / **Val ROC-AUC**ã§æ—©åœï¼ˆpatience=10ï¼‰                                              | **Val PR-AUCæœ€å¤§åŒ–**ã¨ãªã‚‹Î±âˆˆ{0,0.1,â€¦,1}ã‚’æ¢ç´¢ã—ã€**ç¢ºç‡**ã‚’Î±ã§ç·šå½¢çµåˆï¼ˆãƒ†ã‚¹ãƒˆã‚‚**ç¢ºç‡**ã‚’åŒÎ±ã§åˆæˆï¼‰ | å…¥åŠ›ï¼š`/.../data_graph_with_smiles.pt` å‡ºåŠ›ï¼š`/.../results_lco5_trans_nn_ens_posaug/`ï¼ˆ`lco_cv_metrics_trans_nn_ensemble.csv` ã»ã‹ï¼‰                |\n","| M4    | **Advanced LCO-CV**ï¼ˆé«˜æ¬¡ã‚¯ãƒ©ã‚¹ã‚¿ï¼‹åˆ¶ç´„ä»˜ãfoldå‰²å½“ï¼‰           | åŒä¸Š                                   | **ã‚¯ãƒ©ã‚¹ã‚¿æ–¹å¼ã‚’é¸æŠ**ï¼šButina(Tanimotoâ‰¥0.7) / K-Medoids(Tanimoto) / Murcko+ã‚µãƒ–ã‚¯ãƒ©ã‚¹ã‚¿ï¼ˆmin=10, kâ‰¤5ï¼‰ã€‚**foldåˆ¶ç´„**ï¼šå„foldã®æœ€å°Pos/Negï¼ˆãƒ‡ãƒ•ã‚©10/10ï¼‰ã‚’æº€ãŸã™ã‚ˆã†ã‚¯ãƒ©ã‚¹ã‚¿æ¢±åŒ…ï¼‹æ®µéšçš„ç·©å’Œã€‚ã‚ªãƒ¼ãƒãƒ¼ã‚µãƒ³ãƒ—ãƒ«ã¯**é™½æ€§ã®å˜ç´”è¤‡è£½**ï¼ˆSMILESãƒ©ãƒ³ãƒ€ãƒ åŒ–ã¯ã—ãªã„ï¼‰ | AdamW(LR=3e-4, WD=1e-4) / **Val PR-AUCã§æ—©åœ**ï¼ˆpatience=10ï¼‰ / ã‚¯ãƒªãƒƒãƒ—=5                                                                  | **Val PR-AUCæœ€å¤§**ã¨ãªã‚‹Î±ã‚’æ¢ç´¢ã—ã€**ç¢ºç‡**ã‚’Î±ã§åˆæˆï¼ˆãƒ†ã‚¹ãƒˆã‚‚åŒÎ±ï¼‰                          | å…¥åŠ›ï¼š`/.../data_graph_with_smiles.pt` å‡ºåŠ›ï¼š`/.../results_lco5_trans_nn_ens_posaug_advanced/`ï¼ˆã‚¯ãƒ©ã‚¹ã‚¿å‰²å½“CSVãƒ»foldã‚µãƒãƒªãƒ»`lco_cv_metrics_{method}.csv`ï¼‰ |"],"metadata":{"id":"uuWlnA2X3qSp"}},{"cell_type":"code","source":["# ===== External Evaluation (ver7; uses provided 'tier' column & drops unknown rows) =====\n","# - external10_union.csv ã® 'tier' ã¨ 'y' ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆunknownã¯é™¤å¤–ï¼‰\n","# - KEGG-only å´ã¯å¾“æ¥é€šã‚Šå¯¾å¿œï¼ˆtier ãŒç„¡ã‘ã‚Œã° weak_pos æ¨å®šï¼‰\n","# - å‡ºåŠ›: external_eval_comparison_all.csv / external_eval_ranking.csv\n","# - æŒ‡æ¨™: overall + Strong-only + Weak-onlyï¼ˆPR/ROC/F1/BestThr, Weak P@Kï¼‰\n","# ----------------------------------------------------------------------------------------\n","import os, glob, itertools, numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F\n","from pathlib import Path\n","from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, f1_score\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.exceptions import UndefinedMetricWarning\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","from rdkit import RDLogger\n","RDLogger.DisableLog(\"rdApp.warning\")\n","\n","# ===== Paths =====\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","M1_DIR = f\"{ROOT}/results_ens_trans_nn_5fold\"\n","M2_DIR = f\"{ROOT}/results_ens_trans_nn_scaffold5fold\"\n","M3_DIR = f\"{ROOT}/results_lco5_trans_nn_ens_posaug\"\n","M4_DIR = f\"{ROOT}/results_lco5_trans_nn_ens_posaug_advanced\"\n","TRAIN_CSV        = f\"{ROOT}/train_split.csv\"               # for g/r standardization\n","EXT_UNION_CSV    = f\"{ROOT}/external10_union.csv\"\n","EXT_KEGG_CSV     = f\"{ROOT}/external10_kegg_only.csv\"\n","EXT_UNION_GRAPHS = f\"{ROOT}/external10_union_graphs.pt\"\n","EXT_KEGG_GRAPHS  = f\"{ROOT}/external10_kegg_only_graphs.pt\"\n","BATCH = 256\n","P_AT_K = [10,25,50,100]\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","os.makedirs(ROOT, exist_ok=True)\n","\n","# ===== RDKit / PyG =====\n","try:\n","    from rdkit import Chem\n","    from rdkit.Chem import Descriptors\n","    from rdkit.Chem import rdMolDescriptors as rdMD\n","    from rdkit.Chem import rdchem\n","except Exception:\n","    import sys, subprocess\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit-pypi\"])\n","    from rdkit import Chem\n","    from rdkit.Chem import Descriptors\n","    from rdkit.Chem import rdMolDescriptors as rdMD\n","    from rdkit import rdBase; rdBase.DisableLog('rdApp.error')\n","    from rdkit.Chem import rdchem\n","\n","try:\n","    from torch_geometric.loader import DataLoader\n","    from torch_geometric.data import Data\n","    from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","    from torch.serialization import add_safe_globals\n","except Exception:\n","    import sys, subprocess\n","    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-geometric\"])\n","    from torch_geometric.loader import DataLoader\n","    from torch_geometric.data import Data\n","    from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","    from torch.serialization import add_safe_globals\n","\n","# ===== ver7 features =====\n","def gfeat7(mol):\n","    from rdkit.Chem import Descriptors\n","    return [\n","        Descriptors.MolWt(mol),\n","        Descriptors.MolLogP(mol),\n","        Descriptors.NumHDonors(mol),\n","        Descriptors.NumHAcceptors(mol),\n","        Descriptors.TPSA(mol),\n","        Descriptors.HeavyAtomCount(mol),\n","        Descriptors.RingCount(mol),\n","    ]\n","\n","def rdesc10(mol):\n","    from rdkit.Chem import Descriptors\n","    return [\n","        Descriptors.FpDensityMorgan1(mol),\n","        Descriptors.FpDensityMorgan2(mol),\n","        Descriptors.FpDensityMorgan3(mol),\n","        Descriptors.NumAliphaticRings(mol),\n","        Descriptors.NumAromaticRings(mol),\n","        Descriptors.NumRotatableBonds(mol),\n","        Descriptors.NumValenceElectrons(mol),\n","        Descriptors.BalabanJ(mol),\n","        Descriptors.BertzCT(mol),\n","        Descriptors.FractionCSP3(mol),\n","    ]\n","\n","from rdkit.Chem import rdchem\n","def atom_f(atom: rdchem.Atom):\n","    return torch.tensor([\n","        atom.GetAtomicNum(),\n","        atom.GetTotalDegree(),\n","        atom.GetFormalCharge(),\n","        float(atom.GetIsAromatic()),\n","        atom.GetTotalNumHs(includeNeighbors=True),\n","    ], dtype=torch.float32)\n","\n","def bond_f(bond: rdchem.Bond):\n","    return torch.tensor([\n","        bond.GetBondTypeAsDouble(),\n","        float(bond.GetIsConjugated()),\n","        float(bond.IsInRing()),\n","        int(bond.GetStereo()),\n","        bond.GetBeginAtom().GetAtomicNum(),\n","        bond.GetEndAtom().GetAtomicNum(),\n","    ], dtype=torch.float32)\n","\n","# ===== StandardScaler (g/r) fitted on train_split.csv =====\n","def fit_gr_scalers(train_csv):\n","    if not Path(train_csv).exists():\n","        print(f\"[WARN] train_split.csv not found. Skip standardization for g/r.\")\n","        return None, None\n","    tdf = pd.read_csv(train_csv)\n","    if \"SMILES\" not in tdf.columns:\n","        print(\"[WARN] train_split.csv lacks SMILES. Skip g/r standardization.\")\n","        return None, None\n","    tdf = tdf[(tdf[\"SMILES\"].notna()) & (tdf[\"SMILES\"]!=\"\")]\n","    g_raw, r_raw = [], []\n","    for sm in tdf[\"SMILES\"]:\n","        m = Chem.MolFromSmiles(str(sm))\n","        if m is None or m.GetNumAtoms()==0: continue\n","        g_raw.append(gfeat7(m)); r_raw.append(rdesc10(m))\n","    if not g_raw or not r_raw:\n","        print(\"[WARN] No valid g/r to fit. Skip standardization.\")\n","        return None, None\n","    sg = StandardScaler().fit(np.asarray(g_raw, dtype=np.float32))\n","    sr = StandardScaler().fit(np.asarray(r_raw, dtype=np.float32))\n","    print(f\"[INFO] StandardScaler fitted: g(7), r(10) from train_split.csv (n={len(g_raw)})\")\n","    return sg, sr\n","\n","_SCALER_G, _SCALER_R = fit_gr_scalers(TRAIN_CSV)\n","\n","# ===== CSVâ†’PyGï¼ˆprovided tier ã‚’ä½¿ç”¨; unknown ã¯ y ã‚’ -1 ã«ã—ã¦å¾Œã§é™¤å¤–ï¼‰ =====\n","def _norm_tier(val):\n","    if val is None: return \"\"\n","    s = str(val).strip().lower()\n","    mapping = {\n","        \"strongpos\":\"strong_pos\",\"strong+\":\"strong_pos\",\"s_pos\":\"strong_pos\",\n","        \"strongneg\":\"strong_neg\",\"strong-\":\"strong_neg\",\"s_neg\":\"strong_neg\",\n","        \"weakpos\":\"weak_pos\",\"weak+\":\"weak_pos\",\"w_pos\":\"weak_pos\",\n","        \"unknown\":\"unknown\",\"unk\":\"unknown\",\"\": \"\"\n","    }\n","    return mapping.get(s, s)\n","\n","def _pick_smiles_from_row(row):\n","    for key in (\"SMILES\",\"SMILES_aid\",\"SMILES_kegg\"):\n","        if key in row and pd.notna(row[key]):\n","            sm = str(row[key]).strip()\n","            if sm and sm.lower() not in {\"nan\",\"none\",\"null\"}:\n","                return sm\n","    for k,v in row.items():\n","        if \"smiles\" in str(k).lower():\n","            sm = str(v).strip()\n","            if sm and sm.lower() not in {\"nan\",\"none\",\"null\"}:\n","                return sm\n","    return None\n","\n","def _csv_role_from_name(path):\n","    name = os.path.basename(path).lower()\n","    return \"kegg_only\" if (\"kegg\" in name and \"only\" in name) else \"union\"\n","\n","def _tier_for_row(row, role):\n","    if \"tier\" in row and pd.notna(row[\"tier\"]):\n","        return _norm_tier(row[\"tier\"])\n","    # äºˆå‚™: KEGG-only ã¯ weak_pos ã¨ã™ã‚‹\n","    if role == \"kegg_only\":\n","        return \"weak_pos\"\n","    return \"unknown\"\n","\n","def smiles_to_data_ver7(smi, y_val, tier_val):\n","    m = Chem.MolFromSmiles(smi)\n","    if m is None or m.GetNumAtoms()==0: return None\n","    if m.GetNumBonds()==0: return None\n","\n","    x = torch.stack([atom_f(a) for a in m.GetAtoms()])\n","    src, dst, eattr = [], [], []\n","    for b in m.GetBonds():\n","        i, j = b.GetBeginAtomIdx(), b.GetEndAtomIdx()\n","        f = bond_f(b)\n","        src += [i, j]; dst += [j, i]; eattr += [f, f]\n","    edge_index = torch.tensor([src, dst], dtype=torch.long)\n","    edge_attr  = torch.stack(eattr)\n","\n","    g_vec = np.asarray(gfeat7(m), dtype=np.float32).reshape(1, -1)\n","    r_vec = np.asarray(rdesc10(m), dtype=np.float32).reshape(1, -1)\n","    if _SCALER_G is not None and _SCALER_R is not None:\n","        g_vec = _SCALER_G.transform(g_vec); r_vec = _SCALER_R.transform(r_vec)\n","    g = torch.tensor(g_vec, dtype=torch.float32)\n","    r = torch.tensor(r_vec, dtype=torch.float32)\n","\n","    # y: 0/1 ã¯ãã®ã¾ã¾ã€‚æ¬ æã‚„ unknown ã¯ -1ï¼ˆå¾Œæ®µã§é™¤å¤–ï¼‰\n","    y = -1\n","    if y_val is not None:\n","        try:\n","            y_i = int(float(y_val))\n","            if y_i in (0,1): y = y_i\n","        except Exception:\n","            pass\n","\n","    d = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=torch.tensor(y, dtype=torch.long))\n","    d.g = g; d.r = r; d.smiles = smi; d.tier = _norm_tier(tier_val)\n","    return d\n","\n","def csv_to_graphs_ver7(csv_path, out_pt_path):\n","    role = _csv_role_from_name(csv_path)\n","    df = pd.read_csv(csv_path)\n","    if \"y\" not in df.columns: df[\"y\"] = np.nan\n","    if \"tier\" not in df.columns: df[\"tier\"] = np.nan\n","\n","    graphs = []; miss = 0\n","    for _, row in df.iterrows():\n","        smi = _pick_smiles_from_row(row)\n","        if not smi: miss += 1; continue\n","        tier = _tier_for_row(row, role)\n","        d = smiles_to_data_ver7(smi, row[\"y\"], tier)\n","        if d is not None: graphs.append(d)\n","\n","    torch.save(graphs, out_pt_path)\n","    print(f\"âœ… Saved graphs: {out_pt_path}  (n={len(graphs)})\")\n","\n","    # ä»¶æ•°ã‚µãƒãƒªï¼ˆunknown/y=-1 ã‚’æŠŠæ¡ï¼‰\n","    ys = np.array([int(getattr(d,\"y\",-1)) for d in graphs])\n","    ts = np.array([getattr(d,\"tier\",\"\") for d in graphs], dtype=object)\n","    from collections import Counter\n","    print(f\"[SUMMARY] {os.path.basename(csv_path)} | y=1:{(ys==1).sum()}, y=0:{(ys==0).sum()}, y=-1:{(ys==-1).sum()}\")\n","    print(f\"[SUMMARY] {os.path.basename(csv_path)} | tier: {dict(Counter(ts))}\")\n","    return graphs\n","\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception:\n","        pass\n","    obj=torch.load(path,map_location=\"cpu\")\n","    if isinstance(obj,list): return obj\n","    if isinstance(obj,dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","def load_or_build(csv_path, pt_path, force_rebuild=False):\n","    if force_rebuild or (not Path(pt_path).exists()):\n","        return csv_to_graphs_ver7(csv_path, pt_path)\n","    return load_pyg_list(pt_path)\n","\n","# ===== Extractors (unknownã¯ã“ã“ã§é™¤å¤–) =====\n","def valid_mask(data_list):\n","    ys = np.array([int(getattr(d,\"y\",-1)) for d in data_list])\n","    return (ys == 0) | (ys == 1)\n","\n","def extract_labels(data_list, mask):\n","    ys=[]\n","    for i,d in enumerate(data_list):\n","        if not mask[i]: continue\n","        ys.append(int(getattr(d,\"y\",-1)))\n","    return np.array(ys, dtype=int)\n","\n","def extract_tiers(data_list, mask):\n","    out=[]\n","    for i,d in enumerate(data_list):\n","        if not mask[i]: continue\n","        out.append(str(getattr(d,\"tier\",\"\")).lower())\n","    return np.array(out, dtype=object)\n","\n","# ===== Models =====\n","def make_edge_mlp(in_attr_dim,out_channels,in_channels):\n","    hidden=max(64,min(256,in_attr_dim*8))\n","    return nn.Sequential(nn.Linear(in_attr_dim,hidden), nn.ReLU(),\n","                         nn.Linear(hidden,in_channels*out_channels))\n","\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        self.c1=TransformerConv(X_DIM,HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.c2=TransformerConv(HID, HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1)); self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr)); x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g; r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        edge_nn1=make_edge_mlp(E_DIM,HID,X_DIM); edge_nn2=make_edge_mlp(E_DIM,HID,HID)\n","        self.c1=NNConv(X_DIM,HID,edge_nn1,aggr='mean'); self.c2=NNConv(HID, HID,edge_nn2,aggr='mean')\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1)); self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr)); x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g; r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","# ===== Weights & CV-PR weight =====\n","def list_weight_files(folder, patterns):\n","    files=[]\n","    for pat in patterns: files += sorted(glob.glob(os.path.join(folder, pat)))\n","    return files\n","\n","def family_defs():\n","    return {\n","      \"M1\":{\"dir\":M1_DIR,\"transformer\":list_weight_files(M1_DIR,[\"transformer_fold*.pt\"]),\n","            \"nnconv\":list_weight_files(M1_DIR,[\"nnconv_fold*.pt\"]),\n","            \"val_csvs\":list_weight_files(M1_DIR,[\"*cv*results*.csv\",\"*combined*.csv\"])},\n","      \"M2\":{\"dir\":M2_DIR,\"transformer\":list_weight_files(M2_DIR,[\"transformer_fold*.pt\",\"*trans*fold*.pt\"]),\n","            \"nnconv\":list_weight_files(M2_DIR,[\"nnconv_fold*.pt\",\"*nn*fold*.pt\"]),\n","            \"val_csvs\":list_weight_files(M2_DIR,[\"cv_results_*.csv\",\"*combined*.csv\",\"*results*.csv\"])},\n","      \"M3\":{\"dir\":M3_DIR,\"transformer\":list_weight_files(M3_DIR,[\"trans_fold*.pt\",\"*trans*fold*.pt\",\"transformer_fold*.pt\"]),\n","            \"nnconv\":list_weight_files(M3_DIR,[\"nnconv_fold*.pt\",\"*nn*fold*.pt\"]),\n","            \"val_csvs\":list_weight_files(M3_DIR,[\"lco_cv_metrics_*.csv\",\"*ensemble*.csv\",\"*cv*.csv\"])},\n","      \"M4\":{\"dir\":M4_DIR,\"transformer\":list_weight_files(M4_DIR,[\"*trans*fold*.pt\",\"transformer_fold*.pt\"]),\n","            \"nnconv\":list_weight_files(M4_DIR,[\"*nn*fold*.pt\",\"nnconv_fold*.pt\"]),\n","            \"val_csvs\":list_weight_files(M4_DIR,[\"lco_cv_metrics_*.csv\",\"*cv*.csv\"])},\n","    }\n","\n","def infer_weights_from_val_csv(csv_paths):\n","    if not csv_paths: return None\n","    try:\n","        prs=[]\n","        for p in csv_paths:\n","            df=pd.read_csv(p)\n","            for c in [\"PR-AUC\",\"Ensemble_PR\",\"PR\",\"Val PR-AUC\",\"Ensemble_PR:\"]:\n","                if c in df.columns:\n","                    s=pd.to_numeric(df[c], errors=\"coerce\")\n","                    prs += s[~s.isna()].tolist()\n","        if prs: return float(np.nanmean(prs))\n","    except Exception: pass\n","    return None\n","\n","def fold_key_from_path(path):\n","    import re, os\n","    bn=os.path.basename(path)\n","    for tok in bn.replace(\".pt\",\"\").replace(\"-\",\"_\").split(\"_\"):\n","        if tok.lower().startswith(\"fold\"):\n","            try: return int(tok.lower().replace(\"fold\",\"\"))\n","            except: pass\n","    m=re.findall(r\"(\\d+)\", bn)\n","    return int(m[-1]) if m else -1\n","\n","@torch.no_grad()\n","def predict_family_probs(fid, dims, data_list):\n","    fam=family_defs()[fid]; X_DIM,G_DIM,R_DIM,E_DIM = dims[\"x\"],dims[\"g\"],dims[\"r\"],dims[\"edge\"]\n","    tr_files=fam[\"transformer\"]; nn_files=fam[\"nnconv\"]\n","    tr_map={fold_key_from_path(p):p for p in tr_files}\n","    nn_map={fold_key_from_path(p):p for p in nn_files}\n","    fold_ids=sorted(set(list(tr_map.keys())+list(nn_map.keys())))\n","    if not fold_ids: raise RuntimeError(f\"No weight files for {fid} in {fam['dir']}\")\n","    dl=DataLoader(data_list, batch_size=BATCH, shuffle=False)\n","    fold_probs=[]\n","    for f in fold_ids:\n","        probs=[]\n","        if f in tr_map:\n","            m=Transformer_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE); m.load_state_dict(torch.load(tr_map[f], map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if f in nn_map:\n","            m=NNConv_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE); m.load_state_dict(torch.load(nn_map[f], map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if probs: fold_probs.append(np.mean(np.stack(probs,axis=0),axis=0))\n","    fam_probs=np.mean(np.stack(fold_probs,axis=0),axis=0)\n","    fam_weight=infer_weights_from_val_csv(fam[\"val_csvs\"]) or 1.0\n","    return fam_probs, fam_weight\n","\n","# ===== Metrics =====\n","def roc_auc(y,p):\n","    try: return float(roc_auc_score(y,p))\n","    except Exception: return float(\"nan\")\n","\n","def pr_auc(y,p):\n","    try:\n","        prec,rec,_=precision_recall_curve(y,p); return float(auc(rec,prec))\n","    except Exception: return float(\"nan\")\n","\n","def f1_at(y,p,thr):\n","    try: return float(f1_score(y,(p>=thr).astype(int)))\n","    except Exception: return float(\"nan\")\n","\n","def best_f1(y,p):\n","    prec,rec,thr=precision_recall_curve(y,p); thr=np.append(thr,1.0)\n","    f1=2*prec*rec/np.clip(prec+rec,1e-9,None); i=int(np.nanargmax(f1))\n","    return float(thr[i]), float(f1[i])\n","\n","def precision_at_k(y,p,k):\n","    if len(p)==0: return float(\"nan\")\n","    idx=np.argsort(-p)[:min(k,len(p))]\n","    if len(idx)==0: return float(\"nan\")\n","    return float(np.mean(np.array(y)[idx]))\n","\n","# ===== Helpers =====\n","def infer_dims(data_list):\n","    for d in data_list:\n","        if hasattr(d,\"x\") and hasattr(d,\"edge_attr\") and hasattr(d,\"g\") and hasattr(d,\"r\"):\n","            return {\"x\":d.x.size(-1), \"edge\":d.edge_attr.size(-1),\n","                    \"g\":(d.g.size(-1) if d.g.dim() in (2,3) else d.g.numel()),\n","                    \"r\":(d.r.size(-1) if d.r.dim() in (2,3) else d.r.numel())}\n","    raise RuntimeError(\"infer_dims failed\")\n","\n","def combine_probs(combo, table, mode, fam_weights):\n","    probs=[table[f] for f in combo]\n","    if mode==\"equal\": w=np.ones(len(combo))/len(combo)\n","    else:\n","        ws=np.array([max(1e-9,fam_weights[f]) for f in combo]); w=ws/ws.sum()\n","    return np.sum(np.stack([w[i]*probs[i] for i in range(len(combo))],axis=0),axis=0), w\n","\n","def strat_masks(tiers):\n","    tiers = np.array([str(t).lower() for t in tiers], dtype=object)\n","    strong_mask = np.array([t.startswith(\"strong_\") for t in tiers], dtype=bool)\n","    weak_mask   = (tiers == \"weak_pos\")\n","    return strong_mask, weak_mask\n","\n","def metrics_block(y_true, p_pred):\n","    out = {\n","        \"ROC\": roc_auc(y_true, p_pred),\n","        \"PR\":  pr_auc(y_true, p_pred),\n","        \"F1@0.5\": f1_at(y_true, p_pred, 0.5)\n","    }\n","    bt, bf1 = best_f1(y_true, p_pred)\n","    out[\"BestThr\"] = bt; out[\"F1@Best\"] = bf1\n","    return out\n","\n","def metrics_with_strata(prefix, y, p, tiers, p_at_k_list):\n","    rows={}\n","    m_all = metrics_block(y, p)\n","    rows.update({f\"{prefix}_ROC\":m_all[\"ROC\"], f\"{prefix}_PR\":m_all[\"PR\"],\n","                 f\"{prefix}_F1@0.5\":m_all[\"F1@0.5\"], f\"{prefix}_BestThr\":m_all[\"BestThr\"],\n","                 f\"{prefix}_F1@Best\":m_all[\"F1@Best\"]})\n","    mask_s, mask_w = strat_masks(tiers)\n","    # strong-only\n","    if mask_s.any():\n","        m_s = metrics_block(y[mask_s], p[mask_s])\n","        rows.update({f\"{prefix}_Strong_ROC\":m_s[\"ROC\"], f\"{prefix}_Strong_PR\":m_s[\"PR\"],\n","                     f\"{prefix}_Strong_F1@0.5\":m_s[\"F1@0.5\"], f\"{prefix}_Strong_BestThr\":m_s[\"BestThr\"],\n","                     f\"{prefix}_Strong_F1@Best\":m_s[\"F1@Best\"]})\n","    else:\n","        rows.update({f\"{prefix}_Strong_ROC\":np.nan, f\"{prefix}_Strong_PR\":np.nan,\n","                     f\"{prefix}_Strong_F1@0.5\":np.nan, f\"{prefix}_Strong_BestThr\":np.nan,\n","                     f\"{prefix}_Strong_F1@Best\":np.nan})\n","    # weak-only\n","    if mask_w.any():\n","        m_w = metrics_block(y[mask_w], p[mask_w])\n","        rows.update({f\"{prefix}_Weak_ROC\":m_w[\"ROC\"], f\"{prefix}_Weak_PR\":m_w[\"PR\"],\n","                     f\"{prefix}_Weak_F1@0.5\":m_w[\"F1@0.5\"], f\"{prefix}_Weak_BestThr\":m_w[\"BestThr\"],\n","                     f\"{prefix}_Weak_F1@Best\":m_w[\"F1@Best\"]})\n","        for K in p_at_k_list:\n","            rows[f\"{prefix}_Weak_P@{K}\"] = precision_at_k(y[mask_w], p[mask_w], K)\n","    else:\n","        rows.update({f\"{prefix}_Weak_ROC\":np.nan, f\"{prefix}_Weak_PR\":np.nan,\n","                     f\"{prefix}_Weak_F1@0.5\":np.nan, f\"{prefix}_Weak_BestThr\":np.nan,\n","                     f\"{prefix}_Weak_F1@Best\":np.nan})\n","        for K in p_at_k_list:\n","            rows[f\"{prefix}_Weak_P@{K}\"] = np.nan\n","    return rows\n","\n","# ===== Main =====\n","def main():\n","    assert Path(EXT_UNION_CSV).exists(), f\"not found: {EXT_UNION_CSV}\"\n","    # ã‚°ãƒ©ãƒ•ã¯å¸¸ã«å†æ§‹ç¯‰ï¼ˆCSVã®tier/yå¤‰æ›´ãŒç¢ºå®Ÿã«åæ˜ ã•ã‚Œã‚‹ã‚ˆã†ã«ï¼‰\n","    if Path(EXT_UNION_GRAPHS).exists(): os.remove(EXT_UNION_GRAPHS)\n","    data_union_all = load_or_build(EXT_UNION_CSV, EXT_UNION_GRAPHS, force_rebuild=True)\n","\n","    # unknownï¼ˆy==-1ï¼‰ã¯é™¤å¤–\n","    m_union = valid_mask(data_union_all)\n","    data_union = [d for i,d in enumerate(data_union_all) if m_union[i]]\n","\n","    # KEGG-only ã¯å­˜åœ¨ã—ãªã„å ´åˆã‚‚ã‚ã‚‹ã®ã§ä»»æ„\n","    data_kegg = []\n","    if Path(EXT_KEGG_CSV).exists():\n","        if Path(EXT_KEGG_GRAPHS).exists(): os.remove(EXT_KEGG_GRAPHS)\n","        data_kegg_all = load_or_build(EXT_KEGG_CSV, EXT_KEGG_GRAPHS, force_rebuild=True)\n","        m_kegg = valid_mask(data_kegg_all)\n","        data_kegg = [d for i,d in enumerate(data_kegg_all) if m_kegg[i]]\n","\n","    # æ¬¡å…ƒ\n","    dims = None\n","    for d in data_union:\n","        if hasattr(d,\"x\") and hasattr(d,\"edge_attr\") and hasattr(d,\"g\") and hasattr(d,\"r\"):\n","            dims = {\"x\":d.x.size(-1), \"edge\":d.edge_attr.size(-1),\n","                    \"g\":(d.g.size(-1) if d.g.dim() in (2,3) else d.g.numel()),\n","                    \"r\":(d.r.size(-1) if d.r.dim() in (2,3) else d.r.numel())}\n","            break\n","    print(\"[INFO] dims:\", dims)\n","\n","    fam_ids=[\"M1\",\"M2\",\"M3\",\"M4\"]\n","    fam_probs_union={}; fam_probs_kegg={}; fam_weights={}\n","    for fid in fam_ids:\n","        print(f\"\\n== {fid} on UNION ==\")\n","        pu,w=predict_family_probs(fid,dims,data_union); fam_probs_union[fid]=pu; fam_weights[fid]=w; print(\"  weight:\",w)\n","        if data_kegg:\n","            print(f\"== {fid} on KEGG ==\")\n","            pk,_=predict_family_probs(fid,dims,data_kegg);  fam_probs_kegg[fid]=pk\n","\n","    singles=[(f,) for f in fam_ids]\n","    pairs  =list(itertools.combinations(fam_ids,2))\n","    trips  =list(itertools.combinations(fam_ids,3))\n","    combos =singles+pairs+trips\n","\n","    y_union   = extract_labels(data_union, np.ones(len(data_union), dtype=bool))\n","    tiers_union = extract_tiers(data_union, np.ones(len(data_union), dtype=bool))\n","\n","    if data_kegg:\n","        y_kegg   = extract_labels(data_kegg, np.ones(len(data_kegg), dtype=bool))\n","        tiers_kegg = extract_tiers(data_kegg, np.ones(len(data_kegg), dtype=bool))\n","    else:\n","        y_kegg = tiers_kegg = None\n","\n","    rows=[]\n","    for mode in [\"equal\",\"cv_pr\"]:\n","        for combo in combos:\n","            name=\"+\".join(combo)\n","            p_u,_=combine_probs(combo, fam_probs_union, mode, fam_weights)\n","\n","            rec={\"Mode\":mode,\"Combo\":name}\n","            rec.update(metrics_with_strata(\"Union\", y_union, p_u, tiers_union, P_AT_K))\n","\n","            if data_kegg and (combo[0] in fam_probs_kegg or len(combo)>1):\n","                # KEGG å´ã®ç¢ºç‡ãŒã‚ã‚‹çµ„åˆã›ã®ã¿è¨ˆç®—\n","                # ï¼ˆç„¡ã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—ã¾ãŸã¯ NaN åŸ‹ã‚ï¼‰\n","                try:\n","                    p_k,_=combine_probs(combo, fam_probs_kegg,  mode, fam_weights)\n","                    rec.update(metrics_with_strata(\"KEGG\", y_kegg, p_k, tiers_kegg, P_AT_K))\n","                except Exception:\n","                    for key in [\"ROC\",\"PR\",\"F1@0.5\",\"BestThr\",\"F1@Best\"]:\n","                        rec[f\"KEGG_{key}\"]=np.nan; rec[f\"KEGG_Strong_{key}\"]=np.nan; rec[f\"KEGG_Weak_{key}\"]=np.nan\n","                    for K in P_AT_K: rec[f\"KEGG_Weak_P@{K}\"]=np.nan\n","            else:\n","                for key in [\"ROC\",\"PR\",\"F1@0.5\",\"BestThr\",\"F1@Best\"]:\n","                    rec[f\"KEGG_{key}\"]=np.nan; rec[f\"KEGG_Strong_{key}\"]=np.nan; rec[f\"KEGG_Weak_{key}\"]=np.nan\n","                for K in P_AT_K: rec[f\"KEGG_Weak_P@{K}\"]=np.nan\n","\n","            rows.append(rec)\n","\n","    df=pd.DataFrame(rows)\n","    out_all=f\"{ROOT}/external_eval_comparison_all.csv\"; df.to_csv(out_all, index=False); print(\"ğŸ“\", out_all)\n","\n","    # ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆUnion_PRâ†’Union_ROCï¼‰\n","    df_rank=df.copy()\n","    df_rank[\"RankScore\"] = -df_rank[\"Union_PR\"].fillna(-1e9) - 1e-3*df_rank[\"Union_ROC\"].fillna(-1e9)\n","    df_rank=df_rank.sort_values([\"RankScore\"], ascending=True).reset_index(drop=True)\n","    out_rank=f\"{ROOT}/external_eval_ranking.csv\"; df_rank.to_csv(out_rank, index=False); print(\"ğŸ\", out_rank)\n","\n","    print(\"\\n=== Top 10 by Union_PR then Union_ROC ===\")\n","    cols = [\"Mode\",\"Combo\",\"Union_PR\",\"Union_ROC\",\"Union_Weak_PR\",\"Union_Strong_PR\"]\n","    if \"KEGG_PR\" in df_rank.columns: cols += [\"KEGG_PR\"]\n","    print(df_rank[cols].head(10).to_string(index=False))\n","\n","# ===== Run =====\n","if __name__==\"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rWrEzO6QEj4r","executionInfo":{"status":"ok","timestamp":1760685289097,"user_tz":-540,"elapsed":40029,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"ee9bef4f-fc69-4312-a075-22cad24e7a8a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] StandardScaler fitted: g(7), r(10) from train_split.csv (n=6081)\n","âœ… Saved graphs: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/external10_union_graphs.pt  (n=1478)\n","[SUMMARY] external10_union.csv | y=1:22, y=0:1453, y=-1:3\n","[SUMMARY] external10_union.csv | tier: {'aid_weak_neg': 1453, 'unknown': 3, 'aid_weak_pos': 16, 'kegg_pos': 6}\n","âœ… Saved graphs: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/external10_kegg_only_graphs.pt  (n=0)\n","[SUMMARY] external10_kegg_only.csv | y=1:0, y=0:0, y=-1:0\n","[SUMMARY] external10_kegg_only.csv | tier: {}\n","[INFO] dims: {'x': 5, 'edge': 6, 'g': 7, 'r': 10}\n","\n","== M1 on UNION ==\n","  weight: 0.6255231451006052\n","\n","== M2 on UNION ==\n","  weight: 0.40228706089133903\n","\n","== M3 on UNION ==\n","  weight: 0.2918669126356172\n","\n","== M4 on UNION ==\n","  weight: 0.6185174288319562\n","ğŸ“ /content/drive/MyDrive/Chemoinfo_MDR1_ver7/external_eval_comparison_all.csv\n","ğŸ /content/drive/MyDrive/Chemoinfo_MDR1_ver7/external_eval_ranking.csv\n","\n","=== Top 10 by Union_PR then Union_ROC ===\n"," Mode    Combo  Union_PR  Union_ROC  Union_Weak_PR  Union_Strong_PR  KEGG_PR\n","equal       M4  0.279945   0.898580            NaN              NaN      NaN\n","cv_pr       M4  0.279945   0.898580            NaN              NaN      NaN\n","equal    M1+M4  0.272284   0.900175            NaN              NaN      NaN\n","cv_pr    M1+M4  0.271943   0.900081            NaN              NaN      NaN\n","cv_pr    M2+M4  0.254690   0.901301            NaN              NaN      NaN\n","cv_pr M1+M2+M4  0.251355   0.899487            NaN              NaN      NaN\n","equal M1+M2+M4  0.250927   0.898110            NaN              NaN      NaN\n","cv_pr M1+M3+M4  0.244806   0.893355            NaN              NaN      NaN\n","equal    M2+M4  0.241975   0.898236            NaN              NaN      NaN\n","equal       M1  0.239712   0.888037            NaN              NaN      NaN\n"]}]},{"cell_type":"code","source":["# ==== External Evaluation for M4 only with ROC curves (UNION & KEGG-only) ====\n","# - Loads external10_union_graphs.pt / external10_kegg_only_graphs.pt\n","# - Loads only M4 weights, predicts per-family probs\n","# - Reports: PR-AUC, ROC-AUC, Precision/Recall/F1 @ fixed thr, Best-F1\n","# - Saves ROC curves (PNG) and ROC points (CSV) for UNION & KEGG-only (when defined)\n","# -----------------------------------------------------------------------------\n","import sys, subprocess\n","\n","def ensure_sklearn_stack():\n","    try:\n","        import sklearn  # noqa\n","        from sklearn.metrics import precision_recall_curve  # noqa\n","        return\n","    except Exception as e:\n","        print(\"[INFO] fixing sklearn/scipy stack due to:\", repr(e))\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                                   \"scipy>=1.13.0\", \"scikit-learn>=1.4.0\"])\n","        except Exception as e2:\n","            print(\"[WARN] upgrade path failed:\", e2)\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                                   \"numpy<2\", \"scipy<1.11\", \"scikit-learn<1.4\"])\n","        import importlib; importlib.invalidate_caches()\n","ensure_sklearn_stack()\n","\n","import os, glob, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n","from pathlib import Path\n","from sklearn.metrics import (precision_recall_curve, precision_score, recall_score, f1_score,\n","                             roc_auc_score, auc, roc_curve)\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","from torch.serialization import add_safe_globals\n","from sklearn.exceptions import UndefinedMetricWarning\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# matplotlibï¼ˆè‰²ã¯æŒ‡å®šã—ãªã„ï¼å˜ç‹¬ãƒ—ãƒ­ãƒƒãƒˆï¼‰\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","EXT_UNION_PT = f\"{ROOT}/external10_union_graphs.pt\"\n","EXT_KEGG_PT  = f\"{ROOT}/external10_kegg_only_graphs.pt\"\n","\n","# ==== M4 only ====\n","M4_DIR = f\"{ROOT}/results_lco5_trans_nn_ens_posaug_advanced\"\n","\n","OUT_DIR = f\"{ROOT}/figs_m4_roc\"\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","BATCH = 256\n","FIXED_THR = 0.5\n","\n","# ---------- helpers ----------\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception:\n","        pass\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","def dims_from_sample(d):\n","    x_dim = d.x.size(-1)\n","    e_dim = d.edge_attr.size(-1)\n","    g_dim = d.g.size(-1) if d.g.dim() in (2,3) else d.g.numel()\n","    r_dim = d.r.size(-1) if d.r.dim() in (2,3) else d.r.numel()\n","    return x_dim, e_dim, g_dim, r_dim\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hid = max(64, min(256, in_attr_dim*8))\n","    return nn.Sequential(nn.Linear(in_attr_dim,hid), nn.ReLU(),\n","                         nn.Linear(hid, in_channels*out_channels))\n","\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        self.c1=TransformerConv(X_DIM,HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.c2=TransformerConv(HID, HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1))\n","        self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr))\n","        x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g\n","        r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        e1=make_edge_mlp(E_DIM,HID,X_DIM); e2=make_edge_mlp(E_DIM,HID,HID)\n","        self.c1=NNConv(X_DIM,HID,e1,aggr='mean'); self.c2=NNConv(HID,HID,e2,aggr='mean')\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1))\n","        self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr))\n","        x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g\n","        r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","def fold_id(p):\n","    import re, os\n","    bn=os.path.basename(p).lower()\n","    m=re.findall(r\"fold(\\d+)\", bn)\n","    return int(m[-1]) if m else -1\n","\n","def infer_cv_pr_weight(csv_paths):\n","    if not csv_paths: return None\n","    vals=[]\n","    for p in csv_paths:\n","        try:\n","            import pandas as pd\n","            df=pd.read_csv(p)\n","            for c in [\"PR-AUC\",\"Ensemble_PR\",\"PR\",\"Val PR-AUC\",\"Ensemble_PR:\"]:\n","                if c in df.columns:\n","                    s=pd.to_numeric(df[c], errors=\"coerce\")\n","                    vals += s[~s.isna()].tolist()\n","        except Exception:\n","            pass\n","    return float(np.nanmean(vals)) if vals else None\n","\n","@torch.no_grad()\n","def family_probs(data_list, family_dir, dims):\n","    \"\"\"Return mean probs across folds/models for a family, and optional CV-PR weight (unused here).\"\"\"\n","    X_DIM,E_DIM,G_DIM,R_DIM = dims\n","    tr_files=sorted(glob.glob(os.path.join(family_dir,\"transformer_fold*.pt\")))\n","    nn_files=sorted(glob.glob(os.path.join(family_dir,\"nnconv_fold*.pt\")))\n","    if not tr_files: tr_files=sorted(glob.glob(os.path.join(family_dir,\"*trans*fold*.pt\")))\n","    if not nn_files: nn_files=sorted(glob.glob(os.path.join(family_dir,\"*nn*fold*.pt\")))\n","    tr_map={fold_id(p):p for p in tr_files}; nn_map={fold_id(p):p for p in nn_files}\n","    folds=sorted(set(list(tr_map.keys())+list(nn_map.keys())))\n","    assert folds, f\"No weight files found in: {family_dir}\"\n","\n","    # optional weight (not used for single-family reporting)\n","    val_csvs = sorted(glob.glob(os.path.join(family_dir,\"*.csv\")))\n","    fam_w = infer_cv_pr_weight(val_csvs) or 1.0\n","\n","    dl=DataLoader(data_list,batch_size=BATCH,shuffle=False)\n","    fold_probs=[]\n","    for f in folds:\n","        probs=[]\n","        if f in tr_map:\n","            m=Transformer_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE)\n","            m.load_state_dict(torch.load(tr_map[f],map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if f in nn_map:\n","            m=NNConv_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE)\n","            m.load_state_dict(torch.load(nn_map[f],map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if probs:\n","            fold_probs.append(np.mean(np.stack(probs,axis=0),axis=0))\n","    fam_probs=np.mean(np.stack(fold_probs,axis=0),axis=0)\n","    return fam_probs, float(fam_w)\n","\n","def evaluable_subset_or_none(data_list):\n","    idx=[i for i,d in enumerate(data_list) if int(getattr(d,\"y\",-1)) in (0,1)]\n","    if not idx:\n","        return None, None\n","    y=np.array([int(getattr(data_list[i],'y')) for i in idx], dtype=int)\n","    return idx, y\n","\n","def report_block(name, y, p, thr_fixed=0.5):\n","    prev = y.mean()\n","    print(f\"\\n=== {name} ===\")\n","    print(f\"N={len(y)} | positives={y.sum()} ({prev*100:.2f}%)\")\n","    prec, rec, thr = precision_recall_curve(y, p)\n","    pr = auc(rec, prec)\n","    try:\n","        roc = roc_auc_score(y, p)\n","    except Exception:\n","        roc = float(\"nan\")\n","    print(f\"PR-AUC={pr:.6f} | ROC-AUC={roc:.6f}\")\n","\n","    predF = (p>=thr_fixed).astype(int)\n","    prF = precision_score(y,predF,zero_division=0)\n","    rcF = recall_score(y,predF,zero_division=0)\n","    f1F = f1_score(y,predF,zero_division=0)\n","    print(f\"@thr={thr_fixed:.4f}  Precision={prF:.4f}  Recall={rcF:.4f}  F1={f1F:.4f}  PosPred={predF.sum()}\")\n","\n","    thr_all = np.append(thr, 1.0)\n","    f1_all = 2*prec*rec/np.clip(prec+rec,1e-9,None)\n","    i = int(np.nanargmax(f1_all))\n","    print(f\"[Best-F1] thr={thr_all[i]:.4f}  F1={f1_all[i]:.4f}  (Prec={prec[i]:.4f}, Rec={rec[i]:.4f})\")\n","\n","def save_roc_curve(out_png, out_csv, y, p, title):\n","    \"\"\"Save ROC curve image and CSV (fpr,tpr,thresholds). Skip if undefined.\"\"\"\n","    if y is None or p is None or len(y)==0:\n","        print(f\"[SKIP] ROC undefined for {title} (no evaluable samples).\")\n","        return False\n","    if (np.unique(y).size < 2):\n","        print(f\"[SKIP] ROC undefined for {title} (single-class labels).\")\n","        return False\n","    fpr, tpr, thr = roc_curve(y, p)\n","    roc = roc_auc_score(y, p)\n","    import pandas as pd\n","    pd.DataFrame({\"fpr\":fpr, \"tpr\":tpr, \"threshold\":thr}).to_csv(out_csv, index=False)\n","    plt.figure()\n","    plt.plot(fpr, tpr, label=f\"AUC={roc:.4f}\")\n","    plt.plot([0,1],[0,1], linestyle=\"--\")\n","    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n","    plt.title(title); plt.legend(); plt.tight_layout()\n","    plt.savefig(out_png, dpi=160); plt.close()\n","    print(f\"[ROC] Saved: {out_png} | {out_csv}\")\n","    return True\n","\n","# ---------- run ----------\n","Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","union_list = load_pyg_list(EXT_UNION_PT)\n","kegg_list  = load_pyg_list(EXT_KEGG_PT) if Path(EXT_KEGG_PT).exists() else []\n","\n","idx_u, y_u = evaluable_subset_or_none(union_list)\n","if idx_u is None:\n","    raise RuntimeError(\"UNION: No evaluable samples (y in {0,1}).\")\n","\n","idx_k, y_k = evaluable_subset_or_none(kegg_list) if len(kegg_list)>0 else (None, None)\n","\n","X_DIM,E_DIM,G_DIM,R_DIM = dims_from_sample(union_list[idx_u[0]])\n","dims = (X_DIM,E_DIM,G_DIM,R_DIM)\n","print(\"[INFO] dims:\", {\"x\":X_DIM,\"edge\":E_DIM,\"g\":G_DIM,\"r\":R_DIM})\n","\n","# per-family probs (M4 only)\n","pM4_u, wM4 = family_probs([union_list[i] for i in idx_u], M4_DIR, dims)\n","if idx_k is not None:\n","    pM4_k, _  = family_probs([kegg_list[i] for i in idx_k], M4_DIR, dims)\n","else:\n","    pM4_k = None\n","\n","print(f\"[INFO] M4 CV-PR weight (unused for single-family): {wM4:.3f}\")\n","\n","# reports (text)\n","report_block(\"M4 on UNION\", y_u, pM4_u, thr_fixed=FIXED_THR)\n","if idx_k is not None:\n","    report_block(\"M4 on KEGG-only\", y_k, pM4_k, thr_fixed=FIXED_THR)\n","else:\n","    print(\"\\n[INFO] KEGG-only set is empty or has no evaluable samples â€” skip KEGG reports.\")\n","\n","# ROC curves (PNG & CSV)\n","save_roc_curve(f\"{OUT_DIR}/roc_union_m4.png\",\n","               f\"{OUT_DIR}/roc_union_m4.csv\",\n","               y_u, pM4_u, \"M4 ROC - UNION\")\n","\n","if idx_k is not None:\n","    save_roc_curve(f\"{OUT_DIR}/roc_kegg_m4.png\",\n","                   f\"{OUT_DIR}/roc_kegg_m4.csv\",\n","                   y_k, pM4_k, \"M4 ROC - KEGG-only\")\n","\n","print(f\"\\nOutputs in: {OUT_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mzTgYYk_JO9l","executionInfo":{"status":"ok","timestamp":1760685407225,"user_tz":-540,"elapsed":3054,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"c8962166-bd31-4516-cf61-596571e53360"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] dims: {'x': 5, 'edge': 6, 'g': 7, 'r': 10}\n","[INFO] M4 CV-PR weight (unused for single-family): 0.619\n","\n","=== M4 on UNION ===\n","N=1475 | positives=22 (1.49%)\n","PR-AUC=0.279945 | ROC-AUC=0.898580\n","@thr=0.5000  Precision=0.2727  Recall=0.5455  F1=0.3636  PosPred=44\n","[Best-F1] thr=0.5774  F1=0.4314  (Prec=0.3793, Rec=0.5000)\n","\n","[INFO] KEGG-only set is empty or has no evaluable samples â€” skip KEGG reports.\n","[ROC] Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc/roc_union_m4.png | /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc/roc_union_m4.csv\n","\n","Outputs in: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc\n"]}]},{"cell_type":"code","source":["# ==== External Evaluation for M4 only with ROC/PR curves (UNION & KEGG-only) ====\n","# - Loads external10_union_graphs.pt / external10_kegg_only_graphs.pt\n","# - Loads only M4 weights, predicts per-family probs\n","# - Reports: PR-AUC, ROC-AUC, Precision/Recall/F1 @ fixed thr, Best-F1\n","# - Saves ROC/PR curves (PNG) and ROC/PR points (CSV) for UNION & KEGG-only (when defined)\n","# -----------------------------------------------------------------------------\n","import sys, subprocess\n","\n","def ensure_sklearn_stack():\n","    try:\n","        import sklearn  # noqa\n","        from sklearn.metrics import precision_recall_curve  # noqa\n","        return\n","    except Exception as e:\n","        print(\"[INFO] fixing sklearn/scipy stack due to:\", repr(e))\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                                   \"scipy>=1.13.0\", \"scikit-learn>=1.4.0\"])\n","        except Exception as e2:\n","            print(\"[WARN] upgrade path failed:\", e2)\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                                   \"numpy<2\", \"scipy<1.11\", \"scikit-learn<1.4\"])\n","        import importlib; importlib.invalidate_caches()\n","ensure_sklearn_stack()\n","\n","import os, glob, numpy as np, torch, torch.nn as nn, torch.nn.functional as F\n","from pathlib import Path\n","from sklearn.metrics import (precision_recall_curve, precision_score, recall_score, f1_score,\n","                             roc_auc_score, auc, roc_curve)\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","from torch.serialization import add_safe_globals\n","from sklearn.exceptions import UndefinedMetricWarning\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# matplotlibï¼ˆè‰²ã¯æŒ‡å®šã—ãªã„ï¼å˜ç‹¬ãƒ—ãƒ­ãƒƒãƒˆï¼‰\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","EXT_UNION_PT = f\"{ROOT}/external10_union_graphs.pt\"\n","EXT_KEGG_PT  = f\"{ROOT}/external10_kegg_only_graphs.pt\"\n","\n","# ==== M4 only ====\n","M4_DIR = f\"{ROOT}/results_lco5_trans_nn_ens_posaug_advanced\"\n","\n","OUT_DIR = f\"{ROOT}/figs_m4_roc\"\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","BATCH = 256\n","FIXED_THR = 0.5\n","\n","# ---------- helpers ----------\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception:\n","        pass\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","def dims_from_sample(d):\n","    x_dim = d.x.size(-1)\n","    e_dim = d.edge_attr.size(-1)\n","    g_dim = d.g.size(-1) if d.g.dim() in (2,3) else d.g.numel()\n","    r_dim = d.r.size(-1) if d.r.dim() in (2,3) else d.r.numel()\n","    return x_dim, e_dim, g_dim, r_dim\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hid = max(64, min(256, in_attr_dim*8))\n","    return nn.Sequential(nn.Linear(in_attr_dim,hid), nn.ReLU(),\n","                         nn.Linear(hid, in_channels*out_channels))\n","\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        self.c1=TransformerConv(X_DIM,HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.c2=TransformerConv(HID, HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1))\n","        self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr))\n","        x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g\n","        r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        e1=make_edge_mlp(E_DIM,HID,X_DIM); e2=make_edge_mlp(E_DIM,HID,HID)\n","        self.c1=NNConv(X_DIM,HID,e1,aggr='mean'); self.c2=NNConv(HID,HID,e2,aggr='mean')\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1))\n","        self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr))\n","        x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g\n","        r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","def fold_id(p):\n","    import re, os\n","    bn=os.path.basename(p).lower()\n","    m=re.findall(r\"fold(\\d+)\", bn)\n","    return int(m[-1]) if m else -1\n","\n","def infer_cv_pr_weight(csv_paths):\n","    if not csv_paths: return None\n","    vals=[]\n","    for p in csv_paths:\n","        try:\n","            import pandas as pd\n","            df=pd.read_csv(p)\n","            for c in [\"PR-AUC\",\"Ensemble_PR\",\"PR\",\"Val PR-AUC\",\"Ensemble_PR:\"]:\n","                if c in df.columns:\n","                    s=pd.to_numeric(df[c], errors=\"coerce\")\n","                    vals += s[~s.isna()].tolist()\n","        except Exception:\n","            pass\n","    return float(np.nanmean(vals)) if vals else None\n","\n","@torch.no_grad()\n","def family_probs(data_list, family_dir, dims):\n","    \"\"\"Return mean probs across folds/models for a family, and optional CV-PR weight (unused here).\"\"\"\n","    X_DIM,E_DIM,G_DIM,R_DIM = dims\n","    tr_files=sorted(glob.glob(os.path.join(family_dir,\"transformer_fold*.pt\")))\n","    nn_files=sorted(glob.glob(os.path.join(family_dir,\"nnconv_fold*.pt\")))\n","    if not tr_files: tr_files=sorted(glob.glob(os.path.join(family_dir,\"*trans*fold*.pt\")))\n","    if not nn_files: nn_files=sorted(glob.glob(os.path.join(family_dir,\"*nn*fold*.pt\")))\n","    tr_map={fold_id(p):p for p in tr_files}; nn_map={fold_id(p):p for p in nn_files}\n","    folds=sorted(set(list(tr_map.keys())+list(nn_map.keys())))\n","    assert folds, f\"No weight files found in: {family_dir}\"\n","\n","    # optional weight (not used for single-family reporting)\n","    val_csvs = sorted(glob.glob(os.path.join(family_dir,\"*.csv\")))\n","    fam_w = infer_cv_pr_weight(val_csvs) or 1.0\n","\n","    dl=DataLoader(data_list,batch_size=BATCH,shuffle=False)\n","    fold_probs=[]\n","    for f in folds:\n","        probs=[]\n","        if f in tr_map:\n","            m=Transformer_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE)\n","            m.load_state_dict(torch.load(tr_map[f],map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if f in nn_map:\n","            m=NNConv_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE)\n","            m.load_state_dict(torch.load(nn_map[f],map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if probs:\n","            fold_probs.append(np.mean(np.stack(probs,axis=0),axis=0))\n","    fam_probs=np.mean(np.stack(fold_probs,axis=0),axis=0)\n","    return fam_probs, float(fam_w)\n","\n","def evaluable_subset_or_none(data_list):\n","    idx=[i for i,d in enumerate(data_list) if int(getattr(d,\"y\",-1)) in (0,1)]\n","    if not idx:\n","        return None, None\n","    y=np.array([int(getattr(data_list[i],'y')) for i in idx], dtype=int)\n","    return idx, y\n","\n","def report_block(name, y, p, thr_fixed=0.5):\n","    prev = y.mean()\n","    print(f\"\\n=== {name} ===\")\n","    print(f\"N={len(y)} | positives={y.sum()} ({prev*100:.2f}%)\")\n","    prec, rec, thr = precision_recall_curve(y, p)\n","    pr = auc(rec, prec)\n","    try:\n","        roc = roc_auc_score(y, p)\n","    except Exception:\n","        roc = float(\"nan\")\n","    print(f\"PR-AUC={pr:.6f} | ROC-AUC={roc:.6f}\")\n","\n","    predF = (p>=thr_fixed).astype(int)\n","    prF = precision_score(y,predF,zero_division=0)\n","    rcF = recall_score(y,predF,zero_division=0)\n","    f1F = f1_score(y,predF,zero_division=0)\n","    print(f\"@thr={thr_fixed:.4f}  Precision={prF:.4f}  Recall={rcF:.4f}  F1={f1F:.4f}  PosPred={predF.sum()}\")\n","\n","    thr_all = np.append(thr, 1.0)\n","    f1_all = 2*prec*rec/np.clip(prec+rec,1e-9,None)\n","    i = int(np.nanargmax(f1_all))\n","    print(f\"[Best-F1] thr={thr_all[i]:.4f}  F1={f1_all[i]:.4f}  (Prec={prec[i]:.4f}, Rec={rec[i]:.4f})\")\n","\n","def save_roc_curve(out_png, out_csv, y, p, title):\n","    \"\"\"Save ROC curve image and CSV (fpr,tpr,thresholds). Skip if undefined.\"\"\"\n","    if y is None or p is None or len(y)==0:\n","        print(f\"[SKIP] ROC undefined for {title} (no evaluable samples).\")\n","        return False\n","    if (np.unique(y).size < 2):\n","        print(f\"[SKIP] ROC undefined for {title} (single-class labels).\")\n","        return False\n","    fpr, tpr, thr = roc_curve(y, p)\n","    roc = roc_auc_score(y, p)\n","    import pandas as pd\n","    pd.DataFrame({\"fpr\":fpr, \"tpr\":tpr, \"threshold\":thr}).to_csv(out_csv, index=False)\n","    plt.figure()\n","    plt.plot(fpr, tpr, label=f\"AUC={roc:.4f}\")\n","    plt.plot([0,1],[0,1], linestyle=\"--\")\n","    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n","    plt.title(title); plt.legend(); plt.tight_layout()\n","    plt.savefig(out_png, dpi=160); plt.close()\n","    print(f\"[ROC] Saved: {out_png} | {out_csv}\")\n","    return True\n","\n","def save_pr_curve(out_png, out_csv, y, p, title):\n","    \"\"\"Save PR curve image and CSV (recall,precision,threshold). Skip if undefined.\"\"\"\n","    if y is None or p is None or len(y)==0:\n","        print(f\"[SKIP] PR undefined for {title} (no evaluable samples).\")\n","        return False\n","    if (np.unique(y).size < 2):\n","        print(f\"[SKIP] PR undefined for {title} (single-class labels).\")\n","        return False\n","    prec, rec, thr = precision_recall_curve(y, p)\n","    pr_auc = auc(rec, prec)\n","    # thresholds: len = len(prec)-1; append 1.0 to align with prec/rec\n","    thr_all = np.append(thr, 1.0)\n","\n","    import pandas as pd\n","    pd.DataFrame({\"recall\": rec, \"precision\": prec, \"threshold\": thr_all}).to_csv(out_csv, index=False)\n","\n","    plt.figure()\n","    plt.plot(rec, prec, label=f\"PR-AUC={pr_auc:.4f}\")\n","    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n","    plt.title(title); plt.legend(); plt.tight_layout()\n","    plt.savefig(out_png, dpi=160); plt.close()\n","    print(f\"[PR]  Saved: {out_png} | {out_csv}\")\n","    return True\n","\n","# ---------- run ----------\n","Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","union_list = load_pyg_list(EXT_UNION_PT)\n","kegg_list  = load_pyg_list(EXT_KEGG_PT) if Path(EXT_KEGG_PT).exists() else []\n","\n","idx_u, y_u = evaluable_subset_or_none(union_list)\n","if idx_u is None:\n","    raise RuntimeError(\"UNION: No evaluable samples (y in {0,1}).\")\n","\n","idx_k, y_k = evaluable_subset_or_none(kegg_list) if len(kegg_list)>0 else (None, None)\n","\n","X_DIM,E_DIM,G_DIM,R_DIM = dims_from_sample(union_list[idx_u[0]])\n","dims = (X_DIM,E_DIM,G_DIM,R_DIM)\n","print(\"[INFO] dims:\", {\"x\":X_DIM,\"edge\":E_DIM,\"g\":G_DIM,\"r\":R_DIM})\n","\n","# per-family probs (M4 only)\n","pM4_u, wM4 = family_probs([union_list[i] for i in idx_u], M4_DIR, dims)\n","if idx_k is not None:\n","    pM4_k, _  = family_probs([kegg_list[i] for i in idx_k], M4_DIR, dims)\n","else:\n","    pM4_k = None\n","\n","print(f\"[INFO] M4 CV-PR weight (unused for single-family): {wM4:.3f}\")\n","\n","# reports (text)\n","report_block(\"M4 on UNION\", y_u, pM4_u, thr_fixed=FIXED_THR)\n","if idx_k is not None:\n","    report_block(\"M4 on KEGG-only\", y_k, pM4_k, thr_fixed=FIXED_THR)\n","else:\n","    print(\"\\n[INFO] KEGG-only set is empty or has no evaluable samples â€” skip KEGG reports.\")\n","\n","# ROC curves (PNG & CSV)\n","save_roc_curve(f\"{OUT_DIR}/roc_union_m4.png\",\n","               f\"{OUT_DIR}/roc_union_m4.csv\",\n","               y_u, pM4_u, \"M4 ROC - UNION\")\n","\n","if idx_k is not None:\n","    save_roc_curve(f\"{OUT_DIR}/roc_kegg_m4.png\",\n","                   f\"{OUT_DIR}/roc_kegg_m4.csv\",\n","                   y_k, pM4_k, \"M4 ROC - KEGG-only\")\n","\n","# PR curves (PNG & CSV)\n","save_pr_curve(f\"{OUT_DIR}/pr_union_m4.png\",\n","              f\"{OUT_DIR}/pr_union_m4.csv\",\n","              y_u, pM4_u, \"M4 PR - UNION\")\n","\n","if idx_k is not None:\n","    save_pr_curve(f\"{OUT_DIR}/pr_kegg_m4.png\",\n","                  f\"{OUT_DIR}/pr_kegg_m4.csv\",\n","                  y_k, pM4_k, \"M4 PR - KEGG-only\")\n","\n","print(f\"\\nOutputs in: {OUT_DIR}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o_g5--_7zjJ7","executionInfo":{"status":"ok","timestamp":1764557242381,"user_tz":-540,"elapsed":30926,"user":{"displayName":"TE nok","userId":"01928761000188356119"}},"outputId":"bafdcbfe-2c13-4e60-c8e9-44b704629386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] dims: {'x': 5, 'edge': 6, 'g': 7, 'r': 10}\n","[INFO] M4 CV-PR weight (unused for single-family): 0.619\n","\n","=== M4 on UNION ===\n","N=1475 | positives=22 (1.49%)\n","PR-AUC=0.279945 | ROC-AUC=0.898580\n","@thr=0.5000  Precision=0.2727  Recall=0.5455  F1=0.3636  PosPred=44\n","[Best-F1] thr=0.5774  F1=0.4314  (Prec=0.3793, Rec=0.5000)\n","\n","[INFO] KEGG-only set is empty or has no evaluable samples â€” skip KEGG reports.\n","[ROC] Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc/roc_union_m4.png | /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc/roc_union_m4.csv\n","[PR]  Saved: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc/pr_union_m4.png | /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc/pr_union_m4.csv\n","\n","Outputs in: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_m4_roc\n"]}]},{"cell_type":"code","source":["# ==== MDR1-M4-HYB-v1: Internal evaluation with 95% CIs, ROC/PR curves, Confusion table ====\n","# - Input: internal graphs (train/val) at ROOT/data_graph_with_smiles.pt\n","# - Model: M4 only (results_lco5_trans_nn_ens_posaug_advanced)\n","# - Outputs:\n","#   * stats csv with point estimates + 95% bootstrap CIs (ROC-AUC, PR-AUC, F1@0.5, F1@Best)\n","#   * confusion tables (TP/FP/TN/FN) @0.5 and @Best-F1 threshold\n","#   * ROC/PR curves (PNG + CSV)\n","#   * per-sample predictions CSV  (p_ens ã¯äº’æ›ç›®çš„ã§ p_M4 ã¨åŒå€¤)\n","# --------------------------------------------------------------------------------------------------\n","import sys, subprocess\n","\n","# --- ensure sklearn/scipy stack works with current numpy ---\n","def ensure_sklearn_stack():\n","    try:\n","        import sklearn  # noqa\n","        from sklearn.metrics import precision_recall_curve  # noqa\n","        return\n","    except Exception as e:\n","        print(\"[INFO] fixing sklearn/scipy stack due to:\", repr(e))\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                                   \"scipy>=1.13.0\", \"scikit-learn>=1.4.0\"])\n","        except Exception as e2:\n","            print(\"[WARN] upgrade path failed:\", e2)\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\",\n","                                   \"numpy<2\", \"scipy<1.11\", \"scikit-learn<1.4\"])\n","        import importlib; importlib.invalidate_caches()\n","ensure_sklearn_stack()\n","\n","import os, glob, math, json, numpy as np, pandas as pd, torch, torch.nn as nn, torch.nn.functional as F\n","from pathlib import Path\n","from sklearn.metrics import (\n","    precision_recall_curve, roc_curve, auc, roc_auc_score,\n","    precision_score, recall_score, f1_score\n",")\n","from sklearn.exceptions import UndefinedMetricWarning\n","from torch_geometric.loader import DataLoader\n","from torch_geometric.nn import TransformerConv, NNConv, AttentionalAggregation\n","from torch.serialization import add_safe_globals\n","import warnings\n","warnings.filterwarnings(\"ignore\", category=UndefinedMetricWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","# matplotlib backend for headless\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","# ====== CONFIG ======\n","ROOT   = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PT = f\"{ROOT}/data_graph_with_smiles.pt\"   # å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ï¼ˆå­¦ç¿’/æ¤œè¨¼ï¼‰ã‚°ãƒ©ãƒ•\n","\n","# --- M4 ã®ã¿ ---\n","M4_DIR  = f\"{ROOT}/results_lco5_trans_nn_ens_posaug_advanced\"\n","\n","OUT_DIR = f\"{ROOT}/reports_internal_MDR1-M4-HYB-v1\"\n","\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","BATCH = 256\n","FIXED_THR = 0.5           # æ··åŒè¡Œåˆ—/å›ºå®šF1ç”¨ã®é–¾å€¤\n","N_BOOT = 2000             # ãƒ–ãƒ¼ãƒˆã‚¹ãƒˆãƒ©ãƒƒãƒ—åå¾©å›æ•°ï¼ˆ95%CIï¼‰\n","SEED = 42                 # å†ç¾æ€§ã®ãŸã‚\n","\n","# ====== PyG helpers ======\n","def load_pyg_list(path):\n","    try:\n","        from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","        from torch_geometric.data.storage import GlobalStorage\n","        add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    except Exception:\n","        pass\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","def dims_from_sample(d):\n","    x_dim = d.x.size(-1)\n","    e_dim = d.edge_attr.size(-1)\n","    g_dim = d.g.size(-1) if d.g.dim() in (2,3) else d.g.numel()\n","    r_dim = d.r.size(-1) if d.r.dim() in (2,3) else d.r.numel()\n","    return x_dim, e_dim, g_dim, r_dim\n","\n","def make_edge_mlp(in_attr_dim, out_channels, in_channels):\n","    hid = max(64, min(256, in_attr_dim*8))\n","    return nn.Sequential(nn.Linear(in_attr_dim,hid), nn.ReLU(),\n","                         nn.Linear(hid, in_channels*out_channels))\n","\n","class Transformer_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        self.c1=TransformerConv(X_DIM,HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.c2=TransformerConv(HID, HID,heads=4,concat=False,edge_dim=E_DIM,dropout=0.0,beta=False)\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1))\n","        self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr))\n","        x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g\n","        r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","class NNConv_DX_DG_DR(nn.Module):\n","    def __init__(self,X_DIM,G_DIM,R_DIM,E_DIM,HID=256):\n","        super().__init__()\n","        e1=make_edge_mlp(E_DIM,HID,X_DIM); e2=make_edge_mlp(E_DIM,HID,HID)\n","        self.c1=NNConv(X_DIM,HID,e1,aggr='mean'); self.c2=NNConv(HID,HID,e2,aggr='mean')\n","        self.pool=AttentionalAggregation(gate_nn=nn.Linear(HID,1))\n","        self.drop=nn.Dropout(0.2)\n","        self.fc=nn.Linear(HID+G_DIM+R_DIM,1)\n","    def forward(self,d):\n","        x=F.relu(self.c1(d.x,d.edge_index,d.edge_attr))\n","        x=F.relu(self.c2(x,d.edge_index,d.edge_attr))\n","        x=self.pool(self.drop(x), d.batch)\n","        g=d.g.squeeze(1) if d.g.dim()==3 else d.g\n","        r=d.r.squeeze(1) if d.r.dim()==3 else d.r\n","        return self.fc(torch.cat([x,g,r],dim=1)).view(-1)\n","\n","def fold_id(p):\n","    import re, os\n","    bn=os.path.basename(p).lower()\n","    m=re.findall(r\"fold(\\d+)\", bn)\n","    return int(m[-1]) if m else -1\n","\n","def infer_cv_pr_weight(csv_paths):\n","    if not csv_paths: return None\n","    vals=[]\n","    for p in csv_paths:\n","        try:\n","            df=pd.read_csv(p)\n","            for c in [\"PR-AUC\",\"Ensemble_PR\",\"PR\",\"Val PR-AUC\",\"Ensemble_PR:\"]:\n","                if c in df.columns:\n","                    s=pd.to_numeric(df[c], errors=\"coerce\")\n","                    vals += s[~s.isna()].tolist()\n","        except Exception:\n","            pass\n","    return float(np.nanmean(vals)) if vals else None\n","\n","@torch.no_grad()\n","def family_probs(data_list, family_dir, dims):\n","    \"\"\"Return mean probs across folds/models for M4, and optional CV-PR weight (info only).\"\"\"\n","    X_DIM,E_DIM,G_DIM,R_DIM = dims\n","    tr_files=sorted(glob.glob(os.path.join(family_dir,\"transformer_fold*.pt\")))\n","    nn_files=sorted(glob.glob(os.path.join(family_dir,\"nnconv_fold*.pt\")))\n","    if not tr_files: tr_files=sorted(glob.glob(os.path.join(family_dir,\"*trans*fold*.pt\")))\n","    if not nn_files: nn_files=sorted(glob.glob(os.path.join(family_dir,\"*nn*fold*.pt\")))\n","    tr_map={fold_id(p):p for p in tr_files}; nn_map={fold_id(p):p for p in nn_files}\n","    folds=sorted(set(list(tr_map.keys())+list(nn_map.keys())))\n","    assert folds, f\"No weight files found in: {family_dir}\"\n","\n","    val_csvs = sorted(glob.glob(os.path.join(family_dir,\"*.csv\")))\n","    fam_w = infer_cv_pr_weight(val_csvs) or 1.0\n","\n","    dl=DataLoader(data_list,batch_size=BATCH,shuffle=False)\n","    fold_probs=[]\n","    for f in folds:\n","        probs=[]\n","        if f in tr_map:\n","            m=Transformer_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE)\n","            m.load_state_dict(torch.load(tr_map[f],map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if f in nn_map:\n","            m=NNConv_DX_DG_DR(X_DIM,G_DIM,R_DIM,E_DIM).to(DEVICE)\n","            m.load_state_dict(torch.load(nn_map[f],map_location=DEVICE)); m.eval()\n","            ps=[]\n","            for bt in dl: bt=bt.to(DEVICE); ps.append(torch.sigmoid(m(bt)).detach().cpu())\n","            probs.append(torch.cat(ps).numpy()); del m\n","        if probs:\n","            fold_probs.append(np.mean(np.stack(probs,axis=0),axis=0))\n","    fam_probs=np.mean(np.stack(fold_probs,axis=0),axis=0)\n","    return fam_probs, float(fam_w)\n","\n","def evaluable_subset(data_list):\n","    \"\"\"Return indices and labels for samples with y in {0,1}.\"\"\"\n","    idx=[i for i,d in enumerate(data_list) if int(getattr(d,\"y\",-1)) in (0,1)]\n","    if not idx:\n","        raise RuntimeError(\"No evaluable samples (y in {0,1}).\")\n","    y=np.array([int(getattr(data_list[i],'y')) for i in idx], dtype=int)\n","    smiles=[]\n","    for i in idx:\n","        sm=getattr(data_list[i],\"smiles\", None)\n","        smiles.append(sm if sm is not None else \"\")\n","    return idx, y, smiles\n","\n","# ====== metrics & CI ======\n","def pr_auc(y,p):\n","    prec, rec, _ = precision_recall_curve(y, p)\n","    return float(auc(rec, prec))\n","\n","def roc_auc(y,p):\n","    try: return float(roc_auc_score(y,p))\n","    except Exception: return float(\"nan\")\n","\n","def f1_at(y,p,thr):\n","    return float(f1_score(y,(p>=thr).astype(int),zero_division=0))\n","\n","def best_f1(y,p):\n","    prec,rec,thr=precision_recall_curve(y,p)\n","    thr=np.append(thr,1.0)\n","    f1=2*prec*rec/np.clip(prec+rec,1e-9,None)\n","    i=int(np.nanargmax(f1))\n","    return float(thr[i]), float(f1[i]), float(prec[i]), float(rec[i])\n","\n","_compute_best_f1 = best_f1\n","\n","def confusion_counts(y,p,thr):\n","    pred=(p>=thr).astype(int)\n","    tp=int(((pred==1)&(y==1)).sum())\n","    fp=int(((pred==1)&(y==0)).sum())\n","    tn=int(((pred==0)&(y==0)).sum())\n","    fn=int(((pred==0)&(y==1)).sum())\n","    return tp,fp,tn,fn\n","\n","def bootstrap_ci(metric_fn, y, p, n_boot=2000, seed=42, stratified=True):\n","    \"\"\"Return (point, lo95, hi95) using bootstrap. metric_fn(y, p) -> float\"\"\"\n","    rng = np.random.default_rng(seed)\n","    n=len(y)\n","    if stratified:\n","        pos_idx=np.where(y==1)[0]; neg_idx=np.where(y==0)[0]\n","        n_pos=len(pos_idx); n_neg=len(neg_idx)\n","    vals=[]\n","    for _ in range(n_boot):\n","        if stratified and n_pos>0 and n_neg>0:\n","            samp_pos = rng.choice(pos_idx, size=n_pos, replace=True)\n","            samp_neg = rng.choice(neg_idx, size=n_neg, replace=True)\n","            samp = np.concatenate([samp_pos, samp_neg])\n","        else:\n","            samp = rng.choice(np.arange(n), size=n, replace=True)\n","        yy=y[samp]; pp=p[samp]\n","        try:\n","            vals.append(float(metric_fn(yy,pp)))\n","        except Exception:\n","            continue\n","    vals=np.array(vals, dtype=float)\n","    point=float(metric_fn(y,p))\n","    lo=float(np.nanpercentile(vals, 2.5)) if len(vals)>0 else float(\"nan\")\n","    hi=float(np.nanpercentile(vals,97.5)) if len(vals)>0 else float(\"nan\")\n","    return point, lo, hi\n","\n","# ====== curves saving ======\n","def save_roc(out_png, out_csv, y, p, title):\n","    if np.unique(y).size<2:\n","        print(f\"[SKIP] ROC undefined (single-class labels). {title}\")\n","        return None\n","    fpr,tpr,thr = roc_curve(y,p)\n","    roc = roc_auc_score(y,p)\n","    pd.DataFrame({\"fpr\":fpr,\"tpr\":tpr,\"threshold\":thr}).to_csv(out_csv, index=False)\n","    plt.figure()\n","    plt.plot(fpr,tpr,label=f\"AUC={roc:.4f}\")\n","    plt.plot([0,1],[0,1], linestyle=\"--\")\n","    plt.xlabel(\"False Positive Rate\"); plt.ylabel(\"True Positive Rate\")\n","    plt.title(title); plt.legend(); plt.tight_layout()\n","    plt.savefig(out_png, dpi=160); plt.close()\n","    print(f\"[ROC] {title} -> {out_png} | {out_csv}\")\n","    return roc\n","\n","def save_pr(out_png, out_csv, y, p, title):\n","    prec,rec,thr = precision_recall_curve(y,p)\n","    pr = auc(rec,prec)\n","    pd.DataFrame({\"recall\":rec, \"precision\":prec, \"threshold\":np.append(thr,np.nan)}).to_csv(out_csv, index=False)\n","    plt.figure()\n","    plt.plot(rec,prec,label=f\"AUC={pr:.4f}\")\n","    plt.xlabel(\"Recall\"); plt.ylabel(\"Precision\")\n","    plt.title(title); plt.legend(); plt.tight_layout()\n","    plt.savefig(out_png, dpi=160); plt.close()\n","    print(f\"[PR ] {title} -> {out_png} | {out_csv}\")\n","    return pr\n","\n","# ====== run ======\n","def main():\n","    Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n","\n","    # Load internal data\n","    data_list = load_pyg_list(DATA_PT)\n","    idx, y, smiles = evaluable_subset(data_list)\n","    data_eval = [data_list[i] for i in idx]\n","    y = np.asarray(y, dtype=int)\n","    print(f\"[INFO] Internal evaluable N={len(y)} | positives={y.sum()} | negatives={(y==0).sum()}\")\n","\n","    # Dims\n","    X_DIM,E_DIM,G_DIM,R_DIM = dims_from_sample(data_eval[0])\n","    dims = (X_DIM,E_DIM,G_DIM,R_DIM)\n","    print(\"[INFO] dims:\", {\"x\":X_DIM,\"edge\":E_DIM,\"g\":G_DIM,\"r\":R_DIM})\n","\n","    # --- M4 ã®ç¢ºç‡ ---\n","    pM4, wM4 = family_probs(data_eval, M4_DIR, dims)\n","    p = pM4.copy()  # ãã®ã¾ã¾æœ€çµ‚ç¢ºç‡ã¨ã—ã¦ä½¿ç”¨\n","\n","    print(f\"[INFO] Using M4 only | optional CV-PR weight (info): {wM4:.3f}\")\n","\n","    # Save per-sample predictionsï¼ˆäº’æ›ã®ãŸã‚ p_ens ã‚‚ä¿å­˜ï¼‰\n","    df_pred = pd.DataFrame({\n","        \"SMILES\": smiles,\n","        \"y_true\": y,\n","        \"p_M4\": pM4,\n","        \"p_ens\": p,   # ä¸‹æµã‚¹ã‚¯ãƒªãƒ—ãƒˆäº’æ›: p_ens = M4\n","    })\n","    pred_csv = f\"{OUT_DIR}/predictions_internal_MDR1-M4-HYB-v1.csv\"\n","    df_pred.to_csv(pred_csv, index=False)\n","    print(\"[SAVE] predictions ->\", pred_csv)\n","\n","    # Curves\n","    roc_png = f\"{OUT_DIR}/roc_internal_m4.png\"\n","    roc_csv = f\"{OUT_DIR}/roc_internal_m4.csv\"\n","    pr_png  = f\"{OUT_DIR}/pr_internal_m4.png\"\n","    pr_csv  = f\"{OUT_DIR}/pr_internal_m4.csv\"\n","    roc_auc_val = save_roc(roc_png, roc_csv, y, p, \"MDR1-M4-HYB-v1 - INTERNAL ROC\")\n","    pr_auc_val  = save_pr (pr_png , pr_csv , y, p, \"MDR1-M4-HYB-v1 - INTERNAL PR\")\n","\n","    # Point metrics + 95% CIs (bootstrap, stratified)\n","    roc_point, roc_lo, roc_hi = bootstrap_ci(roc_auc, y, p, n_boot=N_BOOT, seed=SEED, stratified=True)\n","    pr_point , pr_lo , pr_hi  = bootstrap_ci(pr_auc , y, p, n_boot=N_BOOT, seed=SEED, stratified=True)\n","    # F1 @ fixed threshold\n","    f1_fixed_point, f1_fixed_lo, f1_fixed_hi = bootstrap_ci(lambda yy,pp: f1_at(yy,pp,FIXED_THR),\n","                                                            y, p, n_boot=N_BOOT, seed=SEED, stratified=True)\n","    # Best-F1ï¼ˆå„ãƒ–ãƒ¼ãƒˆã§ã—ãã„å€¤å†æœ€é©åŒ–ï¼‰\n","    def f1_best_metric(yy,pp):\n","        _, f1b, _, _ = _compute_best_f1(yy,pp); return f1b\n","    f1_best_point, f1_best_lo, f1_best_hi = bootstrap_ci(f1_best_metric, y, p, n_boot=N_BOOT, seed=SEED, stratified=True)\n","\n","    # Confusion tables @0.5 and @Best-F1 thresholdï¼ˆæ¯é›†å›£ã§æ±ºã‚ãŸBestThrï¼‰\n","    best_thr, best_f1_val, best_prec, best_rec = _compute_best_f1(y,p)\n","    tp,fp,tn,fn = confusion_counts(y,p,FIXED_THR)\n","    tp_b,fp_b,tn_b,fn_b = confusion_counts(y,p,best_thr)\n","\n","    # Save metrics table\n","    rows = [\n","        [\"ROC-AUC\", roc_point, roc_lo, roc_hi, \"\"],\n","        [\"PR-AUC\",  pr_point,  pr_lo,  pr_hi,  \"\"],\n","        [f\"F1@{FIXED_THR:.2f}\", f1_fixed_point, f1_fixed_lo, f1_fixed_hi, f\"thr={FIXED_THR}\"],\n","        [\"F1@Best\", f1_best_point, f1_best_lo, f1_best_hi, f\"thrâ‰ˆ{best_thr:.4f}, Precâ‰ˆ{best_prec:.4f}, Recâ‰ˆ{best_rec:.4f}\"],\n","    ]\n","    df_stats = pd.DataFrame(rows, columns=[\"metric\",\"point\",\"ci_2.5\",\"ci_97.5\",\"note\"])\n","    stats_csv = f\"{OUT_DIR}/stats_internal_MDR1-M4-HYB-v1.csv\"\n","    df_stats.to_csv(stats_csv, index=False)\n","    print(\"[SAVE] stats ->\", stats_csv)\n","\n","    # Save confusion tables\n","    df_cm = pd.DataFrame([\n","        [\"@fixed\", FIXED_THR, tp,fp,tn,fn],\n","        [\"@bestF1\", best_thr, tp_b,fp_b,tn_b,fn_b],\n","    ], columns=[\"mode\",\"threshold\",\"TP\",\"FP\",\"TN\",\"FN\"])\n","    cm_csv = f\"{OUT_DIR}/confusion_internal_MDR1-M4-HYB-v1.csv\"\n","    df_cm.to_csv(cm_csv, index=False)\n","    print(\"[SAVE] confusion ->\", cm_csv)\n","\n","    print(\"\\n=== SUMMARY ===\")\n","    print(df_stats.to_string(index=False))\n","    print(\"\\nConfusion (counts):\")\n","    print(df_cm.to_string(index=False))\n","    print(f\"\\nCurves saved to: {roc_png} , {pr_png}\")\n","    print(f\"Predictions: {pred_csv}\")\n","\n","if __name__==\"__main__\":\n","    main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Di02GqW4OiBe","executionInfo":{"status":"ok","timestamp":1760685537718,"user_tz":-540,"elapsed":35893,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"5fa70c91-1d73-4ae3-e41f-5a67d79e69a4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[INFO] Internal evaluable N=7321 | positives=1524 | negatives=5797\n","[INFO] dims: {'x': 5, 'edge': 6, 'g': 7, 'r': 10}\n","[INFO] Using M4 only | optional CV-PR weight (info): 0.619\n","[SAVE] predictions -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/predictions_internal_MDR1-M4-HYB-v1.csv\n","[ROC] MDR1-M4-HYB-v1 - INTERNAL ROC -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/roc_internal_m4.png | /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/roc_internal_m4.csv\n","[PR ] MDR1-M4-HYB-v1 - INTERNAL PR -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/pr_internal_m4.png | /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/pr_internal_m4.csv\n","[SAVE] stats -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/stats_internal_MDR1-M4-HYB-v1.csv\n","[SAVE] confusion -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/confusion_internal_MDR1-M4-HYB-v1.csv\n","\n","=== SUMMARY ===\n"," metric    point   ci_2.5  ci_97.5                                note\n","ROC-AUC 0.987072 0.985025 0.989044                                    \n"," PR-AUC 0.944732 0.935207 0.953370                                    \n","F1@0.50 0.885295 0.874592 0.895228                             thr=0.5\n","F1@Best 0.899968 0.890954 0.910968 thrâ‰ˆ0.5991, Precâ‰ˆ0.8826, Recâ‰ˆ0.9180\n","\n","Confusion (counts):\n","   mode  threshold   TP  FP   TN  FN\n"," @fixed   0.500000 1478 337 5460  46\n","@bestF1   0.599133 1399 186 5611 125\n","\n","Curves saved to: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/roc_internal_m4.png , /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/pr_internal_m4.png\n","Predictions: /content/drive/MyDrive/Chemoinfo_MDR1_ver7/reports_internal_MDR1-M4-HYB-v1/predictions_internal_MDR1-M4-HYB-v1.csv\n"]}]},{"cell_type":"code","source":["# === One-cell Figure Generator for MDR1-M4-HYB-v1 (Index-safe, RDKit-robust) ===\n","# Generates: (A) UMAP, (B) Novelty vs PR-AUC, (C) Reliability (Brier/ECE),\n","#            (D) Top-K Precision, (E) Attribution (ECFP surrogate),\n","#            (F) Misclassification substructure heatmap.\n","# Inputs:\n","#   ROOT/data_graph_with_smiles.pt\n","#   ROOT/reports_internal_MDR1-M4-HYB-v1/predictions_internal_MDR1-M4-HYB-v1.csv\n","# Outputs under ROOT/figs_mdr1_final_m4/\n","\n","import os, sys, subprocess, json, numpy as np, pandas as pd, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# RDKitã®MorganGeneratorç³»Deprecationã‚’é»™ã‚‰ã›ã‚‹\n","warnings.filterwarnings(\"ignore\", message=\".*MorganGenerator.*\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","from rdkit import RDLogger\n","from rdkit import rdBase\n","RDLogger.DisableLog(\"rdApp.*\")\n","rdBase.DisableLog(\"rdApp.warning\")\n","\n","# --------- CONFIG ---------\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PT = f\"{ROOT}/data_graph_with_smiles.pt\"\n","PRED_CSV = f\"{ROOT}/reports_internal_MDR1-M4-HYB-v1/predictions_internal_MDR1-M4-HYB-v1.csv\"\n","OUT_DIR = f\"{ROOT}/figs_mdr1_final_m4\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# --------- Helper: quiet pip ---------\n","def _pip_install(cmd_list):\n","    try:\n","        subprocess.check_call(cmd_list, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n","        return True\n","    except Exception:\n","        return False\n","\n","def _ensure(pkg, pip_name=None):\n","    try:\n","        __import__(pkg)\n","        return True\n","    except Exception:\n","        return _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name or pkg])\n","\n","# sklearn / umap / matplotlib\n","_ensure(\"sklearn\", \"scikit-learn\")\n","_ensure(\"umap\", \"umap-learn\")\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_recall_curve, auc\n","from sklearn.calibration import calibration_curve\n","from sklearn.linear_model import LogisticRegression\n","\n","# torch / pyg\n","_ensure(\"torch\", \"torch\")\n","try:\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","except Exception:\n","    _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-geometric\"])\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","import torch\n","\n","# RDKitï¼ˆä»»æ„ï¼‰\n","HAVE_RDKIT = True\n","try:\n","    import rdkit  # quick probe\n","except Exception:\n","    if not _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit==2023.9.5\"]):\n","        if not _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit\"]):\n","            HAVE_RDKIT = False\n","\n","if HAVE_RDKIT:\n","    from rdkit import Chem\n","    from rdkit.Chem import AllChem, Draw\n","    from rdkit import DataStructs\n","\n","# --------- Load internal data ---------\n","def load_pyg_list(path):\n","    add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","assert os.path.exists(DATA_PT), f\"Missing: {DATA_PT}\"\n","assert os.path.exists(PRED_CSV), f\"Missing: {PRED_CSV}\"\n","\n","dl = load_pyg_list(DATA_PT)\n","pred = pd.read_csv(PRED_CSV)\n","\n","# ---- å®‰å…¨ãªçµåˆï¼šå„è¡Œã« gr_vec ã‚’ç´ã¥ã‘ã¦ã‹ã‚‰ merge ã™ã‚‹ ----\n","records = []\n","for d in dl:\n","    smiles = getattr(d, \"smiles\", \"\")\n","    yv = int(getattr(d, \"y\", -1))\n","    yv = yv if yv in (0,1) else -1\n","    g = np.asarray(getattr(d, \"g\")).reshape(-1)\n","    r = np.asarray(getattr(d, \"r\")).reshape(-1)\n","    gr_vec = np.concatenate([g, r], axis=0)  # 17-dim (g7 + r10)\n","    records.append({\"SMILES\": smiles, \"y_true\": yv, \"gr_vec\": gr_vec})\n","base = pd.DataFrame(records)\n","\n","# æœŸå¾…ã™ã‚‹åˆ—ï¼ˆM4ã®ã¿ï¼‰\n","needed_cols = {\"SMILES\",\"p_M4\",\"p_ens\"}\n","missing = sorted(list(needed_cols - set(pred.columns)))\n","assert not missing, f\"Prediction CSV missing columns: {missing}\"\n","\n","# SMILESã§çµåˆï¼ˆåŒä¸€SMILESãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯é‡è¤‡è¡ŒãŒã§ãã‚‹ãŒ gr_vec ã‚‚è¤‡è£½ã•ã‚Œã‚‹ï¼‰\n","df = base.merge(pred[[\"SMILES\",\"p_M4\",\"p_ens\"]], on=\"SMILES\", how=\"inner\")\n","df = df[df[\"y_true\"].isin([0,1])].reset_index(drop=True)\n","\n","# UMAPç”¨ã®è¡Œåˆ—ã¯ df[\"gr_vec\"] ã‹ã‚‰ç”Ÿæˆï¼ˆå¸¸ã«è¡Œã¨ä¸€è‡´ï¼‰\n","gr_mat = np.vstack(df[\"gr_vec\"].to_numpy())\n","\n","# --------- (A) UMAP on [g;r] ---------\n","try:\n","    import umap\n","    reducer = umap.UMAP(n_neighbors=30, min_dist=0.1, metric=\"euclidean\", random_state=42)\n","    X2 = reducer.fit_transform(gr_mat)\n","    plt.figure()\n","    pos = df[\"y_true\"].values==1\n","    neg = df[\"y_true\"].values==0\n","    plt.scatter(X2[neg,0], X2[neg,1], s=8, alpha=0.7, label=\"Negative\")\n","    plt.scatter(X2[pos,0], X2[pos,1], s=8, alpha=0.7, marker=\"x\", label=\"Positive\")\n","    plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\"); plt.title(\"A) UMAP of molecular descriptors (g+r)\")\n","    plt.legend(); plt.tight_layout()\n","    A_PATH = os.path.join(OUT_DIR, \"A_umap_gr.png\")\n","    plt.savefig(A_PATH, dpi=160); plt.close()\n","except Exception as e:\n","    A_PATH = None\n","    print(\"[WARN] UMAP failed:\", e)\n","\n","# --------- (B) Novelty proxy vs PR-AUCï¼ˆRDKitãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰ ---------\n","B_PATH = None\n","if HAVE_RDKIT:\n","    def morgan_fp(smiles, radius=2, nBits=2048):\n","        m = Chem.MolFromSmiles(smiles)\n","        if m is None: return None\n","        return AllChem.GetMorganFingerprintAsBitVect(m, radius, nBits=nBits)\n","\n","    fps = [morgan_fp(s) for s in df[\"SMILES\"].tolist()]\n","    valid_idx = [i for i,f in enumerate(fps) if f is not None]\n","\n","    max_sim = np.zeros(len(df), dtype=float)\n","    for i in valid_idx:\n","        fi = fps[i]\n","        best = 0.0\n","        for j in valid_idx:\n","            if i==j: continue\n","            best = max(best, DataStructs.TanimotoSimilarity(fi, fps[j]))\n","        max_sim[i] = best\n","    df[\"max_sim_rest\"] = max_sim\n","    bins = [0.0, 0.4, 0.6, 0.7, 0.8, 0.9, 0.95, 1.01]\n","    df[\"sim_bin\"] = pd.cut(df[\"max_sim_rest\"], bins=bins, right=False)\n","\n","    rows_b = []\n","    for b in df[\"sim_bin\"].dropna().unique().sort_values():\n","        sub = df[df[\"sim_bin\"]==b]\n","        if sub[\"y_true\"].nunique()<2:\n","            pr = np.nan\n","        else:\n","            prec, rec, _ = precision_recall_curve(sub[\"y_true\"].values, sub[\"p_ens\"].values)\n","            pr = auc(rec, prec)\n","        rows_b.append({\"bin\": str(b), \"n\": len(sub), \"pr_auc\": pr})\n","    df_b = pd.DataFrame(rows_b)\n","\n","    plt.figure()\n","    plt.plot(np.arange(len(df_b)), df_b[\"pr_auc\"].values, marker=\"o\")\n","    plt.xticks(np.arange(len(df_b)), df_b[\"bin\"].tolist(), rotation=45, ha=\"right\")\n","    plt.ylabel(\"PR-AUC\"); plt.xlabel(\"Max similarity to others (bin)\")\n","    plt.title(\"B) Novelty proxy vs PR-AUC\")\n","    plt.tight_layout()\n","    B_PATH = os.path.join(OUT_DIR, \"B_novelty_vs_prauc.png\")\n","    plt.savefig(B_PATH, dpi=160); plt.close()\n","else:\n","    print(\"[SKIP] RDKit unavailable -> skip panel (B).\")\n","\n","# --------- (C) Reliability curve (Brier/ECE) ---------\n","frac_pos, mean_pred = calibration_curve(df[\"y_true\"].values, df[\"p_ens\"].values, n_bins=10, strategy=\"quantile\")\n","brier = np.mean((df[\"p_ens\"].values - df[\"y_true\"].values)**2)\n","ece = np.mean(np.abs(frac_pos - mean_pred))\n","plt.figure()\n","plt.plot([0,1],[0,1], linestyle=\"--\")\n","plt.plot(mean_pred, frac_pos, marker=\"o\")\n","plt.xlabel(\"Predicted probability\"); plt.ylabel(\"Observed frequency\")\n","plt.title(f\"C) Reliability (Brier={brier:.3f}, ECE={ece:.3f})\")\n","plt.tight_layout()\n","C_PATH = os.path.join(OUT_DIR, \"C_reliability.png\")\n","plt.savefig(C_PATH, dpi=160); plt.close()\n","\n","# --------- (D) Top-K precision ---------\n","def precision_at_k(y, p, k):\n","    k = max(1, min(k, len(p)))\n","    idx = np.argsort(-p)[:k]\n","    return float(np.mean(y[idx]))\n","Ks = [10,25,50,100,200,500,1000]\n","p_at = [precision_at_k(df[\"y_true\"].values, df[\"p_ens\"].values, k) for k in Ks]\n","plt.figure()\n","plt.plot(Ks, p_at, marker=\"o\")\n","plt.xlabel(\"K\"); plt.ylabel(\"Precision@K\")\n","plt.title(\"D) Top-K Precision curve\")\n","plt.tight_layout()\n","D_PATH = os.path.join(OUT_DIR, \"D_topk_precision.png\")\n","plt.savefig(D_PATH, dpi=160); plt.close()\n","\n","# --------- (E) Attribution via ECFP surrogateï¼ˆRDKitãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰ ---------\n","E_PATHS = []\n","if HAVE_RDKIT:\n","    bit_infos, bit_mats = [], []\n","    ys = df[\"y_true\"].values\n","    for s in df[\"SMILES\"].tolist():\n","        m = Chem.MolFromSmiles(s)\n","        if m is None:\n","            bit_infos.append({})\n","            bit_mats.append(np.zeros((2048,), dtype=np.uint8))\n","            continue\n","        info = {}\n","        bv = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048, bitInfo=info)\n","        arr = np.zeros((2048,), dtype=np.uint8)\n","        DataStructs.ConvertToNumpyArray(bv, arr)\n","        bit_infos.append(info); bit_mats.append(arr)\n","    X = np.vstack(bit_mats)\n","    try:\n","        clf = LogisticRegression(max_iter=200, n_jobs=1)\n","    except TypeError:\n","        clf = LogisticRegression(max_iter=200)\n","    clf.fit(X, ys)\n","    coef = clf.coef_[0]\n","\n","    p = df[\"p_ens\"].values\n","    pred = (p>=0.5).astype(int)\n","    TP_idx = np.where((pred==1)&(ys==1))[0][:2]\n","    FP_idx = np.where((pred==1)&(ys==0))[0][:2]\n","    FN_idx = np.where((pred==0)&(ys==1))[0][:2]\n","\n","    def atom_importance_from_bits(mol, bit_info, coefs):\n","        n = mol.GetNumAtoms()\n","        scores = np.zeros(n, dtype=float)\n","        for b, envs in bit_info.items():\n","            w = coefs[b]\n","            for (atom_idx, radius) in envs:\n","                amap = Chem.FindAtomEnvironmentOfRadiusN(mol, radius, atom_idx)\n","                atoms = {atom_idx}\n","                for bond_idx in amap:\n","                    bnd = mol.GetBondWithIdx(bond_idx)\n","                    atoms.add(bnd.GetBeginAtomIdx()); atoms.add(bnd.GetEndAtomIdx())\n","                for a in atoms: scores[a] += w\n","        if (scores.max() - scores.min())>1e-9:\n","            scores = (scores - scores.min())/(scores.max()-scores.min())\n","        return scores\n","\n","    def draw_with_atom_scores(smiles, scores, path, title):\n","        mol = Chem.MolFromSmiles(smiles)\n","        if mol is None: return False\n","        atom_cols = {i:(float(scores[i]), 0.0, 0.0) for i in range(mol.GetNumAtoms())}\n","        d2d = Draw.MolDraw2DCairo(500, 400)\n","        Draw.PrepareAndDrawMolecule(d2d, mol, highlightAtoms=list(atom_cols.keys()), highlightAtomColors=atom_cols, legend=title)\n","        d2d.FinishDrawing()\n","        with open(path, \"wb\") as f: f.write(d2d.GetDrawingText())\n","        return True\n","\n","    def make_attr_panels(indices, label):\n","        outs=[]\n","        for i in indices:\n","            s = df.loc[i,\"SMILES\"]\n","            m = Chem.MolFromSmiles(s)\n","            if m is None: continue\n","            scores = atom_importance_from_bits(m, bit_infos[i], coef)\n","            pth = os.path.join(OUT_DIR, f\"E_attr_{label}_{i}.png\")\n","            draw_with_atom_scores(s, scores, pth, title=f\"{label} #{i}  p={p[i]:.2f}  y={ys[i]}\")\n","            outs.append(pth)\n","        return outs\n","\n","    E_PATHS += make_attr_panels(TP_idx, \"TP\")\n","    E_PATHS += make_attr_panels(FP_idx, \"FP\")\n","    E_PATHS += make_attr_panels(FN_idx, \"FN\")\n","else:\n","    print(\"[SKIP] RDKit unavailable -> skip panel (E).\")\n","\n","# --------- (F) Misclassification substructure heatmapï¼ˆRDKitãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰ ---------\n","F_PATH = None\n","if HAVE_RDKIT:\n","    SMARTS = {\n","        \"AromaticRing\": \"a1aaaaa1\",\n","        \"AliphaticRing\": \"[R;!a]\",\n","        \"Halogen\": \"[F,Cl,Br,I]\",\n","        \"QuaternaryAmmonium\": \"[N+](C)(C)(C)C\",\n","        \"TertiaryAmine\": \"[NX3;H0;!$(NC=O)]\",\n","        \"CarboxylicAcid\": \"C(=O)[OH]\",\n","        \"Amide\": \"C(=O)N\",\n","        \"Ether\": \"COC\",\n","        \"Sulfonamide\": \"S(=O)(=O)N\",\n","        \"Nitrile\": \"C#N\",\n","    }\n","    ps = {k: Chem.MolFromSmarts(v) for k,v in SMARTS.items()}\n","    ys = df[\"y_true\"].values\n","    p = df[\"p_ens\"].values\n","    pred = (p>=0.5).astype(int)\n","    groups = {\n","        \"TP\": np.where((pred==1)&(ys==1))[0],\n","        \"FP\": np.where((pred==1)&(ys==0))[0],\n","        \"TN\": np.where((pred==0)&(ys==0))[0],\n","        \"FN\": np.where((pred==0)&(ys==1))[0],\n","    }\n","    counts = pd.DataFrame(0, index=list(SMARTS.keys()), columns=list(groups.keys()))\n","    totals = {g: len(idx) for g, idx in groups.items()}\n","\n","    for name, patt in ps.items():\n","        for g, idxs in groups.items():\n","            c = 0\n","            for i in idxs:\n","                m = Chem.MolFromSmiles(df.loc[i,\"SMILES\"])\n","                if m is None: continue\n","                if m.HasSubstructMatch(patt): c += 1\n","            counts.loc[name, g] = c\n","\n","    rates = counts.copy().astype(float)\n","    for g in groups.keys():\n","        rates[g] = rates[g] / max(1, totals[g])  # 0å‰²å›é¿ã€0ã€œ1ã®å‰²åˆã«\n","\n","    # â˜… ä½ã„=é’ â†’ é«˜ã„=èµ¤ã€å‡¡ä¾‹ã‚ã‚Š\n","    plt.figure(figsize=(7, 5))\n","    im = plt.imshow(\n","        rates.values,\n","        aspect=\"auto\",\n","        cmap=\"bwr\",     # blue-white-redï¼ˆä½:é’ â†’ é«˜:èµ¤ï¼‰\n","        vmin=0.0,\n","        vmax=1.0        # æ¯”ç‡ãªã®ã§0ã€œ1ã«å›ºå®š\n","    )\n","    plt.yticks(np.arange(len(rates.index)), rates.index.tolist())\n","    plt.xticks(np.arange(len(rates.columns)), rates.columns.tolist())\n","    plt.title(\"F) Misclassification substructure heatmap (rate)\")\n","    cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n","    cbar.set_label(\"Rate\", rotation=90)\n","    plt.tight_layout()\n","\n","    F_PATH = os.path.join(OUT_DIR, \"F_misclf_substruct_heatmap.png\")\n","    plt.savefig(F_PATH, dpi=160); plt.close()\n","else:\n","    print(\"[SKIP] RDKit unavailable -> skip panel (F).\")\n","\n","# --------- Save working table & report paths ---------\n","WORK_TBL = os.path.join(OUT_DIR, \"working_table.csv\")\n","# RDKitãŒç„¡ã„å ´åˆã€max_simã‚„sim_binãŒç„¡ã„ã®ã§NaNã§ç”¨æ„\n","if \"max_sim_rest\" not in df.columns:\n","    df[\"max_sim_rest\"] = np.nan\n","    df[\"sim_bin\"] = np.nan\n","df[[\"SMILES\",\"y_true\",\"p_ens\",\"max_sim_rest\",\"sim_bin\"]].to_csv(WORK_TBL, index=False)\n","\n","outputs = {\n","    \"A_umap_gr.png\": A_PATH,\n","    \"B_novelty_vs_prauc.png\": B_PATH,\n","    \"C_reliability.png\": C_PATH,\n","    \"D_topk_precision.png\": D_PATH,\n","    \"E_attr_paths\": E_PATHS,\n","    \"F_misclf_heatmap.png\": F_PATH,\n","    \"working_table.csv\": WORK_TBL,\n","    \"note\": \"Panels B/E/F require RDKit. Index mismatch fixed by carrying gr_vec inside the merged DataFrame. p_ens is M4 probability.\"\n","}\n","print(json.dumps(outputs, indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5RKXNqBxUhTo","executionInfo":{"status":"ok","timestamp":1760687587636,"user_tz":-540,"elapsed":230811,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"86d032fd-24b8-4172-ccdf-8f60d69e73e4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"A_umap_gr.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/A_umap_gr.png\",\n","  \"B_novelty_vs_prauc.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/B_novelty_vs_prauc.png\",\n","  \"C_reliability.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/C_reliability.png\",\n","  \"D_topk_precision.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/D_topk_precision.png\",\n","  \"E_attr_paths\": [\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/E_attr_TP_79.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/E_attr_TP_80.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/E_attr_FP_19.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/E_attr_FP_30.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/E_attr_FN_225.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/E_attr_FN_226.png\"\n","  ],\n","  \"F_misclf_heatmap.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/F_misclf_substruct_heatmap.png\",\n","  \"working_table.csv\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m4/working_table.csv\",\n","  \"note\": \"Panels B/E/F require RDKit. Index mismatch fixed by carrying gr_vec inside the merged DataFrame. p_ens is M4 probability.\"\n","}\n"]}]},{"cell_type":"code","source":["# === One-cell Figure Generator for MDR1-M1M4-cvpr (Index-safe, RDKit-robust) ===\n","# Generates: (A) UMAP, (B) Novelty vs PR-AUC, (C) Reliability (Brier/ECE),\n","#            (D) Top-K Precision, (E) Attribution (ECFP surrogate),\n","#            (F) Misclassification substructure heatmap.\n","# Inputs:\n","#   ROOT/data_graph_with_smiles.pt\n","#   ROOT/reports_internal_MDR1-M1M4-cvpr/predictions_internal_MDR1-M1M4-cvpr.csv\n","# Outputs under ROOT/figs_mdr1_final_m1m4_cvpr/\n","\n","import os, sys, subprocess, json, numpy as np, pandas as pd, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# RDKitã®MorganGeneratorç³»Deprecationã‚’é»™ã‚‰ã›ã‚‹\n","warnings.filterwarnings(\"ignore\", message=\".*MorganGenerator.*\", category=DeprecationWarning)\n","warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n","\n","from rdkit import RDLogger\n","from rdkit import rdBase\n","RDLogger.DisableLog(\"rdApp.*\")\n","rdBase.DisableLog(\"rdApp.warning\")\n","\n","# --------- CONFIG ---------\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PT = f\"{ROOT}/data_graph_with_smiles.pt\"\n","PRED_CSV = f\"{ROOT}/reports_internal_MDR1-M1M4-cvpr/predictions_internal_MDR1-M1M4-cvpr.csv\"\n","OUT_DIR = f\"{ROOT}/figs_mdr1_final_m1m4_cvpr\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# --------- Helper: quiet pip ---------\n","def _pip_install(cmd_list):\n","    try:\n","        subprocess.check_call(cmd_list, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n","        return True\n","    except Exception:\n","        return False\n","\n","def _ensure(pkg, pip_name=None):\n","    try:\n","        __import__(pkg)\n","        return True\n","    except Exception:\n","        return _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name or pkg])\n","\n","# sklearn / umap / matplotlib\n","_ensure(\"sklearn\", \"scikit-learn\")\n","_ensure(\"umap\", \"umap-learn\")\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import precision_recall_curve, auc\n","from sklearn.calibration import calibration_curve\n","from sklearn.linear_model import LogisticRegression\n","\n","# torch / pyg\n","_ensure(\"torch\", \"torch\")\n","try:\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","except Exception:\n","    _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-geometric\"])\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","import torch\n","\n","# RDKitï¼ˆä»»æ„ï¼‰\n","HAVE_RDKIT = True\n","try:\n","    import rdkit  # quick probe\n","except Exception:\n","    if not _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit==2023.9.5\"]):\n","        if not _pip_install([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"rdkit\"]):\n","            HAVE_RDKIT = False\n","\n","if HAVE_RDKIT:\n","    from rdkit import Chem\n","    from rdkit.Chem import AllChem, Draw\n","    from rdkit import DataStructs\n","\n","# --------- Load internal data ---------\n","def load_pyg_list(path):\n","    add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","assert os.path.exists(DATA_PT), f\"Missing: {DATA_PT}\"\n","assert os.path.exists(PRED_CSV), f\"Missing: {PRED_CSV}\"\n","\n","dl = load_pyg_list(DATA_PT)\n","pred = pd.read_csv(PRED_CSV)\n","\n","# ---- å®‰å…¨ãªçµåˆï¼šå„è¡Œã« gr_vec ã‚’ç´ã¥ã‘ã¦ã‹ã‚‰ merge ã™ã‚‹ ----\n","records = []\n","for d in dl:\n","    smiles = getattr(d, \"smiles\", \"\")\n","    yv = int(getattr(d, \"y\", -1))\n","    yv = yv if yv in (0,1) else -1\n","    g = np.asarray(getattr(d, \"g\")).reshape(-1)\n","    r = np.asarray(getattr(d, \"r\")).reshape(-1)\n","    gr_vec = np.concatenate([g, r], axis=0)  # 17-dim (g7 + r10)\n","    records.append({\"SMILES\": smiles, \"y_true\": yv, \"gr_vec\": gr_vec})\n","base = pd.DataFrame(records)\n","\n","# æœŸå¾…ã™ã‚‹åˆ—ï¼ˆcv_pr ã® M1+M4ï¼‰\n","needed_cols = {\"SMILES\",\"p_M1\",\"p_M4\",\"p_ens\"}  # è§£æã¯ p_ens ã‚’ä½¿ç”¨\n","missing = sorted(list(needed_cols - set(pred.columns)))\n","assert not missing, f\"Prediction CSV missing columns: {missing}\"\n","\n","# SMILESã§çµåˆï¼ˆåŒä¸€SMILESãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯é‡è¤‡è¡ŒãŒã§ãã‚‹ãŒ gr_vec ã‚‚è¤‡è£½ã•ã‚Œã‚‹ï¼‰\n","df = base.merge(pred[[\"SMILES\",\"p_M1\",\"p_M4\",\"p_ens\"]], on=\"SMILES\", how=\"inner\")\n","df = df[df[\"y_true\"].isin([0,1])].reset_index(drop=True)\n","\n","# UMAPç”¨ã®è¡Œåˆ—ã¯ df[\"gr_vec\"] ã‹ã‚‰ç”Ÿæˆï¼ˆå¸¸ã«è¡Œã¨ä¸€è‡´ï¼‰\n","gr_mat = np.vstack(df[\"gr_vec\"].to_numpy())\n","\n","# --------- (A) UMAP on [g;r] ---------\n","try:\n","    import umap\n","    reducer = umap.UMAP(n_neighbors=30, min_dist=0.1, metric=\"euclidean\", random_state=42)\n","    X2 = reducer.fit_transform(gr_mat)\n","    plt.figure()\n","    pos = df[\"y_true\"].values==1\n","    neg = df[\"y_true\"].values==0\n","    plt.scatter(X2[neg,0], X2[neg,1], s=8, alpha=0.7, label=\"Negative\")\n","    plt.scatter(X2[pos,0], X2[pos,1], s=8, alpha=0.7, marker=\"x\", label=\"Positive\")\n","    plt.xlabel(\"UMAP-1\"); plt.ylabel(\"UMAP-2\"); plt.title(\"A) UMAP of molecular descriptors (g+r)\")\n","    plt.legend(); plt.tight_layout()\n","    A_PATH = os.path.join(OUT_DIR, \"A_umap_gr.png\")\n","    plt.savefig(A_PATH, dpi=160); plt.close()\n","except Exception as e:\n","    A_PATH = None\n","    print(\"[WARN] UMAP failed:\", e)\n","\n","# --------- (B) Novelty proxy vs PR-AUCï¼ˆRDKitãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰ ---------\n","B_PATH = None\n","if HAVE_RDKIT:\n","    def morgan_fp(smiles, radius=2, nBits=2048):\n","        m = Chem.MolFromSmiles(smiles)\n","        if m is None: return None\n","        return AllChem.GetMorganFingerprintAsBitVect(m, radius, nBits=nBits)\n","\n","    fps = [morgan_fp(s) for s in df[\"SMILES\"].tolist()]\n","    valid_idx = [i for i,f in enumerate(fps) if f is not None]\n","\n","    max_sim = np.zeros(len(df), dtype=float)\n","    for i in valid_idx:\n","        fi = fps[i]\n","        best = 0.0\n","        for j in valid_idx:\n","            if i==j: continue\n","            best = max(best, DataStructs.TanimotoSimilarity(fi, fps[j]))\n","        max_sim[i] = best\n","    df[\"max_sim_rest\"] = max_sim\n","    bins = [0.0, 0.4, 0.6, 0.7, 0.8, 0.9, 0.95, 1.01]\n","    df[\"sim_bin\"] = pd.cut(df[\"max_sim_rest\"], bins=bins, right=False)\n","\n","    rows_b = []\n","    for b in df[\"sim_bin\"].dropna().unique().sort_values():\n","        sub = df[df[\"sim_bin\"]==b]\n","        if sub[\"y_true\"].nunique()<2:\n","            pr = np.nan\n","        else:\n","            prec, rec, _ = precision_recall_curve(sub[\"y_true\"].values, sub[\"p_ens\"].values)\n","            pr = auc(rec, prec)\n","        rows_b.append({\"bin\": str(b), \"n\": len(sub), \"pr_auc\": pr})\n","    df_b = pd.DataFrame(rows_b)\n","\n","    plt.figure()\n","    plt.plot(np.arange(len(df_b)), df_b[\"pr_auc\"].values, marker=\"o\")\n","    plt.xticks(np.arange(len(df_b)), df_b[\"bin\"].tolist(), rotation=45, ha=\"right\")\n","    plt.ylabel(\"PR-AUC\"); plt.xlabel(\"Max similarity to others (bin)\")\n","    plt.title(\"B) Novelty proxy vs PR-AUC\")\n","    plt.tight_layout()\n","    B_PATH = os.path.join(OUT_DIR, \"B_novelty_vs_prauc.png\")\n","    plt.savefig(B_PATH, dpi=160); plt.close()\n","else:\n","    print(\"[SKIP] RDKit unavailable -> skip panel (B).\")\n","\n","# --------- (C) Reliability curve (Brier/ECE) ---------\n","frac_pos, mean_pred = calibration_curve(df[\"y_true\"].values, df[\"p_ens\"].values, n_bins=10, strategy=\"quantile\")\n","brier = np.mean((df[\"p_ens\"].values - df[\"y_true\"].values)**2)\n","ece = np.mean(np.abs(frac_pos - mean_pred))\n","plt.figure()\n","plt.plot([0,1],[0,1], linestyle=\"--\")\n","plt.plot(mean_pred, frac_pos, marker=\"o\")\n","plt.xlabel(\"Predicted probability\"); plt.ylabel(\"Observed frequency\")\n","plt.title(f\"C) Reliability (Brier={brier:.3f}, ECE={ece:.3f})\")\n","plt.tight_layout()\n","C_PATH = os.path.join(OUT_DIR, \"C_reliability.png\")\n","plt.savefig(C_PATH, dpi=160); plt.close()\n","\n","# --------- (D) Top-K precision ---------\n","def precision_at_k(y, p, k):\n","    k = max(1, min(k, len(p)))\n","    idx = np.argsort(-p)[:k]\n","    return float(np.mean(y[idx]))\n","Ks = [10,25,50,100,200,500,1000]\n","p_at = [precision_at_k(df[\"y_true\"].values, df[\"p_ens\"].values, k) for k in Ks]\n","plt.figure()\n","plt.plot(Ks, p_at, marker=\"o\")\n","plt.xlabel(\"K\"); plt.ylabel(\"Precision@K\")\n","plt.title(\"D) Top-K Precision curve\")\n","plt.tight_layout()\n","D_PATH = os.path.join(OUT_DIR, \"D_topk_precision.png\")\n","plt.savefig(D_PATH, dpi=160); plt.close()\n","\n","# --------- (E) Attribution via ECFP surrogateï¼ˆRDKitãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰ ---------\n","E_PATHS = []\n","if HAVE_RDKIT:\n","    bit_infos, bit_mats = [], []\n","    ys = df[\"y_true\"].values\n","    for s in df[\"SMILES\"].tolist():\n","        m = Chem.MolFromSmiles(s)\n","        if m is None:\n","            bit_infos.append({})\n","            bit_mats.append(np.zeros((2048,), dtype=np.uint8))\n","            continue\n","        info = {}\n","        bv = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048, bitInfo=info)\n","        arr = np.zeros((2048,), dtype=np.uint8)\n","        DataStructs.ConvertToNumpyArray(bv, arr)\n","        bit_infos.append(info); bit_mats.append(arr)\n","    X = np.vstack(bit_mats)\n","    try:\n","        clf = LogisticRegression(max_iter=200, n_jobs=1)\n","    except TypeError:\n","        clf = LogisticRegression(max_iter=200)\n","    clf.fit(X, ys)\n","    coef = clf.coef_[0]\n","\n","    p = df[\"p_ens\"].values\n","    pred = (p>=0.5).astype(int)\n","    TP_idx = np.where((pred==1)&(ys==1))[0][:2]\n","    FP_idx = np.where((pred==1)&(ys==0))[0][:2]\n","    FN_idx = np.where((pred==0)&(ys==1))[0][:2]\n","\n","    def atom_importance_from_bits(mol, bit_info, coefs):\n","        n = mol.GetNumAtoms()\n","        scores = np.zeros(n, dtype=float)\n","        for b, envs in bit_info.items():\n","            w = coefs[b]\n","            for (atom_idx, radius) in envs:\n","                amap = Chem.FindAtomEnvironmentOfRadiusN(mol, radius, atom_idx)\n","                atoms = {atom_idx}\n","                for bond_idx in amap:\n","                    bnd = mol.GetBondWithIdx(bond_idx)\n","                    atoms.add(bnd.GetBeginAtomIdx()); atoms.add(bnd.GetEndAtomIdx())\n","                for a in atoms: scores[a] += w\n","        if (scores.max() - scores.min())>1e-9:\n","            scores = (scores - scores.min())/(scores.max()-scores.min())\n","        return scores\n","\n","    def draw_with_atom_scores(smiles, scores, path, title):\n","        mol = Chem.MolFromSmiles(smiles)\n","        if mol is None: return False\n","        atom_cols = {i:(float(scores[i]), 0.0, 0.0) for i in range(mol.GetNumAtoms())}\n","        d2d = Draw.MolDraw2DCairo(500, 400)\n","        Draw.PrepareAndDrawMolecule(d2d, mol, highlightAtoms=list(atom_cols.keys()), highlightAtomColors=atom_cols, legend=title)\n","        d2d.FinishDrawing()\n","        with open(path, \"wb\") as f: f.write(d2d.GetDrawingText())\n","        return True\n","\n","    def make_attr_panels(indices, label):\n","        outs=[]\n","        for i in indices:\n","            s = df.loc[i,\"SMILES\"]\n","            m = Chem.MolFromSmiles(s)\n","            if m is None: continue\n","            scores = atom_importance_from_bits(m, bit_infos[i], coef)\n","            pth = os.path.join(OUT_DIR, f\"E_attr_{label}_{i}.png\")\n","            draw_with_atom_scores(s, scores, pth, title=f\"{label} #{i}  p={p[i]:.2f}  y={ys[i]}\")\n","            outs.append(pth)\n","        return outs\n","\n","    E_PATHS += make_attr_panels(TP_idx, \"TP\")\n","    E_PATHS += make_attr_panels(FP_idx, \"FP\")\n","    E_PATHS += make_attr_panels(FN_idx, \"FN\")\n","else:\n","    print(\"[SKIP] RDKit unavailable -> skip panel (E).\")\n","\n","# --------- (F) Misclassification substructure heatmapï¼ˆRDKitãŒã‚ã‚‹æ™‚ã®ã¿ï¼‰ ---------\n","F_PATH = None\n","if HAVE_RDKIT:\n","    SMARTS = {\n","        \"AromaticRing\": \"a1aaaaa1\",\n","        \"AliphaticRing\": \"[R;!a]\",\n","        \"Halogen\": \"[F,Cl,Br,I]\",\n","        \"QuaternaryAmmonium\": \"[N+](C)(C)(C)C\",\n","        \"TertiaryAmine\": \"[NX3;H0;!$(NC=O)]\",\n","        \"CarboxylicAcid\": \"C(=O)[OH]\",\n","        \"Amide\": \"C(=O)N\",\n","        \"Ether\": \"COC\",\n","        \"Sulfonamide\": \"S(=O)(=O)N\",\n","        \"Nitrile\": \"C#N\",\n","    }\n","    ps = {k: Chem.MolFromSmarts(v) for k,v in SMARTS.items()}\n","    ys = df[\"y_true\"].values\n","    p = df[\"p_ens\"].values\n","    pred = (p>=0.5).astype(int)\n","    groups = {\n","        \"TP\": np.where((pred==1)&(ys==1))[0],\n","        \"FP\": np.where((pred==1)&(ys==0))[0],\n","        \"TN\": np.where((pred==0)&(ys==0))[0],\n","        \"FN\": np.where((pred==0)&(ys==1))[0],\n","    }\n","    counts = pd.DataFrame(0, index=list(SMARTS.keys()), columns=list(groups.keys()))\n","    totals = {g: len(idx) for g, idx in groups.items()}\n","\n","    for name, patt in ps.items():\n","        for g, idxs in groups.items():\n","            c = 0\n","            for i in idxs:\n","                m = Chem.MolFromSmiles(df.loc[i,\"SMILES\"])\n","                if m is None: continue\n","                if m.HasSubstructMatch(patt): c += 1\n","            counts.loc[name, g] = c\n","\n","    rates = counts.copy().astype(float)\n","    for g in groups.keys():\n","        rates[g] = rates[g] / max(1, totals[g])  # 0å‰²å›é¿ã€0ã€œ1ã®å‰²åˆã«\n","\n","    # â˜… ä½ã„=é’ â†’ é«˜ã„=èµ¤ã€å‡¡ä¾‹ã‚ã‚Š\n","    plt.figure(figsize=(7, 5))\n","    im = plt.imshow(\n","        rates.values,\n","        aspect=\"auto\",\n","        cmap=\"bwr\",     # blue-white-redï¼ˆä½:é’ â†’ é«˜:èµ¤ï¼‰\n","        vmin=0.0,\n","        vmax=1.0        # æ¯”ç‡ãªã®ã§0ã€œ1ã«å›ºå®š\n","    )\n","    plt.yticks(np.arange(len(rates.index)), rates.index.tolist())\n","    plt.xticks(np.arange(len(rates.columns)), rates.columns.tolist())\n","    plt.title(\"F) Misclassification substructure heatmap (rate)\")\n","    cbar = plt.colorbar(im, fraction=0.046, pad=0.04)\n","    cbar.set_label(\"Rate\", rotation=90)\n","    plt.tight_layout()\n","\n","    F_PATH = os.path.join(OUT_DIR, \"F_misclf_substruct_heatmap.png\")\n","    plt.savefig(F_PATH, dpi=160); plt.close()\n","else:\n","    print(\"[SKIP] RDKit unavailable -> skip panel (F).\")\n","\n","# --------- Save working table & report paths ---------\n","WORK_TBL = os.path.join(OUT_DIR, \"working_table.csv\")\n","# RDKitãŒç„¡ã„å ´åˆã€max_simã‚„sim_binãŒç„¡ã„ã®ã§NaNã§ç”¨æ„\n","if \"max_sim_rest\" not in df.columns:\n","    df[\"max_sim_rest\"] = np.nan\n","    df[\"sim_bin\"] = np.nan\n","df[[\"SMILES\",\"y_true\",\"p_ens\",\"max_sim_rest\",\"sim_bin\"]].to_csv(WORK_TBL, index=False)\n","\n","outputs = {\n","    \"A_umap_gr.png\": A_PATH,\n","    \"B_novelty_vs_prauc.png\": B_PATH,\n","    \"C_reliability.png\": C_PATH,\n","    \"D_topk_precision.png\": D_PATH,\n","    \"E_attr_paths\": E_PATHS,\n","    \"F_misclf_heatmap.png\": F_PATH,\n","    \"working_table.csv\": WORK_TBL,\n","    \"note\": \"Panels B/E/F require RDKit. Index mismatch fixed by carrying gr_vec inside the merged DataFrame. p_ens is cv_pr-weighted M1+M4 probability.\"\n","}\n","print(json.dumps(outputs, indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDc3UHSLaEac","executionInfo":{"status":"ok","timestamp":1760688538186,"user_tz":-540,"elapsed":241960,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"2b8fde74-4f67-4558-c118-8153dd52c0ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"A_umap_gr.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/A_umap_gr.png\",\n","  \"B_novelty_vs_prauc.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/B_novelty_vs_prauc.png\",\n","  \"C_reliability.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/C_reliability.png\",\n","  \"D_topk_precision.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/D_topk_precision.png\",\n","  \"E_attr_paths\": [\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/E_attr_TP_79.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/E_attr_TP_80.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/E_attr_FP_9.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/E_attr_FP_19.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/E_attr_FN_225.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/E_attr_FN_226.png\"\n","  ],\n","  \"F_misclf_heatmap.png\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/F_misclf_substruct_heatmap.png\",\n","  \"working_table.csv\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_m1m4_cvpr/working_table.csv\",\n","  \"note\": \"Panels B/E/F require RDKit. Index mismatch fixed by carrying gr_vec inside the merged DataFrame. p_ens is cv_pr-weighted M1+M4 probability.\"\n","}\n"]}]},{"cell_type":"code","source":["# === Cell 2 (fixed): SHAP + PDP on g(7) & r(10) features (surrogate on p_ens) ===\n","# Target model: M4 (single family)  â€» p_ens ã¯ M4 ã®æœ€çµ‚ç¢ºç‡ã‚’æƒ³å®š\n","# Robust to scikit-learn version differences for partial_dependence outputs.\n","\n","import os, sys, subprocess, json, numpy as np, pandas as pd, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# -------- CONFIG --------\n","ROOT    = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PT = f\"{ROOT}/data_graph_with_smiles.pt\"\n","# â˜… M4 ã§ä½œæˆã—ãŸå†…éƒ¨è©•ä¾¡ã®äºˆæ¸¬CSVã‚’å‚ç…§ï¼ˆp_ens=M4ç¢ºç‡ï¼‰\n","PRED_CSV = f\"{ROOT}/reports_internal_MDR1-M4-HYB-v1/predictions_internal_MDR1-M4-HYB-v1.csv\"\n","OUT_DIR  = f\"{ROOT}/figs_shap_pdp_M4\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# ----- deps -----\n","def _pip(cmd):\n","    try:\n","        subprocess.check_call(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL); return True\n","    except Exception:\n","        return False\n","\n","def _ensure(mod, pip_name=None):\n","    try:\n","        __import__(mod); return True\n","    except Exception:\n","        return _pip([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name or mod])\n","\n","_ensure(\"sklearn\", \"scikit-learn\")\n","_ensure(\"shap\", \"shap\")\n","_ensure(\"torch\", \"torch\")\n","try:\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","except Exception:\n","    _pip([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-geometric\"])\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","\n","import torch\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.inspection import partial_dependence\n","import shap\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","# ---- load ----\n","def load_pyg_list(path):\n","    add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","assert os.path.exists(DATA_PT), f\"Missing: {DATA_PT}\"\n","assert os.path.exists(PRED_CSV), f\"Missing: {PRED_CSV}\"\n","dl = load_pyg_list(DATA_PT)\n","pred = pd.read_csv(PRED_CSV)\n","\n","# p_ensï¼ˆ= M4 ã®æœ€çµ‚ç¢ºç‡ï¼‰ãŒå¿…é ˆ\n","if \"p_ens\" not in pred.columns:\n","    raise RuntimeError(\"predictions CSV ã« 'p_ens' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚M4 å†…éƒ¨è©•ä¾¡ã® predictions ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\")\n","\n","# carry (g,r) inside rows and merge by SMILES\n","rows = []\n","for d in dl:\n","    sm = getattr(d, \"smiles\", \"\")\n","    y  = int(getattr(d, \"y\", -1)); y  = y if y in (0,1) else -1\n","    g = np.asarray(getattr(d, \"g\")).reshape(-1)  # 7\n","    r = np.asarray(getattr(d, \"r\")).reshape(-1)  # 10\n","    gr = np.concatenate([g,r], axis=0)\n","    rows.append({\"SMILES\": sm, \"y_true\": y, \"gr_vec\": gr})\n","base = pd.DataFrame(rows)\n","\n","df = base.merge(pred[[\"SMILES\",\"p_ens\"]], on=\"SMILES\", how=\"inner\")\n","df = df[df[\"y_true\"].isin([0,1])].reset_index(drop=True)\n","\n","X = np.vstack(df[\"gr_vec\"].to_numpy())  # (n,17)\n","y = df[\"p_ens\"].values.astype(float)\n","feat_names = [f\"g{i+1}\" for i in range(7)] + [f\"r{i+1}\" for i in range(10)]\n","\n","# ---- surrogate (GBR) ----\n","sur = GradientBoostingRegressor(random_state=42)\n","sur.fit(X, y)\n","\n","# ---- SHAP summary ----\n","explainer = shap.TreeExplainer(sur)\n","shap_values = explainer.shap_values(X)\n","shap.summary_plot(shap_values, X, feature_names=feat_names, show=False, plot_size=(9,6))\n","SUM_PATH = os.path.join(OUT_DIR, \"shap_summary_gr.png\")\n","plt.tight_layout(); plt.savefig(SUM_PATH, dpi=180); plt.close()\n","\n","# ---- PDP: top-3 features by |SHAP| ----\n","imp = np.abs(shap_values).mean(axis=0)\n","top_idx = np.argsort(-imp)[:3]\n","\n","def _pd_xy(pd_bunch):\n","    \"\"\"Handle sklearn version differences: grid_values / values / x_values.\"\"\"\n","    if hasattr(pd_bunch, \"grid_values\"):\n","        xs = pd_bunch.grid_values[0]\n","    elif isinstance(pd_bunch, dict) and \"grid_values\" in pd_bunch:\n","        xs = pd_bunch[\"grid_values\"][0]\n","    elif isinstance(pd_bunch, dict) and \"values\" in pd_bunch:\n","        xs = pd_bunch[\"values\"][0]\n","    elif hasattr(pd_bunch, \"values\"):\n","        xs = pd_bunch.values[0]\n","    elif hasattr(pd_bunch, \"x_values\"):\n","        xs = pd_bunch.x_values[0]\n","    elif isinstance(pd_bunch, dict) and \"x_values\" in pd_bunch:\n","        xs = pd_bunch[\"x_values\"][0]\n","    else:\n","        raise KeyError(\"No x grid found in partial_dependence result.\")\n","    # average\n","    if hasattr(pd_bunch, \"average\"):\n","        ys = pd_bunch.average[0]\n","    elif isinstance(pd_bunch, dict) and \"average\" in pd_bunch:\n","        ys = pd_bunch[\"average\"][0]\n","    else:\n","        raise KeyError(\"No 'average' in partial_dependence result.\")\n","    return np.asarray(xs), np.asarray(ys)\n","\n","pdp_paths = []\n","for k in top_idx:\n","    pd_res = partial_dependence(sur, X, [k], kind=\"average\")\n","    xs, ys_pd = _pd_xy(pd_res)\n","    plt.figure()\n","    plt.plot(xs, ys_pd)\n","    plt.xlabel(feat_names[k]); plt.ylabel(\"p_ens (surrogate of M4)\")\n","    plt.title(f\"PDP: {feat_names[k]}\")\n","    plt.tight_layout()\n","    pth = os.path.join(OUT_DIR, f\"pdp_{feat_names[k]}.png\")\n","    plt.savefig(pth, dpi=180); plt.close()\n","    pdp_paths.append(pth)\n","\n","print(json.dumps({\n","    \"out_dir\": OUT_DIR,\n","    \"shap_summary\": SUM_PATH,\n","    \"pdp_top3\": pdp_paths,\n","}, indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVFNFchZdBuQ","executionInfo":{"status":"ok","timestamp":1760686275315,"user_tz":-540,"elapsed":22297,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"9d6a080b-6159-440d-de6d-e5db544fb49e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"out_dir\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M4\",\n","  \"shap_summary\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M4/shap_summary_gr.png\",\n","  \"pdp_top3\": [\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M4/pdp_r5.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M4/pdp_r10.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M4/pdp_r9.png\"\n","  ]\n","}\n"]}]},{"cell_type":"code","source":["# === Cell 2 (fixed): SHAP + PDP on g(7) & r(10) features (surrogate on p_ens) ===\n","# Target model: M1+M4 cv_pr ensemble  â€» p_ens ã¯ M1+M4ï¼ˆæ¤œè¨¼PR-AUCé‡ã¿ï¼‰ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã®æœ€çµ‚ç¢ºç‡ã‚’æƒ³å®š\n","# Robust to scikit-learn version differences for partial_dependence outputs.\n","\n","import os, sys, subprocess, json, numpy as np, pandas as pd, warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# -------- CONFIG --------\n","ROOT    = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PT = f\"{ROOT}/data_graph_with_smiles.pt\"\n","# â˜… M1+M4(cv_pr) ã§ä½œæˆã—ãŸå†…éƒ¨è©•ä¾¡ã®äºˆæ¸¬CSVã‚’å‚ç…§ï¼ˆp_ens= M1+M4(cv_pr) ç¢ºç‡ï¼‰\n","PRED_CSV = f\"{ROOT}/reports_internal_MDR1-M1M4-cvpr/predictions_internal_MDR1-M1M4-cvpr.csv\"\n","OUT_DIR  = f\"{ROOT}/figs_shap_pdp_M1M4_cvpr\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# ----- deps -----\n","def _pip(cmd):\n","    try:\n","        subprocess.check_call(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL); return True\n","    except Exception:\n","        return False\n","\n","def _ensure(mod, pip_name=None):\n","    try:\n","        __import__(mod); return True\n","    except Exception:\n","        return _pip([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pip_name or mod])\n","\n","_ensure(\"sklearn\", \"scikit-learn\")\n","_ensure(\"shap\", \"shap\")\n","_ensure(\"torch\", \"torch\")\n","try:\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","except Exception:\n","    _pip([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"torch-geometric\"])\n","    from torch.serialization import add_safe_globals\n","    from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","    from torch_geometric.data.storage import GlobalStorage\n","\n","import torch\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.inspection import partial_dependence\n","import shap\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","# ---- load ----\n","def load_pyg_list(path):\n","    add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","assert os.path.exists(DATA_PT), f\"Missing: {DATA_PT}\"\n","assert os.path.exists(PRED_CSV), f\"Missing: {PRED_CSV}\"\n","dl = load_pyg_list(DATA_PT)\n","pred = pd.read_csv(PRED_CSV)\n","\n","# p_ensï¼ˆ= M1+M4(cv_pr) ã®æœ€çµ‚ç¢ºç‡ï¼‰ãŒå¿…é ˆ\n","if \"p_ens\" not in pred.columns:\n","    raise RuntimeError(\"predictions CSV ã« 'p_ens' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚M1+M4(cv_pr) å†…éƒ¨è©•ä¾¡ã® predictions ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\")\n","\n","# carry (g,r) inside rows and merge by SMILES\n","rows = []\n","for d in dl:\n","    sm = getattr(d, \"smiles\", \"\")\n","    y  = int(getattr(d, \"y\", -1)); y  = y if y in (0,1) else -1\n","    g = np.asarray(getattr(d, \"g\")).reshape(-1)  # 7\n","    r = np.asarray(getattr(d, \"r\")).reshape(-1)  # 10\n","    gr = np.concatenate([g,r], axis=0)\n","    rows.append({\"SMILES\": sm, \"y_true\": y, \"gr_vec\": gr})\n","base = pd.DataFrame(rows)\n","\n","df = base.merge(pred[[\"SMILES\",\"p_ens\"]], on=\"SMILES\", how=\"inner\")\n","df = df[df[\"y_true\"].isin([0,1])].reset_index(drop=True)\n","\n","X = np.vstack(df[\"gr_vec\"].to_numpy())  # (n,17)\n","y = df[\"p_ens\"].values.astype(float)\n","feat_names = [f\"g{i+1}\" for i in range(7)] + [f\"r{i+1}\" for i in range(10)]\n","\n","# ---- surrogate (GBR) ----\n","sur = GradientBoostingRegressor(random_state=42)\n","sur.fit(X, y)\n","\n","# ---- SHAP summary ----\n","explainer = shap.TreeExplainer(sur)\n","shap_values = explainer.shap_values(X)\n","shap.summary_plot(shap_values, X, feature_names=feat_names, show=False, plot_size=(9,6))\n","SUM_PATH = os.path.join(OUT_DIR, \"shap_summary_gr.png\")\n","plt.tight_layout(); plt.savefig(SUM_PATH, dpi=180); plt.close()\n","\n","# ---- PDP: top-3 features by |SHAP| ----\n","imp = np.abs(shap_values).mean(axis=0)\n","top_idx = np.argsort(-imp)[:3]\n","\n","def _pd_xy(pd_bunch):\n","    \"\"\"Handle sklearn version differences: grid_values / values / x_values.\"\"\"\n","    if hasattr(pd_bunch, \"grid_values\"):\n","        xs = pd_bunch.grid_values[0]\n","    elif isinstance(pd_bunch, dict) and \"grid_values\" in pd_bunch:\n","        xs = pd_bunch[\"grid_values\"][0]\n","    elif isinstance(pd_bunch, dict) and \"values\" in pd_bunch:\n","        xs = pd_bunch[\"values\"][0]\n","    elif hasattr(pd_bunch, \"values\"):\n","        xs = pd_bunch.values[0]\n","    elif hasattr(pd_bunch, \"x_values\"):\n","        xs = pd_bunch.x_values[0]\n","    elif isinstance(pd_bunch, dict) and \"x_values\" in pd_bunch:\n","        xs = pd_bunch[\"x_values\"][0]\n","    else:\n","        raise KeyError(\"No x grid found in partial_dependence result.\")\n","    # average\n","    if hasattr(pd_bunch, \"average\"):\n","        ys = pd_bunch.average[0]\n","    elif isinstance(pd_bunch, dict) and \"average\" in pd_bunch:\n","        ys = pd_bunch[\"average\"][0]\n","    else:\n","        raise KeyError(\"No 'average' in partial_dependence result.\")\n","    return np.asarray(xs), np.asarray(ys)\n","\n","pdp_paths = []\n","for k in top_idx:\n","    pd_res = partial_dependence(sur, X, [k], kind=\"average\")\n","    xs, ys_pd = _pd_xy(pd_res)\n","    plt.figure()\n","    plt.plot(xs, ys_pd)\n","    plt.xlabel(feat_names[k]); plt.ylabel(\"p_ens (surrogate of M1+M4 cv_pr)\")\n","    plt.title(f\"PDP: {feat_names[k]}\")\n","    plt.tight_layout()\n","    pth = os.path.join(OUT_DIR, f\"pdp_{feat_names[k]}.png\")\n","    plt.savefig(pth, dpi=180); plt.close()\n","    pdp_paths.append(pth)\n","\n","print(json.dumps({\n","    \"out_dir\": OUT_DIR,\n","    \"shap_summary\": SUM_PATH,\n","    \"pdp_top3\": pdp_paths,\n","}, indent=2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vgdKwUGzcF3E","executionInfo":{"status":"ok","timestamp":1760686295837,"user_tz":-540,"elapsed":18852,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"ed60e128-bb1b-47b4-ce0c-95b12c4af0f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{\n","  \"out_dir\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M1M4_cvpr\",\n","  \"shap_summary\": \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M1M4_cvpr/shap_summary_gr.png\",\n","  \"pdp_top3\": [\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M1M4_cvpr/pdp_r5.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M1M4_cvpr/pdp_r10.png\",\n","    \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_shap_pdp_M1M4_cvpr/pdp_r9.png\"\n","  ]\n","}\n"]}]},{"cell_type":"code","source":["# ==== Digoxin mapping on MDR1-M4-HYB-v1 ====\n","# - äºˆæ¸¬CSVï¼ˆp_ens: M4å˜ç‹¬ï¼‰ã¨å†…éƒ¨ã‚°ãƒ©ãƒ•ã‚’çµåˆã—ã¦ã€ã‚¸ã‚´ã‚­ã‚·ãƒ³ã® p_ens ã‚’ç‰¹å®š\n","# - ECFP(2048, r=2) ã‚µãƒ­ã‚²ãƒ¼ãƒˆï¼ˆãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ï¼‰ã§åŸå­é‡è¦åº¦ã‚’æç”»\n","# - ãƒ‡ãƒ¼ã‚¿é›†åˆã«å¯¾ã™ã‚‹æœ€å¤§Tanimotoé¡ä¼¼åº¦ï¼ˆæ–°è¦æ€§ï¼‰ã¨è¿‘å‚Top-5ã‚’å‡ºåŠ›\n","# å‡ºåŠ›ç‰©: å›³ (PNG) / è¿‘å‚CSV / ã‚µãƒãƒªãƒ¼TXT\n","\n","import os, numpy as np, pandas as pd\n","import warnings; warnings.filterwarnings(\"ignore\")\n","\n","# ----------------- CONFIG -----------------\n","ROOT = \"/content/drive/MyDrive/Chemoinfo_MDR1_ver7\"\n","DATA_PT = f\"{ROOT}/data_graph_with_smiles.pt\"\n","# â˜… M4å†…éƒ¨è©•ä¾¡ã®äºˆæ¸¬CSVï¼ˆp_ens=M4ç¢ºç‡ï¼‰ã«åˆã‚ã›ã¦ãƒ‘ã‚¹ã‚’è¨­å®š\n","PRED_CSV = f\"{ROOT}/reports_internal_MDR1-M4-HYB-v1/predictions_internal_MDR1-M4-HYB-v1.csv\"\n","OUT_DIR  = f\"{ROOT}/figs_mdr1_final_digoxin_M4\"\n","os.makedirs(OUT_DIR, exist_ok=True)\n","\n","# --- ã§ãã‚‹ã ã‘å …ç‰¢ãª SMILES å€™è£œï¼ˆå…ˆé ­ã‹ã‚‰é †ã«è©¦è¡Œï¼‰\n","CANDIDATE_SMILES = [\n","    # ä¸€ä¾‹ï¼ˆå¿…è¦ãªã‚‰ç½®ãæ›ãˆï¼‰\n","    \"C[C@H]1O[C@@H](O[C@H]2[C@@H](O)C[C@H](O[C@H]3[C@@H](O)C[C@H](O[C@H]4CC[C@@]5(C)[C@H](CC[C@@H]6[C@@H]5CC[C@]5(C)[C@@H](C7=CC(=O)OC7)CC[C@]65O)C4)O[C@@H]3C)O[C@@H]2C)C[C@H](O)[C@@H]1O\"\n","]\n","\n","# ----------------- Imports -----------------\n","import matplotlib\n","matplotlib.use(\"Agg\")\n","import matplotlib.pyplot as plt\n","\n","import torch\n","from torch.serialization import add_safe_globals\n","from torch_geometric.data.data import DataEdgeAttr, DataTensorAttr\n","from torch_geometric.data.storage import GlobalStorage\n","\n","from rdkit import Chem\n","from rdkit.Chem import AllChem, Draw\n","from rdkit import DataStructs\n","from rdkit import RDLogger\n","# RDKit ãƒ­ã‚°æŠ‘æ­¢\n","RDLogger.DisableLog('rdApp.*')\n","# MorganGeneratorã®Deprecation WarningæŠ‘æ­¢\n","import warnings as _pywarn\n","_pywarn.filterwarnings(\"ignore\", message=\".*MorganGenerator.*\", category=UserWarning)\n","\n","from sklearn.linear_model import LogisticRegression\n","\n","# ----------------- Helpers -----------------\n","def load_pyg_list(path):\n","    add_safe_globals([DataEdgeAttr, DataTensorAttr, GlobalStorage])\n","    obj = torch.load(path, map_location=\"cpu\")\n","    if isinstance(obj, list): return obj\n","    if isinstance(obj, dict) and \"data_list\" in obj: return obj[\"data_list\"]\n","    return list(obj)\n","\n","def best_parsable_smiles(candidates):\n","    for s in candidates:\n","        m = Chem.MolFromSmiles(s)\n","        if m is not None:\n","            return Chem.MolToSmiles(m)\n","    return None\n","\n","def smiles_equal_or_inchikey_match(sm1, sm2):\n","    try:\n","        m1 = Chem.MolFromSmiles(sm1); m2 = Chem.MolFromSmiles(sm2)\n","        if m1 is None or m2 is None: return (sm1 == sm2)\n","        return Chem.MolToInchiKey(m1) == Chem.MolToInchiKey(m2)\n","    except Exception:\n","        return (sm1 == sm2)\n","\n","def ecfp2048(sm):\n","    m = Chem.MolFromSmiles(sm)\n","    if m is None: return None, None\n","    fp = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048)\n","    arr = np.zeros((2048,), dtype=np.uint8)\n","    DataStructs.ConvertToNumpyArray(fp, arr)\n","    bit_info = {}\n","    _ = AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048, bitInfo=bit_info)\n","    return m, (arr, bit_info)\n","\n","def atom_scores_from_bits(mol, bit_info, coef):\n","    n = mol.GetNumAtoms()\n","    scores = np.zeros(n, dtype=float)\n","    for b, envs in bit_info.items():\n","        w = float(coef[b])\n","        for (atom_idx, radius) in envs:\n","            amap = Chem.FindAtomEnvironmentOfRadiusN(mol, radius, atom_idx)\n","            atoms = {atom_idx}\n","            for bond_idx in amap:\n","                bd = mol.GetBondWithIdx(bond_idx)\n","                atoms.add(bd.GetBeginAtomIdx()); atoms.add(bd.GetEndAtomIdx())\n","            for a in atoms: scores[a] += w\n","    if scores.max() > scores.min():\n","        scores = (scores - scores.min())/(scores.max() - scores.min())\n","    return scores\n","\n","def draw_atom_heat(smiles, scores, out_png, legend):\n","    mol = Chem.MolFromSmiles(smiles)\n","    if mol is None: return False\n","    atom_cols = {i: (float(scores[i]), 0.0, 0.0) for i in range(mol.GetNumAtoms())}\n","    d2d = Draw.MolDraw2DCairo(800, 520)\n","    Draw.PrepareAndDrawMolecule(d2d, mol, highlightAtoms=list(atom_cols.keys()),\n","                                highlightAtomColors=atom_cols, legend=legend)\n","    d2d.FinishDrawing()\n","    with open(out_png, \"wb\") as f: f.write(d2d.GetDrawingText())\n","    return True\n","\n","# ----------------- Load data -----------------\n","assert os.path.exists(DATA_PT), f\"Missing: {DATA_PT}\"\n","assert os.path.exists(PRED_CSV), f\"Missing: {PRED_CSV}\"\n","\n","dl = load_pyg_list(DATA_PT)\n","pred = pd.read_csv(PRED_CSV)\n","\n","# p_ensï¼ˆ= M4 ã®æœ€çµ‚ç¢ºç‡ï¼‰ãŒå¿…é ˆ\n","if \"p_ens\" not in pred.columns:\n","    raise RuntimeError(\"predictions CSV ã« 'p_ens' åˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚M4 ã® predictions CSV ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚\")\n","\n","merge_cols = [\"SMILES\",\"p_ens\"]\n","\n","# PyG -> åŸºæœ¬è¡¨ï¼ˆSMILES, y_trueï¼‰\n","rows = []\n","for d in dl:\n","    sm = getattr(d, \"smiles\", \"\")\n","    y  = int(getattr(d, \"y\", -1))\n","    y  = y if y in (0,1) else -1\n","    rows.append({\"SMILES\": sm, \"y_true\": y})\n","base = pd.DataFrame(rows)\n","\n","df = base.merge(pred[merge_cols], on=\"SMILES\", how=\"inner\")\n","df = df[df[\"y_true\"].isin([0,1])].reset_index(drop=True)\n","\n","# ----------------- Pick DIGOXIN SMILES -----------------\n","SMILES_DIG = best_parsable_smiles(CANDIDATE_SMILES)\n","if SMILES_DIG is None:\n","    raise ValueError(\"ã‚¸ã‚´ã‚­ã‚·ãƒ³ã® SMILES å€™è£œãŒã™ã¹ã¦ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CANDIDATE_SMILES ã‚’ç½®ãæ›ãˆã¦ãã ã•ã„ã€‚\")\n","\n","mol_dig = Chem.MolFromSmiles(SMILES_DIG)\n","\n","# ----------------- Find in internal table -----------------\n","match_idx = None\n","for i, sm in enumerate(df[\"SMILES\"].tolist()):\n","    if smiles_equal_or_inchikey_match(sm, SMILES_DIG):\n","        match_idx = i; break\n","\n","if match_idx is not None:\n","    p_ens_dig = float(df.loc[match_idx, \"p_ens\"])\n","    y_dig     = int(df.loc[match_idx, \"y_true\"])\n","    print(f\"[FOUND] Digoxin present. p_ens={p_ens_dig:.4f}, y={y_dig}\")\n","else:\n","    p_ens_dig = None\n","    y_dig = None\n","    print(\"[INFO] Digoxin not found in internal table (SMILES/InChIKey). ä»¥é™ã¯é‡è¦åº¦ã¨é¡ä¼¼åº¦ã®ã¿å‡ºåŠ›ã€‚\")\n","\n","# ----------------- Build ECFP matrix & train surrogate -----------------\n","fps = []\n","for sm in df[\"SMILES\"].tolist():\n","    m = Chem.MolFromSmiles(sm)\n","    if m is None:\n","        fps.append(None); continue\n","    fps.append(AllChem.GetMorganFingerprintAsBitVect(m, 2, nBits=2048))\n","\n","valid = [(i,f) for i,f in enumerate(fps) if f is not None]\n","if not valid:\n","    raise RuntimeError(\"ECFP ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\")\n","\n","X = np.zeros((len(valid), 2048), dtype=np.uint8)\n","y = df.loc[[i for i,_ in valid], \"y_true\"].values.astype(int)\n","for r, (i, fp) in enumerate(valid):\n","    arr = np.zeros((2048,), dtype=np.uint8)\n","    DataStructs.ConvertToNumpyArray(fp, arr)\n","    X[r] = arr\n","\n","try:\n","    clf = LogisticRegression(max_iter=300, n_jobs=1)\n","except TypeError:\n","    clf = LogisticRegression(max_iter=300)\n","clf.fit(X, y)\n","coef = clf.coef_[0]\n","\n","# ----------------- Digoxin: attribution & novelty -----------------\n","mt, bits = ecfp2048(SMILES_DIG)\n","if mt is None or bits is None:\n","    raise RuntimeError(\"Digoxin ã® ECFP ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ã€‚\")\n","\n","arr_dig, bit_info_dig = bits\n","scores = atom_scores_from_bits(mt, bit_info_dig, coef)\n","fig_path = os.path.join(OUT_DIR, \"digoxin_atom_importance.png\")\n","_ = draw_atom_heat(\n","    SMILES_DIG, scores, fig_path,\n","    legend=f\"Digoxin{'' if p_ens_dig is None else f'  p_ens={p_ens_dig:.3f}'}\"\n",")\n","print(\"[SAVE] atom-importance figure ->\", fig_path)\n","\n","# æ–°è¦æ€§ï¼ˆå†…éƒ¨é›†åˆã«å¯¾ã™ã‚‹æœ€å¤§Tanimotoé¡ä¼¼åº¦ï¼‰\n","fp_dig = AllChem.GetMorganFingerprintAsBitVect(mt, 2, nBits=2048)\n","sims = [DataStructs.TanimotoSimilarity(fp, fp_dig) for _, fp in valid]\n","max_sim = float(np.max(sims)) if sims else float(\"nan\")\n","print(f\"[NOVELTY] Max Tanimoto similarity to internal set: {max_sim:.3f}\")\n","\n","# è¿‘å‚Top-5\n","nn_idx = np.argsort(-np.array(sims))[:5]\n","nn_rows = []\n","for k in nn_idx:\n","    i = valid[k][0]\n","    nn_rows.append({\n","        \"rank\": len(nn_rows)+1,\n","        \"SMILES\": df.loc[i, \"SMILES\"],\n","        \"y_true\": int(df.loc[i, \"y_true\"]),\n","        \"p_ens\": float(df.loc[i, \"p_ens\"]),\n","        \"sim\": float(sims[k]),\n","    })\n","nn_df = pd.DataFrame(nn_rows)\n","nn_csv = os.path.join(OUT_DIR, \"digoxin_nearest_neighbors.csv\")\n","nn_df.to_csv(nn_csv, index=False)\n","print(\"[SAVE] nearest neighbors ->\", nn_csv)\n","\n","# ã‚µãƒãƒªãƒ¼\n","summary_txt = os.path.join(OUT_DIR, \"digoxin_summary.txt\")\n","with open(summary_txt, \"w\") as f:\n","    f.write(\"Digoxin mapping on MDR1-M4-HYB-v1\\n\")\n","    f.write(f\"Chosen SMILES: {SMILES_DIG}\\n\")\n","    if match_idx is not None:\n","        f.write(f\"Found in internal set: YES | p_ens={p_ens_dig:.4f} | y_true={y_dig}\\n\")\n","    else:\n","        f.write(\"Found in internal set: NO (only surrogate attribution & novelty reported)\\n\")\n","    f.write(f\"Max Tanimoto similarity to internal set: {max_sim:.3f}\\n\")\n","    f.write(f\"Atom-importance figure: {fig_path}\\n\")\n","    f.write(f\"Nearest neighbors CSV: {nn_csv}\\n\")\n","\n","print(\"[DONE] Summary ->\", summary_txt)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tbA38VDZNo46","executionInfo":{"status":"ok","timestamp":1760686082253,"user_tz":-540,"elapsed":24109,"user":{"displayName":"Tom Eno","userId":"01928761000188356119"}},"outputId":"72da2a6c-d81b-457b-e384-c6b0823ad74f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[FOUND] Digoxin present. p_ens=0.7565, y=1\n","[SAVE] atom-importance figure -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_digoxin_M4/digoxin_atom_importance.png\n","[NOVELTY] Max Tanimoto similarity to internal set: 1.000\n","[SAVE] nearest neighbors -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_digoxin_M4/digoxin_nearest_neighbors.csv\n","[DONE] Summary -> /content/drive/MyDrive/Chemoinfo_MDR1_ver7/figs_mdr1_final_digoxin_M4/digoxin_summary.txt\n"]}]}]}